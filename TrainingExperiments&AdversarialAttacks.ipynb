{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers pandas scikit-learn tqdm textstat spacy\n",
        "\n",
        "# Install and download all at once\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download fr_core_news_sm\n",
        "!python -m spacy download de_core_news_sm\n",
        "!python -m spacy download es_core_news_sm"
      ],
      "metadata": {
        "collapsed": true,
        "id": "wbz0pFjLjUvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RETRAIN"
      ],
      "metadata": {
        "id": "miDN2ZxaQo26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================== EMC Full Training (All Models) ===========================\n",
        "# Trains:\n",
        "#  1) XLM-R only (Transformer baseline)\n",
        "#  2) Simple Fusion (XLM-R + 12 engineered features, concat)\n",
        "#  3) Gated Fusion  (XLM-R + 12 engineered features, gated injection)\n",
        "#  4) XGBoost       (12 engineered features only)\n",
        "#\n",
        "# Features (12 total):\n",
        "#  - Structural: char_count, word_count, sent_count\n",
        "#  - Psycholinguistic (English-only): flesch_reading_ease, gunning_fog (else 0)\n",
        "#  - Trust: eng_term_pct, punct_count, num_count, has_standard, has_safety\n",
        "#  - Numeric: avg_num_mag, decimal_ratio\n",
        "#\n",
        "# Inputs expected:\n",
        "#  - train/val/test CSVs with columns: content, label, lang\n",
        "#  - engineering_terms.csv with columns: terms, count, lang  (NB: column is 'terms')\n",
        "#\n",
        "# Outputs:\n",
        "#  - /.../xlmr_only_outputs/\n",
        "#  - /.../simple_fusion_outputs/\n",
        "#  - /.../gated_fusion_outputs/\n",
        "#  - /.../xgb_outputs/\n",
        "#\n",
        "# --------------------------------------------------------------------------------------\n",
        "\n",
        "import os, re, json, math, argparse, random\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Any, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Text stats (readability)\n",
        "try:\n",
        "    import textstat\n",
        "    _HAS_TEXTSTAT = True\n",
        "except Exception:\n",
        "    _HAS_TEXTSTAT = False\n",
        "\n",
        "# Torch / HF\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    XLMRobertaModel,\n",
        "    XLMRobertaForSequenceClassification,\n",
        "    XLMRobertaTokenizerFast,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# XGBoost\n",
        "import xgboost as xgb\n",
        "\n",
        "# ------------------------------- Config ---------------------------------------------\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    base_dir: str = \"/content/drive/MyDrive/emc\"\n",
        "    train_csv: str = \"/content/drive/MyDrive/emc/train.csv\"\n",
        "    val_csv: str   = \"/content/drive/MyDrive/emc/val.csv\"\n",
        "    test_csv: str  = \"/content/drive/MyDrive/emc/test.csv\"\n",
        "\n",
        "    terms_csv: str = \"/content/drive/MyDrive/emc/engineering_terms.csv\"  # <-- 'terms' column\n",
        "\n",
        "    xlmr_name: str = \"xlm-roberta-base\"\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    seed: int = 13\n",
        "\n",
        "    # training\n",
        "    epochs: int = 5\n",
        "    batch_size: int = 16\n",
        "    max_len: int = 256\n",
        "    lr: float = 2e-5\n",
        "    weight_decay: float = 0.01\n",
        "    warmup_ratio: float = 0.0\n",
        "    patience: int = 2\n",
        "    use_amp: bool = True\n",
        "\n",
        "    # output dirs\n",
        "    out_xlmr: str = os.path.join(base_dir, \"xlmr_only_outputs\")\n",
        "    out_simple: str = os.path.join(base_dir, \"simple_fusion_outputs\")\n",
        "    out_gated: str = os.path.join(base_dir, \"gated_fusion_outputs\")\n",
        "    out_xgb: str = os.path.join(base_dir, \"xgb_outputs\")\n",
        "\n",
        "    # engineered feature count (fixed at 12 per spec)\n",
        "    feat_dim: int = 12\n",
        "\n",
        "\n",
        "# ------------------------------- Utils / Repro ---------------------------------------\n",
        "\n",
        "STD_TERMS = {\"iso\",\"asme\",\"ieee\",\"din\",\"ansi\",\"iec\",\"ul\",\"astm\",\"en\"}\n",
        "SAFETY_TERMS = {\"safety\",\"hazard\",\"warning\",\"risk\",\"caution\",\"danger\",\"emergency\"}\n",
        "\n",
        "def set_seed(s: int):\n",
        "    random.seed(s)\n",
        "    np.random.seed(s)\n",
        "    torch.manual_seed(s)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(s)\n",
        "\n",
        "def safe_makedirs(path: str):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def sent_count(text: str) -> int:\n",
        "    # lightweight sentence split: split on [.?!] with some tolerance\n",
        "    if not text:\n",
        "        return 0\n",
        "    # Count non-empty segments after splitting\n",
        "    parts = re.split(r'[.!?]+[\\s\\n]+', text)\n",
        "    return sum(1 for p in parts if p.strip() != \"\")\n",
        "\n",
        "# ===== Replace these helpers in your script =====\n",
        "\n",
        "_NUM_RE = re.compile(r'[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?')\n",
        "\n",
        "def extract_numbers(text: str):\n",
        "    \"\"\"Parse numeric strings into floats, robustly.\"\"\"\n",
        "    nums = []\n",
        "    dec_count = 0\n",
        "    for m in _NUM_RE.finditer(text or \"\"):\n",
        "        s = m.group(0)\n",
        "        try:\n",
        "            v = float(s)\n",
        "            # Count decimals / scientific notation for decimal_ratio:\n",
        "            if ('.' in s) or ('e' in s.lower()):\n",
        "                dec_count += 1\n",
        "            nums.append(abs(v))\n",
        "        except Exception:\n",
        "            # skip unparsable tokens\n",
        "            pass\n",
        "    return nums, dec_count\n",
        "\n",
        "def _finite_or_zero(x: float) -> float:\n",
        "    return float(x) if np.isfinite(x) else 0.0\n",
        "\n",
        "class FeatureExtractor:\n",
        "    \"\"\"\n",
        "    12-feature extractor with robust clipping & finite-guards.\n",
        "    \"\"\"\n",
        "    # Caps chosen to be realistic for engineering text and safe for float32/scaling\n",
        "    MAX_CHARS      = 200_000   # structural caps\n",
        "    MAX_WORDS      = 40_000\n",
        "    MAX_SENTS      = 10_000\n",
        "    MAX_PUNCT      = 50_000\n",
        "    MAX_NUM_COUNT  = 10_000\n",
        "\n",
        "    MAX_NUM_ABS    = 1e12      # cap each numeric value before averaging\n",
        "    MAX_AVG_MAG    = 1e12      # cap avg magnitude (redundant but safe)\n",
        "\n",
        "    def __init__(self, terms_lex: TermsLexicon):\n",
        "        self.tlex = terms_lex\n",
        "\n",
        "    def extract_one(self, text: str, lang: str) -> np.ndarray:\n",
        "        text = \"\" if text is None else str(text)\n",
        "        lang = \"en\" if not lang else str(lang).lower()\n",
        "        ws = simple_words(text)\n",
        "        n_words = len(ws)\n",
        "\n",
        "        # Structural (with caps)\n",
        "        chars = min(len(text), self.MAX_CHARS)\n",
        "        words = min(n_words, self.MAX_WORDS)\n",
        "        sents = min(sent_count(text), self.MAX_SENTS)\n",
        "\n",
        "        # Psycholinguistic (English only) with finite guard\n",
        "        if lang == \"en\" and _HAS_TEXTSTAT and text.strip():\n",
        "            try:\n",
        "                fre = _finite_or_zero(textstat.flesch_reading_ease(text))\n",
        "                fog = _finite_or_zero(textstat.gunning_fog(text))\n",
        "            except Exception:\n",
        "                fre, fog = 0.0, 0.0\n",
        "        else:\n",
        "            fre, fog = 0.0, 0.0\n",
        "\n",
        "        # Trust & numeric\n",
        "        eng_pct = self.tlex.pct_in_text(text, lang)\n",
        "        punc    = min(punct_count(text), self.MAX_PUNCT)\n",
        "\n",
        "        nums, dec_cnt = extract_numbers(text)\n",
        "        nnums = min(len(nums), self.MAX_NUM_COUNT)\n",
        "\n",
        "        # Clip each numeric value before averaging to avoid overflow/outliers\n",
        "        if len(nums) > 0:\n",
        "            nums_clipped = [min(v, self.MAX_NUM_ABS) for v in nums]\n",
        "            avg_mag = float(np.mean(nums_clipped))\n",
        "            if not np.isfinite(avg_mag):\n",
        "                avg_mag = 0.0\n",
        "            avg_mag = min(avg_mag, self.MAX_AVG_MAG)\n",
        "        else:\n",
        "            avg_mag = 0.0\n",
        "\n",
        "        dec_ratio = float(dec_cnt / len(nums)) if len(nums) > 0 else 0.0\n",
        "        if not np.isfinite(dec_ratio):\n",
        "            dec_ratio = 0.0\n",
        "\n",
        "        has_std = 1.0 if any(t in text.lower() for t in STD_TERMS) else 0.0\n",
        "        has_saf = 1.0 if any(t in text.lower() for t in SAFETY_TERMS) else 0.0\n",
        "\n",
        "        # Assemble, ensure dtype=float32 and all finite\n",
        "        feats = np.array([\n",
        "            float(chars),               # 1 char_count\n",
        "            float(words),               # 2 word_count\n",
        "            float(sents),               # 3 sent_count\n",
        "            float(fre),                 # 4 Flesch RE (en)\n",
        "            float(fog),                 # 5 Gunning Fog (en)\n",
        "            float(eng_pct),             # 6 % engineering terms\n",
        "            float(punc),                # 7 punctuation count\n",
        "            float(nnums),               # 8 number count\n",
        "            float(has_std),             # 9 contains standard\n",
        "            float(has_saf),             #10 contains safety\n",
        "            float(avg_mag),             #11 average number magnitude (clipped)\n",
        "            float(dec_ratio),           #12 decimal point ratio\n",
        "        ], dtype=np.float32)\n",
        "\n",
        "        # Final safety: replace any non-finite with 0\n",
        "        if not np.all(np.isfinite(feats)):\n",
        "            feats = np.nan_to_num(feats, nan=0.0, posinf=self.MAX_AVG_MAG, neginf=0.0).astype(np.float32)\n",
        "\n",
        "        return feats\n",
        "\n",
        "    def extract_df(self, df: pd.DataFrame) -> np.ndarray:\n",
        "        out = []\n",
        "        for _, r in tqdm(df.iterrows(), total=len(df), desc=\"Extracting features\"):\n",
        "            out.append(self.extract_one(r.get(\"content\",\"\"), r.get(\"lang\",\"en\")))\n",
        "        return np.stack(out, axis=0).astype(np.float32)\n",
        "\n",
        "\n",
        "\n",
        "# ------------------------------- Datasets --------------------------------------------\n",
        "\n",
        "class TextFeatDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, tok: XLMRobertaTokenizerFast, max_len: int,\n",
        "                 feats: Optional[np.ndarray] = None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tok = tok\n",
        "        self.max_len = max_len\n",
        "        self.feats = feats  # [N,F] or None\n",
        "\n",
        "    def __len__(self): return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        text = str(row[\"content\"])\n",
        "        enc = self.tok(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        item = {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"label\": torch.tensor(int(row[\"label\"]), dtype=torch.long),\n",
        "        }\n",
        "        if self.feats is not None:\n",
        "            item[\"engineered\"] = torch.tensor(self.feats[idx], dtype=torch.float32)\n",
        "        return item\n",
        "\n",
        "\n",
        "# ------------------------------- Pooling / Models ------------------------------------\n",
        "\n",
        "def mean_pool(last_hidden_state: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
        "    # last_hidden_state: [B, L, H], attention_mask: [B, L]\n",
        "    mask = attention_mask.unsqueeze(-1)  # [B,L,1]\n",
        "    masked = last_hidden_state * mask\n",
        "    summed = masked.sum(dim=1)                    # [B,H]\n",
        "    denom = mask.sum(dim=1).clamp(min=1e-6)      # [B,1]\n",
        "    return summed / denom\n",
        "\n",
        "class SimpleFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, feat_dim: int, n_classes=2):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.classifier = nn.Linear(self.encoder.config.hidden_size + feat_dim, n_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, engineered):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        pooled = mean_pool(out.last_hidden_state, attention_mask)\n",
        "        fused = torch.cat([pooled, engineered], dim=1)\n",
        "        logits = self.classifier(self.dropout(fused))\n",
        "        return logits\n",
        "\n",
        "class GatedFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, feat_dim: int, n_classes=2, feat_proj: int = 64):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.fe_proj = nn.Sequential(\n",
        "            nn.Linear(feat_dim, feat_proj),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        # compute a gate α ∈ [0,1] from text (pooled) + raw features\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(H + feat_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.classifier = nn.Linear(H + feat_proj, n_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, engineered):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        pooled = mean_pool(out.last_hidden_state, attention_mask)     # [B,H]\n",
        "        alpha = self.gate(torch.cat([pooled, engineered], dim=1))     # [B,1]\n",
        "        ef = self.fe_proj(engineered)                                 # [B,feat_proj]\n",
        "        fused = torch.cat([pooled, alpha * ef], dim=1)                # gated injection\n",
        "        logits = self.classifier(self.dropout(fused))\n",
        "        return logits\n",
        "\n",
        "# ------------------------------- HF helper (logits fix) ------------------------------\n",
        "\n",
        "def hf_forward_logits(model, inputs, labels=None, use_amp=False, device=\"cuda\", loss_fn=None):\n",
        "    with torch.amp.autocast(\"cuda\", enabled=(use_amp and device == \"cuda\")):\n",
        "        out = model(**inputs)              # SequenceClassifierOutput\n",
        "        logits = out.logits               # <-- important!\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            if loss_fn is not None:\n",
        "                loss = loss_fn(logits, labels)\n",
        "            else:\n",
        "                # fallback plain CE\n",
        "                loss = nn.CrossEntropyLoss()(logits, labels)\n",
        "    return logits, loss\n",
        "\n",
        "# ------------------------------- Train / Eval loops ----------------------------------\n",
        "\n",
        "def train_epoch(model, loader, optimizer, scheduler, device, use_amp, loss_fn):\n",
        "    model.train()\n",
        "    total = 0.0\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=(use_amp and device == \"cuda\"))\n",
        "    for batch in tqdm(loader, desc=\"train\", leave=False):\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        am = batch[\"attention_mask\"].to(device)\n",
        "        y = batch[\"label\"].to(device)\n",
        "        if \"engineered\" in batch:\n",
        "            logits = model(input_ids, am, batch[\"engineered\"].to(device))\n",
        "            loss = loss_fn(logits, y)\n",
        "            if use_amp and device==\"cuda\":\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    pass\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer); scaler.update()\n",
        "        else:\n",
        "            # HF classifier path should pass through hf_forward_logits\n",
        "            raise RuntimeError(\"train_epoch called without engineered features; use train_epoch_xlmr for HF model.\")\n",
        "        scheduler.step()\n",
        "        total += float(loss.item())\n",
        "    return total / max(1, len(loader))\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_epoch_logits(model, loader, device, use_amp, fusion: bool):\n",
        "    model.eval()\n",
        "    ys, ps = [], []\n",
        "    for batch in tqdm(loader, desc=\"eval\", leave=False):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        am = batch[\"attention_mask\"].to(device)\n",
        "        y = batch[\"label\"].to(device)\n",
        "        if fusion:\n",
        "            logits = model(input_ids, am, batch[\"engineered\"].to(device))\n",
        "        else:\n",
        "            # hf model outside (calls hf_forward_logits)\n",
        "            raise RuntimeError(\"eval_epoch_logits fusion=False is only for HF model wrapper.\")\n",
        "        p = logits.argmax(dim=1)\n",
        "        ys.extend(y.cpu().tolist()); ps.extend(p.cpu().tolist())\n",
        "    return ys, ps\n",
        "\n",
        "def train_epoch_xlmr(hf_model, loader, optimizer, scheduler, device, use_amp, loss_fn):\n",
        "    hf_model.train()\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=(use_amp and device == \"cuda\"))\n",
        "    total = 0.0\n",
        "    for batch in tqdm(loader, desc=\"train\", leave=False):\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        inputs = {\n",
        "            \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "            \"attention_mask\": batch[\"attention_mask\"].to(device)\n",
        "        }\n",
        "        y = batch[\"label\"].to(device)\n",
        "        logits, loss = hf_forward_logits(hf_model, inputs, labels=y, use_amp=use_amp, device=device, loss_fn=loss_fn)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer); scaler.update()\n",
        "        scheduler.step()\n",
        "        total += float(loss.item())\n",
        "    return total / max(1, len(loader))\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_epoch_xlmr(hf_model, loader, device, use_amp):\n",
        "    hf_model.eval()\n",
        "    ys, ps = [], []\n",
        "    for batch in tqdm(loader, desc=\"eval\", leave=False):\n",
        "        inputs = {\n",
        "            \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "            \"attention_mask\": batch[\"attention_mask\"].to(device)\n",
        "        }\n",
        "        y = batch[\"label\"].to(device)\n",
        "        logits, _ = hf_forward_logits(hf_model, inputs, labels=None, use_amp=use_amp, device=device)\n",
        "        p = logits.argmax(dim=1)\n",
        "        ys.extend(y.cpu().tolist()); ps.extend(p.cpu().tolist())\n",
        "    return ys, ps\n",
        "\n",
        "def compute_metrics(y_true, y_pred) -> Dict[str, float]:\n",
        "    return {\n",
        "        \"macro_f1\": f1_score(y_true, y_pred, average=\"macro\"),\n",
        "        \"micro_f1\": f1_score(y_true, y_pred, average=\"micro\"),\n",
        "        \"weighted_f1\": f1_score(y_true, y_pred, average=\"weighted\"),\n",
        "        \"accuracy\": (np.array(y_true) == np.array(y_pred)).mean().item(),\n",
        "    }\n",
        "\n",
        "# ------------------------------- XGBoost wrapper -------------------------------------\n",
        "\n",
        "def train_xgb(X_train, y_train, X_val, y_val, X_test, y_test, out_dir: str):\n",
        "    safe_makedirs(out_dir)\n",
        "    # handle class imbalance\n",
        "    neg = (y_train == 0).sum()\n",
        "    pos = (y_train == 1).sum()\n",
        "    scale_pos_weight = float(neg / max(1, pos))\n",
        "    params = dict(\n",
        "        n_estimators=1500,\n",
        "        max_depth=6,\n",
        "        learning_rate=0.05,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        reg_lambda=1.0,\n",
        "        reg_alpha=0.0,\n",
        "        objective=\"binary:logistic\",\n",
        "        tree_method=\"hist\",\n",
        "        n_jobs=4,\n",
        "        scale_pos_weight=scale_pos_weight,\n",
        "        eval_metric=\"logloss\",\n",
        "        random_state=13,\n",
        "    )\n",
        "    clf = xgb.XGBClassifier(**params)\n",
        "    # Try to use early stopping if available in current xgb version\n",
        "    try:\n",
        "        clf.fit(\n",
        "            X_train, y_train,\n",
        "            eval_set=[(X_val, y_val)],\n",
        "            verbose=False,\n",
        "            early_stopping_rounds=100\n",
        "        )\n",
        "    except TypeError:\n",
        "        clf.fit(X_train, y_train, verbose=False)\n",
        "    # eval\n",
        "    def _pred(clf, X):\n",
        "        p = clf.predict_proba(X)[:,1]\n",
        "        return (p >= 0.5).astype(int)\n",
        "    yv = _pred(clf, X_val)\n",
        "    yt = _pred(clf, X_test)\n",
        "    mv = compute_metrics(y_val, yv)\n",
        "    mt = compute_metrics(y_test, yt)\n",
        "    pd.DataFrame([mv, mt], index=[\"val\",\"test\"]).to_csv(os.path.join(out_dir, \"metrics.csv\"))\n",
        "    clf.save_model(os.path.join(out_dir, \"xgb_model.json\"))\n",
        "    print(\"[XGB] val:\", mv)\n",
        "    print(\"[XGB] test:\", mt)\n",
        "\n",
        "# ------------------------------- Main (All Models) -----------------------------------\n",
        "\n",
        "def main(mode: str):\n",
        "    cfg = Config()\n",
        "    set_seed(cfg.seed)\n",
        "    print(\"Using device:\", cfg.device)\n",
        "\n",
        "    # I/O\n",
        "    for p in [cfg.base_dir, cfg.out_xlmr, cfg.out_simple, cfg.out_gated, cfg.out_xgb]:\n",
        "        safe_makedirs(p)\n",
        "    assert os.path.exists(cfg.train_csv), f\"Missing train_csv: {cfg.train_csv}\"\n",
        "    assert os.path.exists(cfg.val_csv),   f\"Missing val_csv: {cfg.val_csv}\"\n",
        "    assert os.path.exists(cfg.test_csv),  f\"Missing test_csv: {cfg.test_csv}\"\n",
        "\n",
        "    # Data\n",
        "    train_df = pd.read_csv(cfg.train_csv)\n",
        "    val_df   = pd.read_csv(cfg.val_csv)\n",
        "    test_df  = pd.read_csv(cfg.test_csv)\n",
        "    for df in (train_df, val_df, test_df):\n",
        "        if \"lang\" not in df.columns: df[\"lang\"] = \"en\"\n",
        "        df[\"label\"] = df[\"label\"].astype(int)\n",
        "\n",
        "    # Terms / Features\n",
        "    lex = TermsLexicon(cfg.terms_csv)\n",
        "    fx = FeatureExtractor(lex)\n",
        "\n",
        "    print(\"Extracting features (train/val/test) ...\")\n",
        "    feats_tr_raw = fx.extract_df(train_df)   # [N,12]\n",
        "    feats_v_raw  = fx.extract_df(val_df)\n",
        "    feats_te_raw = fx.extract_df(test_df)\n",
        "\n",
        "    # Scale on train -> apply to val/test\n",
        "    scaler = StandardScaler()\n",
        "    feats_tr = scaler.fit_transform(feats_tr_raw)\n",
        "    feats_v  = scaler.transform(feats_v_raw)\n",
        "    feats_te = scaler.transform(feats_te_raw)\n",
        "\n",
        "    # Save scalers for fusion / xgb\n",
        "    job_scl_simple = os.path.join(cfg.out_simple, \"scaler12.pkl\")\n",
        "    job_scl_gated  = os.path.join(cfg.out_gated, \"scaler12.pkl\")\n",
        "    from joblib import dump as joblib_dump\n",
        "    joblib_dump(scaler, job_scl_simple)\n",
        "    joblib_dump(scaler, job_scl_gated)\n",
        "    print(f\"Saved StandardScaler -> {job_scl_simple} and {job_scl_gated}\")\n",
        "\n",
        "    # Tokenizer\n",
        "    tok = XLMRobertaTokenizerFast.from_pretrained(cfg.xlmr_name)\n",
        "\n",
        "    # Datasets\n",
        "    ds_tr_no_feat = TextFeatDataset(train_df, tok, cfg.max_len, feats=None)\n",
        "    ds_v_no_feat  = TextFeatDataset(val_df, tok, cfg.max_len, feats=None)\n",
        "    ds_te_no_feat = TextFeatDataset(test_df, tok, cfg.max_len, feats=None)\n",
        "\n",
        "    ds_tr = TextFeatDataset(train_df, tok, cfg.max_len, feats_tr)\n",
        "    ds_v  = TextFeatDataset(val_df, tok, cfg.max_len, feats_v)\n",
        "    ds_te = TextFeatDataset(test_df, tok, cfg.max_len, feats_te)\n",
        "\n",
        "    dl_args = dict(batch_size=cfg.batch_size, num_workers=2, pin_memory=True)\n",
        "    tr_no = DataLoader(ds_tr_no_feat, shuffle=True, **dl_args)\n",
        "    v_no  = DataLoader(ds_v_no_feat, shuffle=False, **dl_args)\n",
        "    te_no = DataLoader(ds_te_no_feat, shuffle=False, **dl_args)\n",
        "\n",
        "    tr = DataLoader(ds_tr, shuffle=True, **dl_args)\n",
        "    v  = DataLoader(ds_v, shuffle=False, **dl_args)\n",
        "    te = DataLoader(ds_te, shuffle=False, **dl_args)\n",
        "\n",
        "    # Class weights for CE\n",
        "    c0 = (train_df[\"label\"]==0).sum()\n",
        "    c1 = (train_df[\"label\"]==1).sum()\n",
        "    w0 = (len(train_df) / max(1, c0))\n",
        "    w1 = (len(train_df) / max(1, c1))\n",
        "    class_weights = torch.tensor([w0, w1], dtype=torch.float32, device=cfg.device)\n",
        "    ce_weighted = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "    # ------------------------- 1) XLM-R only ---------------------------------------\n",
        "    if mode in (\"all\",\"xlmr\"):\n",
        "        print(\"\\n=== Train XLM-R only ===\")\n",
        "        hf = XLMRobertaForSequenceClassification.from_pretrained(\n",
        "            cfg.xlmr_name,\n",
        "            num_labels=2,\n",
        "            id2label={0:\"0\",1:\"1\"},\n",
        "            label2id={\"0\":0,\"1\":1}\n",
        "        ).to(cfg.device)\n",
        "\n",
        "        opt = torch.optim.AdamW(hf.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "        total_steps = len(tr_no) * cfg.epochs\n",
        "        sched = get_linear_schedule_with_warmup(\n",
        "            opt,\n",
        "            num_warmup_steps=int(cfg.warmup_ratio * total_steps),\n",
        "            num_training_steps=total_steps\n",
        "        )\n",
        "\n",
        "        best, best_state = -1.0, None\n",
        "        patience = cfg.patience\n",
        "        for ep in range(1, cfg.epochs+1):\n",
        "            tl = train_epoch_xlmr(hf, tr_no, opt, sched, cfg.device, cfg.use_amp, ce_weighted)\n",
        "            yv, pv = eval_epoch_xlmr(hf, v_no, cfg.device, cfg.use_amp)\n",
        "            mv = compute_metrics(yv, pv)\n",
        "            print(f\"[XLMR][ep{ep}] loss={tl:.4f} | val macroF1={mv['macro_f1']:.4f}\")\n",
        "            if mv[\"macro_f1\"] > best:\n",
        "                best = mv[\"macro_f1\"]\n",
        "                best_state = hf.state_dict()\n",
        "                patience = cfg.patience\n",
        "            else:\n",
        "                patience -= 1\n",
        "                if patience < 0:\n",
        "                    print(\"  ⏹ Early stop (xlmr).\")\n",
        "                    break\n",
        "        # save best\n",
        "        outd = cfg.out_xlmr\n",
        "        safe_makedirs(outd)\n",
        "        hf.load_state_dict(best_state)\n",
        "        torch.save(hf.state_dict(), os.path.join(outd, \"pytorch_model.bin\"))\n",
        "        with open(os.path.join(outd, \"label_map.json\"), \"w\") as f:\n",
        "            json.dump({\"label2id\":{\"0\":0,\"1\":1},\"id2label\":{\"0\":\"0\",\"1\":\"1\"}}, f, indent=2)\n",
        "        # test\n",
        "        yt, pt = eval_epoch_xlmr(hf, te_no, cfg.device, cfg.use_amp)\n",
        "        mt = compute_metrics(yt, pt)\n",
        "        pd.DataFrame([mt]).to_csv(os.path.join(outd, \"test_metrics.csv\"), index=False)\n",
        "        print(\"[XLMR][test]\", mt)\n",
        "\n",
        "    # ------------------------- 2) Simple Fusion ------------------------------------\n",
        "    if mode in (\"all\",\"simple\"):\n",
        "        print(\"\\n=== Train Simple Fusion (concat) ===\")\n",
        "        model = SimpleFusion(cfg.xlmr_name, feat_dim=cfg.feat_dim, n_classes=2).to(cfg.device)\n",
        "        opt = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "        total_steps = len(tr) * cfg.epochs\n",
        "        sched = get_linear_schedule_with_warmup(\n",
        "            opt,\n",
        "            num_warmup_steps=int(cfg.warmup_ratio * total_steps),\n",
        "            num_training_steps=total_steps\n",
        "        )\n",
        "        best, best_state = -1.0, None\n",
        "        patience = cfg.patience\n",
        "        for ep in range(1, cfg.epochs+1):\n",
        "            model.train()\n",
        "            scaler = torch.cuda.amp.GradScaler(enabled=(cfg.use_amp and cfg.device==\"cuda\"))\n",
        "            tot = 0.0\n",
        "            for batch in tqdm(tr, desc=f\"train simple ep{ep}\", leave=False):\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                ids = batch[\"input_ids\"].to(cfg.device)\n",
        "                am  = batch[\"attention_mask\"].to(cfg.device)\n",
        "                ef  = batch[\"engineered\"].to(cfg.device)\n",
        "                y   = batch[\"label\"].to(cfg.device)\n",
        "                with torch.amp.autocast(\"cuda\", enabled=(cfg.use_amp and cfg.device==\"cuda\")):\n",
        "                    logits = model(ids, am, ef)\n",
        "                    loss = ce_weighted(logits, y)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(opt); scaler.update(); sched.step()\n",
        "                tot += float(loss.item())\n",
        "            # val\n",
        "            model.eval()\n",
        "            yv, pv = [], []\n",
        "            for batch in tqdm(v, desc=\"eval simple\", leave=False):\n",
        "                ids = batch[\"input_ids\"].to(cfg.device)\n",
        "                am  = batch[\"attention_mask\"].to(cfg.device)\n",
        "                ef  = batch[\"engineered\"].to(cfg.device)\n",
        "                y   = batch[\"label\"].to(cfg.device)\n",
        "                with torch.no_grad(), torch.amp.autocast(\"cuda\", enabled=(cfg.use_amp and cfg.device==\"cuda\")):\n",
        "                    logits = model(ids, am, ef)\n",
        "                p = logits.argmax(1)\n",
        "                yv.extend(y.cpu().tolist()); pv.extend(p.cpu().tolist())\n",
        "            mv = compute_metrics(yv, pv)\n",
        "            print(f\"[Simple][ep{ep}] loss={tot/max(1,len(tr)):.4f} | val macroF1={mv['macro_f1']:.4f}\")\n",
        "            if mv[\"macro_f1\"] > best:\n",
        "                best, best_state = mv[\"macro_f1\"], model.state_dict()\n",
        "                patience = cfg.patience\n",
        "            else:\n",
        "                patience -= 1\n",
        "                if patience < 0:\n",
        "                    print(\"  ⏹ Early stop (simple).\")\n",
        "                    break\n",
        "        outd = cfg.out_simple\n",
        "        safe_makedirs(outd)\n",
        "        model.load_state_dict(best_state)\n",
        "        torch.save(model.state_dict(), os.path.join(outd, \"fusion_simple.pt\"))\n",
        "        # test\n",
        "        model.eval()\n",
        "        yt, pt = [], []\n",
        "        for batch in tqdm(te, desc=\"test simple\", leave=False):\n",
        "            ids = batch[\"input_ids\"].to(cfg.device)\n",
        "            am  = batch[\"attention_mask\"].to(cfg.device)\n",
        "            ef  = batch[\"engineered\"].to(cfg.device)\n",
        "            y   = batch[\"label\"].to(cfg.device)\n",
        "            with torch.no_grad(), torch.amp.autocast(\"cuda\", enabled=(cfg.use_amp and cfg.device==\"cuda\")):\n",
        "                logits = model(ids, am, ef)\n",
        "            p = logits.argmax(1)\n",
        "            yt.extend(y.cpu().tolist()); pt.extend(p.cpu().tolist())\n",
        "        mt = compute_metrics(yt, pt)\n",
        "        pd.DataFrame([mt]).to_csv(os.path.join(outd, \"test_metrics.csv\"), index=False)\n",
        "        print(\"[Simple][test]\", mt)\n",
        "\n",
        "    # ------------------------- 3) Gated Fusion -------------------------------------\n",
        "    if mode in (\"all\",\"gated\"):\n",
        "        print(\"\\n=== Train Gated Fusion ===\")\n",
        "        model = GatedFusion(cfg.xlmr_name, feat_dim=cfg.feat_dim, n_classes=2, feat_proj=64).to(cfg.device)\n",
        "        opt = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "        total_steps = len(tr) * cfg.epochs\n",
        "        sched = get_linear_schedule_with_warmup(\n",
        "            opt,\n",
        "            num_warmup_steps=int(cfg.warmup_ratio * total_steps),\n",
        "            num_training_steps=total_steps\n",
        "        )\n",
        "        best, best_state = -1.0, None\n",
        "        patience = cfg.patience\n",
        "        for ep in range(1, cfg.epochs+1):\n",
        "            model.train()\n",
        "            scaler = torch.cuda.amp.GradScaler(enabled=(cfg.use_amp and cfg.device==\"cuda\"))\n",
        "            tot = 0.0\n",
        "            for batch in tqdm(tr, desc=f\"train gated ep{ep}\", leave=False):\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                ids = batch[\"input_ids\"].to(cfg.device)\n",
        "                am  = batch[\"attention_mask\"].to(cfg.device)\n",
        "                ef  = batch[\"engineered\"].to(cfg.device)\n",
        "                y   = batch[\"label\"].to(cfg.device)\n",
        "                with torch.amp.autocast(\"cuda\", enabled=(cfg.use_amp and cfg.device==\"cuda\")):\n",
        "                    logits = model(ids, am, ef)\n",
        "                    loss = ce_weighted(logits, y)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(opt); scaler.update(); sched.step()\n",
        "                tot += float(loss.item())\n",
        "            # val\n",
        "            model.eval()\n",
        "            yv, pv = [], []\n",
        "            for batch in tqdm(v, desc=\"eval gated\", leave=False):\n",
        "                ids = batch[\"input_ids\"].to(cfg.device)\n",
        "                am  = batch[\"attention_mask\"].to(cfg.device)\n",
        "                ef  = batch[\"engineered\"].to(cfg.device)\n",
        "                y   = batch[\"label\"].to(cfg.device)\n",
        "                with torch.no_grad(), torch.amp.autocast(\"cuda\", enabled=(cfg.use_amp and cfg.device==\"cuda\")):\n",
        "                    logits = model(ids, am, ef)\n",
        "                p = logits.argmax(1)\n",
        "                yv.extend(y.cpu().tolist()); pv.extend(p.cpu().tolist())\n",
        "            mv = compute_metrics(yv, pv)\n",
        "            print(f\"[Gated][ep{ep}] loss={tot/max(1,len(tr)):.4f} | val macroF1={mv['macro_f1']:.4f}\")\n",
        "            if mv[\"macro_f1\"] > best:\n",
        "                best, best_state = mv[\"macro_f1\"], model.state_dict()\n",
        "                patience = cfg.patience\n",
        "            else:\n",
        "                patience -= 1\n",
        "                if patience < 0:\n",
        "                    print(\"  ⏹ Early stop (gated).\")\n",
        "                    break\n",
        "        outd = cfg.out_gated\n",
        "        safe_makedirs(outd)\n",
        "        model.load_state_dict(best_state)\n",
        "        torch.save(model.state_dict(), os.path.join(outd, \"fusion_gated.pt\"))\n",
        "        # test\n",
        "        model.eval()\n",
        "        yt, pt = [], []\n",
        "        for batch in tqdm(te, desc=\"test gated\", leave=False):\n",
        "            ids = batch[\"input_ids\"].to(cfg.device)\n",
        "            am  = batch[\"attention_mask\"].to(cfg.device)\n",
        "            ef  = batch[\"engineered\"].to(cfg.device)\n",
        "            y   = batch[\"label\"].to(cfg.device)\n",
        "            with torch.no_grad(), torch.amp.autocast(\"cuda\", enabled=(cfg.use_amp and cfg.device==\"cuda\")):\n",
        "                logits = model(ids, am, ef)\n",
        "            p = logits.argmax(1)\n",
        "            yt.extend(y.cpu().tolist()); pt.extend(p.cpu().tolist())\n",
        "        mt = compute_metrics(yt, pt)\n",
        "        pd.DataFrame([mt]).to_csv(os.path.join(outd, \"test_metrics.csv\"), index=False)\n",
        "        print(\"[Gated][test]\", mt)\n",
        "\n",
        "    # ------------------------- 4) XGBoost (features only) ---------------------------\n",
        "    if mode in (\"all\",\"xgb\"):\n",
        "        print(\"\\n=== Train XGBoost (features-only) ===\")\n",
        "        y_tr = train_df[\"label\"].values.astype(int)\n",
        "        y_v  = val_df[\"label\"].values.astype(int)\n",
        "        y_te = test_df[\"label\"].values.astype(int)\n",
        "        train_xgb(feats_tr, y_tr, feats_v, y_v, feats_te, y_te, cfg.out_xgb)\n",
        "\n",
        "    print(\"\\n✅ Done.\")\n",
        "\n",
        "# --------------------------------- Entry ---------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--mode\", type=str, default=\"all\",\n",
        "                        choices=[\"all\",\"xlmr\",\"simple\",\"gated\",\"xgb\"])\n",
        "    args, _ = parser.parse_known_args()\n",
        "    main(args.mode)\n"
      ],
      "metadata": {
        "id": "nVN-_LgQQsmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ATTACK"
      ],
      "metadata": {
        "id": "decQDJZzdLs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Adversarial evaluation for EMC (12 engineered features), covering:\n",
        "  - Typos (char)\n",
        "  - Synonyms (word)\n",
        "  - Structure (mix)\n",
        "  - Numbers/Units formatting\n",
        "  - Cue removal\n",
        "\n",
        "Evaluates 4 models:\n",
        "  1) XLM-R only (HF directory)\n",
        "  2) Simple Fusion (concat [pooled, feats])\n",
        "  3) Gated Fusion (gated pooled + feats)\n",
        "  4) Features-only XGBoost (optional; skipped if path not given)\n",
        "\n",
        "Outputs:\n",
        "  - CSV with per-attack metrics per model\n",
        "  - \"changed fraction\" per attack\n",
        "  - LaTeX tables (clean & attacked; and feature-masked variant)\n",
        "  - Optional: feature-masked robustness (zeroing numeric features)\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import math\n",
        "import argparse\n",
        "from typing import Tuple, List, Dict, Any\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Torch / HF\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModel,\n",
        "    AutoModelForSequenceClassification,\n",
        ")\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import joblib\n",
        "\n",
        "# NLTK\n",
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "# Optional XGBoost\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    _HAS_XGB = True\n",
        "except Exception:\n",
        "    _HAS_XGB = False\n",
        "\n",
        "# -----------------------------\n",
        "# Utilities\n",
        "# -----------------------------\n",
        "\n",
        "def seed_everything(seed=13):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# -----------------------------\n",
        "# Text helpers & engineered features\n",
        "# -----------------------------\n",
        "\n",
        "_HAS_TEXTSTAT = False\n",
        "try:\n",
        "    import textstat\n",
        "    _HAS_TEXTSTAT = True\n",
        "except Exception:\n",
        "    _HAS_TEXTSTAT = False\n",
        "\n",
        "STD_TERMS = {\"iso\", \"asme\", \"ieee\", \"din\", \"ansi\", \"iec\", \"ul\", \"astm\", \"en\"}\n",
        "SAFETY_TERMS = {\"safety\", \"hazard\", \"warning\", \"risk\", \"caution\", \"danger\", \"emergency\"}\n",
        "\n",
        "_WORD_RE = re.compile(r\"\\w+\", re.UNICODE)\n",
        "_NUM_RE = re.compile(r\"[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?\")\n",
        "\n",
        "\n",
        "def simple_words(text: str) -> List[str]:\n",
        "    return _WORD_RE.findall(text or \"\")\n",
        "\n",
        "\n",
        "def sent_count(text: str) -> int:\n",
        "    if not text:\n",
        "        return 0\n",
        "    return max(1, len(re.split(r'[.!?]+[\\s\\n]+', text)))\n",
        "\n",
        "\n",
        "def punct_count(text: str) -> int:\n",
        "    return sum(1 for ch in (text or \"\") if ch in \".,;:!?\")\n",
        "\n",
        "\n",
        "class TermsLexicon:\n",
        "    def __init__(self, csv_path: str, term_col=\"terms\", lang_col=\"lang\"):\n",
        "        if not os.path.exists(csv_path):\n",
        "            raise FileNotFoundError(f\"Terms CSV not found: {csv_path}\")\n",
        "        df = pd.read_csv(csv_path)\n",
        "        if term_col not in df.columns:\n",
        "            raise ValueError(f\"Expected column '{term_col}' in {csv_path}\")\n",
        "        if lang_col not in df.columns:\n",
        "            df[lang_col] = 'en'\n",
        "        self.by_lang = {}\n",
        "        for lg, sub in df.groupby(lang_col):\n",
        "            terms = set(str(t).strip().lower() for t in sub[term_col].dropna().tolist() if str(t).strip())\n",
        "            self.by_lang[str(lg).lower()] = terms\n",
        "\n",
        "    def pct_in_text(self, text: str, lang: str) -> float:\n",
        "        if not text:\n",
        "            return 0.0\n",
        "        lg = (lang or \"en\").lower()\n",
        "        terms = self.by_lang.get(lg, set())\n",
        "        if not terms:\n",
        "            return 0.0\n",
        "        ws = [w.lower() for w in simple_words(text)]\n",
        "        if not ws:\n",
        "            return 0.0\n",
        "        hits = sum(1 for w in ws if w in terms)\n",
        "        return hits / max(1, len(ws))\n",
        "\n",
        "\n",
        "def extract_numbers(text: str):\n",
        "    nums = []\n",
        "    dec_count = 0\n",
        "    for m in _NUM_RE.finditer(text or \"\"):\n",
        "        s = m.group(0)\n",
        "        try:\n",
        "            v = float(s)\n",
        "            if ('.' in s) or ('e' in s.lower()):\n",
        "                dec_count += 1\n",
        "            nums.append(abs(v))\n",
        "        except Exception:\n",
        "            pass\n",
        "    return nums, dec_count\n",
        "\n",
        "\n",
        "def _finite_or_zero(x: float) -> float:\n",
        "    return float(x) if np.isfinite(x) else 0.0\n",
        "\n",
        "\n",
        "class FeatureExtractor12:\n",
        "    \"\"\"12-feature extractor with robust clipping & finite guards.\"\"\"\n",
        "    MAX_CHARS      = 200_000\n",
        "    MAX_WORDS      = 40_000\n",
        "    MAX_SENTS      = 10_000\n",
        "    MAX_PUNCT      = 50_000\n",
        "    MAX_NUM_COUNT  = 10_000\n",
        "    MAX_NUM_ABS    = 1e12\n",
        "    MAX_AVG_MAG    = 1e12\n",
        "\n",
        "    def __init__(self, terms_lex: TermsLexicon):\n",
        "        self.tlex = terms_lex\n",
        "\n",
        "    def extract_one(self, text: str, lang: str) -> np.ndarray:\n",
        "        text = \"\" if text is None else str(text)\n",
        "        lang = (lang or \"en\").lower()\n",
        "        ws = simple_words(text)\n",
        "        n_words = len(ws)\n",
        "\n",
        "        chars = min(len(text), self.MAX_CHARS)\n",
        "        words = min(n_words, self.MAX_WORDS)\n",
        "        sents = min(sent_count(text), self.MAX_SENTS)\n",
        "\n",
        "        if lang == \"en\" and _HAS_TEXTSTAT and text.strip():\n",
        "            try:\n",
        "                fre = _finite_or_zero(textstat.flesch_reading_ease(text))\n",
        "                fog = _finite_or_zero(textstat.gunning_fog(text))\n",
        "            except Exception:\n",
        "                fre, fog = 0.0, 0.0\n",
        "        else:\n",
        "            fre, fog = 0.0, 0.0\n",
        "\n",
        "        eng_pct = self.tlex.pct_in_text(text, lang)\n",
        "        punc    = min(punct_count(text), self.MAX_PUNCT)\n",
        "\n",
        "        nums, dec_cnt = extract_numbers(text)\n",
        "        nnums = min(len(nums), self.MAX_NUM_COUNT)\n",
        "        if len(nums) > 0:\n",
        "            nums_clipped = [min(v, self.MAX_NUM_ABS) for v in nums]\n",
        "            avg_mag = float(np.mean(nums_clipped))\n",
        "            if not np.isfinite(avg_mag):\n",
        "                avg_mag = 0.0\n",
        "            avg_mag = min(avg_mag, self.MAX_AVG_MAG)\n",
        "        else:\n",
        "            avg_mag = 0.0\n",
        "        dec_ratio = float(dec_cnt / len(nums)) if len(nums) > 0 else 0.0\n",
        "        if not np.isfinite(dec_ratio):\n",
        "            dec_ratio = 0.0\n",
        "\n",
        "        has_std = 1.0 if any(t in text.lower() for t in STD_TERMS) else 0.0\n",
        "        has_saf = 1.0 if any(t in text.lower() for t in SAFETY_TERMS) else 0.0\n",
        "\n",
        "        feats = np.array([\n",
        "            float(chars),\n",
        "            float(words),\n",
        "            float(sents),\n",
        "            float(fre),\n",
        "            float(fog),\n",
        "            float(eng_pct),\n",
        "            float(punc),\n",
        "            float(nnums),\n",
        "            float(has_std),\n",
        "            float(has_saf),\n",
        "            float(avg_mag),\n",
        "            float(dec_ratio),\n",
        "        ], dtype=np.float32)\n",
        "\n",
        "        if not np.all(np.isfinite(feats)):\n",
        "            feats = np.nan_to_num(feats, nan=0.0, posinf=self.MAX_AVG_MAG, neginf=0.0).astype(np.float32)\n",
        "        return feats\n",
        "\n",
        "    def extract_df(self, df: pd.DataFrame) -> np.ndarray:\n",
        "        out = []\n",
        "        for _, r in tqdm(df.iterrows(), total=len(df), desc=\"Extracting features (eval)\"):\n",
        "            out.append(self.extract_one(r.get(\"content\", \"\"), r.get(\"lang\", \"en\")))\n",
        "        return np.stack(out, axis=0).astype(np.float32)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Datasets & collate\n",
        "# -----------------------------\n",
        "\n",
        "class TextFeatDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, tokenizer: AutoTokenizer, max_len=256,\n",
        "                 feats: np.ndarray = None, labels: np.ndarray = None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tok = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.feats = feats\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        row = self.df.iloc[i]\n",
        "        text = str(row.get('content', ''))\n",
        "        enc = self.tok(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding=False,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors=None,\n",
        "        )\n",
        "        item = {\n",
        "            'input_ids': torch.tensor(enc['input_ids'], dtype=torch.long),\n",
        "            'attention_mask': torch.tensor(enc['attention_mask'], dtype=torch.long),\n",
        "        }\n",
        "        if self.feats is not None:\n",
        "            item['feats'] = torch.tensor(self.feats[i], dtype=torch.float32)\n",
        "        if self.labels is not None:\n",
        "            item['labels'] = int(row['label'])\n",
        "        return item\n",
        "\n",
        "\n",
        "def collate_batch(batch: List[Dict[str, Any]]):\n",
        "    input_ids = [b['input_ids'] for b in batch]\n",
        "    attn = [b['attention_mask'] for b in batch]\n",
        "    input_ids = nn.utils.rnn.pad_sequence(input_ids, batch_first=True, padding_value=1)\n",
        "    attn = nn.utils.rnn.pad_sequence(attn, batch_first=True, padding_value=0)\n",
        "    out = {'input_ids': input_ids, 'attention_mask': attn}\n",
        "\n",
        "    if 'feats' in batch[0]:\n",
        "        feats = torch.stack([b['feats'] for b in batch], dim=0)\n",
        "        out['feats'] = feats\n",
        "    if 'labels' in batch[0]:\n",
        "        labels = torch.tensor([b['labels'] for b in batch], dtype=torch.long)\n",
        "        out['labels'] = labels\n",
        "    return out\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Models (pooling via masked mean)\n",
        "# -----------------------------\n",
        "\n",
        "def masked_mean_pool(last_hidden_state: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
        "    mask = attention_mask.unsqueeze(-1).float()\n",
        "    summed = (last_hidden_state * mask).sum(dim=1)\n",
        "    denom = mask.sum(dim=1).clamp(min=1e-6)\n",
        "    return summed / denom\n",
        "\n",
        "\n",
        "class SimpleFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + n_feats, n_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        pooled = masked_mean_pool(out.last_hidden_state, attention_mask)\n",
        "        fused = torch.cat([pooled, feats], dim=1)\n",
        "        logits = self.classifier(self.dropout(fused))\n",
        "        return logits\n",
        "\n",
        "\n",
        "class GatedFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2, feat_proj: int = 64):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.fe_proj = nn.Sequential(\n",
        "            nn.Linear(n_feats, feat_proj),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(H + n_feats, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + feat_proj, n_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        pooled = masked_mean_pool(out.last_hidden_state, attention_mask)\n",
        "        alpha = self.gate(torch.cat([pooled, feats], dim=1))\n",
        "        ef = self.fe_proj(feats)\n",
        "        fused = torch.cat([pooled, alpha * ef], dim=1)\n",
        "        logits = self.classifier(self.dropout(fused))\n",
        "        return logits\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Robust loader for fusion .pt checkpoints\n",
        "# -----------------------------\n",
        "\n",
        "def load_fusion_from_pt(model: nn.Module, pt_path: str) -> Tuple[int, int]:\n",
        "    sd = torch.load(pt_path, map_location=\"cpu\")\n",
        "    if isinstance(sd, dict) and 'state_dict' in sd:\n",
        "        sd = sd['state_dict']\n",
        "\n",
        "    missing, unexpected = model.load_state_dict(sd, strict=False)\n",
        "    if len(missing) == 0 and len(unexpected) == 0:\n",
        "        return (len(sd), 0)\n",
        "\n",
        "    def remap(keys_map: Dict[str, str], src: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
        "        out = {}\n",
        "        for k, v in src.items():\n",
        "            nk = k\n",
        "            for a, b in keys_map.items():\n",
        "                if k.startswith(a):\n",
        "                    nk = b + k[len(a):]\n",
        "                    break\n",
        "            out[nk] = v\n",
        "        return out\n",
        "\n",
        "    candidates = [\n",
        "        {'encoder.': 'encoder.'}, {'backbone.': 'encoder.'},\n",
        "        {'roberta.': 'encoder.'}, {'xlm_roberta.': 'encoder.'},\n",
        "        {'transformer.': 'encoder.'},\n",
        "    ]\n",
        "    for mp in candidates:\n",
        "        trial = remap(mp, sd)\n",
        "        missing, unexpected = model.load_state_dict(trial, strict=False)\n",
        "        if len(unexpected) == 0:\n",
        "            return (len(sd), len(missing))\n",
        "\n",
        "    model_sd = model.state_dict()\n",
        "    filtered = {k: v for k, v in sd.items() if k in model_sd and model_sd[k].shape == v.shape}\n",
        "    model_sd.update(filtered)\n",
        "    model.load_state_dict(model_sd, strict=False)\n",
        "    return (len(filtered), len(model_sd) - len(filtered))\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Attacks\n",
        "# -----------------------------\n",
        "\n",
        "def attack_typos(text: str, rate: float = 0.06) -> str:\n",
        "    \"\"\"Random char-level typos: delete/insert/swap.\"\"\"\n",
        "    if not text:\n",
        "        return text\n",
        "    rng = np.random.default_rng(123)\n",
        "    chars = list(text)\n",
        "\n",
        "    try:\n",
        "        n = max(1, int(len(chars) * rate))\n",
        "    except ValueError:\n",
        "        # If text contains a non-numeric character in a way that breaks int(),\n",
        "        # default to making no changes to avoid a crash.\n",
        "        return text\n",
        "\n",
        "    for _ in range(n):\n",
        "        if not chars:\n",
        "            break\n",
        "        op = rng.integers(0, 3)\n",
        "        i = int(rng.integers(0, len(chars)))\n",
        "        if op == 0 and len(chars) > 1:\n",
        "            j = int(rng.integers(0, len(chars)))\n",
        "            chars[i], chars[j] = chars[j], chars[i]\n",
        "        elif op == 1:\n",
        "            del chars[i]\n",
        "        else:\n",
        "            c = chr(int(rng.integers(97, 123)))\n",
        "            chars.insert(i, c)\n",
        "    return ''.join(chars)\n",
        "\n",
        "\n",
        "def attack_synonyms(text: str, lang: str = 'en', p: float = 0.15) -> str:\n",
        "    if not text:\n",
        "        return text\n",
        "    if lang != 'en':\n",
        "        return text\n",
        "    try:\n",
        "        tokens = text.split()\n",
        "        rng = np.random.default_rng(123)\n",
        "        idxs = [i for i, w in enumerate(tokens) if w.isalpha()]\n",
        "        rng.shuffle(idxs)\n",
        "        k = max(1, int(len(tokens) * p))\n",
        "        replaced = 0\n",
        "        for i in idxs:\n",
        "            w = tokens[i]\n",
        "            syns = set()\n",
        "            for syn in wn.synsets(w):\n",
        "                for l in syn.lemmas():\n",
        "                    s = l.name().replace('_', ' ')\n",
        "                    if s.lower() != w.lower():\n",
        "                        syns.add(s)\n",
        "            if syns:\n",
        "                tokens[i] = sorted(syns, key=len)[0]\n",
        "                replaced += 1\n",
        "            if replaced >= k:\n",
        "                break\n",
        "        return ' '.join(tokens)\n",
        "    except Exception:\n",
        "        return text\n",
        "\n",
        "\n",
        "def attack_structure(text: str) -> str:\n",
        "    if not text:\n",
        "        return text\n",
        "    rng = np.random.default_rng(123)\n",
        "    out = []\n",
        "    for ch in text:\n",
        "        out.append(ch)\n",
        "        if ch.isalpha() and rng.random() < 0.08:\n",
        "            out.append('\\u200b')\n",
        "        if ch == ' ' and rng.random() < 0.2:\n",
        "            out.append(' ')\n",
        "    return ''.join(out)\n",
        "\n",
        "\n",
        "def _format_number_token(tok: str) -> str:\n",
        "    try:\n",
        "        if '.' in tok or 'e' in tok.lower():\n",
        "            v = float(tok)\n",
        "            return f\"{v:.3f}\"\n",
        "        else:\n",
        "            n = int(tok)\n",
        "            return f\"{n:,}\"\n",
        "    except Exception:\n",
        "        return tok\n",
        "\n",
        "\n",
        "def attack_numbers(text: str) -> str:\n",
        "    if not text:\n",
        "        return text\n",
        "    def repl(m):\n",
        "        return _format_number_token(m.group(0))\n",
        "    return _NUM_RE.sub(repl, text)\n",
        "\n",
        "\n",
        "def attack_cue_removal(text: str) -> str:\n",
        "    if not text:\n",
        "        return text\n",
        "    t = re.sub(r\"[#*_`>-]+\", \" \", text)\n",
        "    t = re.sub(r\"\\b(introduction|abstract|conclusion|overview|table of contents)\\b\", \" \", t, flags=re.I)\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "    return t\n",
        "\n",
        "\n",
        "ATTACKS = [\n",
        "    (\"Typos (char)\", attack_typos),\n",
        "    (\"Synonyms (word)\", attack_synonyms),\n",
        "    (\"Structure (mix)\", lambda t, lang='en': attack_structure(t)),\n",
        "    (\"Numbers/Units\", lambda t, lang='en': attack_numbers(t)),\n",
        "    (\"Cue Removal\", lambda t, lang='en': attack_cue_removal(t)),\n",
        "]\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Prediction wrappers\n",
        "# -----------------------------\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_xlmr(hf_dir: str, df: pd.DataFrame, tok: AutoTokenizer, batch=32, max_len=256) -> np.ndarray:\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(hf_dir).to(DEVICE).eval()\n",
        "    ds = TextFeatDataset(df, tok, max_len=max_len, feats=None, labels=None)\n",
        "    dl = DataLoader(ds, batch_size=batch, shuffle=False, collate_fn=collate_batch)\n",
        "    preds = []\n",
        "    for b in dl:\n",
        "        inp = {k: v.to(DEVICE) for k, v in b.items() if k in (\"input_ids\", \"attention_mask\")}\n",
        "        with torch.amp.autocast(\"cuda\", enabled=(DEVICE == \"cuda\")):\n",
        "            out = model(**inp)\n",
        "            logits = out.logits\n",
        "        p = logits.argmax(1)\n",
        "        preds.extend(p.cpu().tolist())\n",
        "    return np.array(preds, dtype=int)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_fusion(args, pt_path: str, scaler_pkl: str, df: pd.DataFrame, tok: AutoTokenizer,\n",
        "                   kind: str, batch=32, max_len=256, model_name='xlm-roberta-base',\n",
        "                   mask_numeric: bool = False) -> np.ndarray:\n",
        "    terms_lex = TermsLexicon(args.terms_csv)\n",
        "    fe = FeatureExtractor12(terms_lex)\n",
        "    feats = fe.extract_df(df)\n",
        "    if mask_numeric:\n",
        "        feats[:, [7, 10, 11]] = 0.0\n",
        "\n",
        "    scaler: StandardScaler = joblib.load(scaler_pkl)\n",
        "    feats = scaler.transform(feats).astype(np.float32)\n",
        "    n_feats = 12\n",
        "\n",
        "    if kind == 'simple':\n",
        "        model = SimpleFusion(model_name, n_feats).to(DEVICE).eval()\n",
        "    else:  # 'gated'\n",
        "        model = GatedFusion(model_name, n_feats, feat_proj=64).to(DEVICE).eval()\n",
        "\n",
        "    _loaded, _missing = load_fusion_from_pt(model, pt_path)\n",
        "\n",
        "    ds = TextFeatDataset(df, tok, max_len=max_len, feats=feats, labels=None)\n",
        "    dl = DataLoader(ds, batch_size=batch, shuffle=False, collate_fn=collate_batch)\n",
        "\n",
        "    preds = []\n",
        "    for b in dl:\n",
        "        inp = {\n",
        "            'input_ids': b['input_ids'].to(DEVICE),\n",
        "            'attention_mask': b['attention_mask'].to(DEVICE),\n",
        "            'feats': b['feats'].to(DEVICE),\n",
        "        }\n",
        "        with torch.amp.autocast(\"cuda\", enabled=(DEVICE == \"cuda\")):\n",
        "            logits = model(**inp)\n",
        "        p = logits.argmax(1)\n",
        "        preds.extend(p.cpu().tolist())\n",
        "    return np.array(preds, dtype=int)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Metrics & tables\n",
        "# -----------------------------\n",
        "\n",
        "def f1_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:\n",
        "    return {\n",
        "        'macro_f1': f1_score(y_true, y_pred, average='macro'),\n",
        "        'micro_f1': f1_score(y_true, y_pred, average='micro'),\n",
        "        'weighted_f1': f1_score(y_true, y_pred, average='weighted'),\n",
        "        'accuracy': accuracy_score(y_true, y_pred),\n",
        "    }\n",
        "\n",
        "\n",
        "def to_latex_table(df: pd.DataFrame, path: str):\n",
        "    cols = [c for c in df.columns]\n",
        "    with open(path, 'w') as f:\n",
        "        f.write(\"\\\\begin{tabular}{l\" + \"c\" * (len(cols) - 1) + \"}\\n\\\\toprule\\n\")\n",
        "        f.write(\" \".join([cols[0]] + [\"& \" + c for c in cols[1:]]) + \" \\\\\\n\")\n",
        "        f.write(\"\\\\midrule\\n\")\n",
        "        for _, r in df.iterrows():\n",
        "            row = [str(r[c]) for c in cols]\n",
        "            f.write(\" \".join([row[0]] + [\"& \" + x for x in row[1:]]) + \" \\\\\\n\")\n",
        "        f.write(\"\\\\bottomrule\\n\\\\end{tabular}\\n\")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Main\n",
        "# -----------------------------\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--base_dir', type=str, default='/content/drive/MyDrive/emc')\n",
        "    parser.add_argument('--test_csv', type=str, default='/content/drive/MyDrive/emc/test.csv')\n",
        "    parser.add_argument('--terms_csv', type=str, default='/content/drive/MyDrive/emc/engineering_terms.csv')\n",
        "    parser.add_argument('--xlmr_dir', type=str, default='/content/drive/MyDrive/emc/xlmr_only_outputs/best_model')\n",
        "    parser.add_argument('--simple_pt', type=str, default='/content/drive/MyDrive/emc/simple_fusion_outputs/fusion_simple.pt')\n",
        "    parser.add_argument('--simple_scaler', type=str, default='/content/drive/MyDrive/emc/simple_fusion_outputs/scaler12.pkl')\n",
        "    parser.add_argument('--gated_pt', type=str, default='/content/drive/MyDrive/emc/gated_fusion_outputs/fusion_gated.pt')\n",
        "    parser.add_argument('--gated_scaler', type=str, default='/content/drive/MyDrive/emc/gated_fusion_outputs/scaler12.pkl')\n",
        "    parser.add_argument('--xgb_json', type=str, default=None)\n",
        "    parser.add_argument('--out_dir', type=str, default='/content/drive/MyDrive/emc/adv_eval_outputs')\n",
        "    parser.add_argument('--max_len', type=int, default=256)\n",
        "    parser.add_argument('--batch', type=int, default=32)\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    os.makedirs(args.out_dir, exist_ok=True)\n",
        "    seed_everything(13)\n",
        "    print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "    df_test = pd.read_csv(args.test_csv)\n",
        "    assert {'content', 'label'}.issubset(df_test.columns), \"test CSV must have 'content' and 'label'\"\n",
        "    if 'lang' not in df_test.columns:\n",
        "        df_test['lang'] = 'en'\n",
        "    y_true = df_test['label'].astype(int).values\n",
        "    tok = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
        "\n",
        "    print(\"\\n=== Clean evaluation ===\")\n",
        "    y_xlmr = predict_xlmr(args.xlmr_dir, df_test, tok, batch=args.batch, max_len=args.max_len)\n",
        "    m_xlmr = f1_metrics(y_true, y_xlmr)\n",
        "    print(\"[XLM-R]\", m_xlmr)\n",
        "\n",
        "    y_simple = predict_fusion(args=args, pt_path=args.simple_pt, scaler_pkl=args.simple_scaler, df=df_test, tok=tok, kind='simple', batch=args.batch, max_len=args.max_len)\n",
        "    m_simple = f1_metrics(y_true, y_simple)\n",
        "    print(\"[Simple]\", m_simple)\n",
        "\n",
        "    y_gated = predict_fusion(args=args, pt_path=args.gated_pt, scaler_pkl=args.gated_scaler, df=df_test, tok=tok, kind='gated', batch=args.batch, max_len=args.max_len)\n",
        "    m_gated = f1_metrics(y_true, y_gated)\n",
        "    print(\"[Gated ]\", m_gated)\n",
        "\n",
        "    m_xgb = None\n",
        "    if _HAS_XGB and args.xgb_json and os.path.exists(args.xgb_json):\n",
        "        terms_lex = TermsLexicon(args.terms_csv)\n",
        "        fe = FeatureExtractor12(terms_lex)\n",
        "        X = fe.extract_df(df_test)\n",
        "        clf = xgb.XGBClassifier()\n",
        "        clf.load_model(args.xgb_json)\n",
        "        prob = clf.predict_proba(X)\n",
        "        y_xgb = np.argmax(prob, axis=1)\n",
        "        m_xgb = f1_metrics(y_true, y_xgb)\n",
        "        print(\"[XGB  ]\", m_xgb)\n",
        "\n",
        "    clean_df = pd.DataFrame([\n",
        "        ['Clean', 'XLM-R Only', m_xlmr['macro_f1'], m_xlmr['micro_f1'], m_xlmr['weighted_f1'], m_xlmr['accuracy']],\n",
        "        ['Clean', 'Simple Fusion', m_simple['macro_f1'], m_simple['micro_f1'], m_simple['weighted_f1'], m_simple['accuracy']],\n",
        "        ['Clean', 'Gated Fusion', m_gated['macro_f1'], m_gated['micro_f1'], m_gated['weighted_f1'], m_gated['accuracy']],\n",
        "    ], columns=['Attack', 'Model', 'macro_f1', 'micro_f1', 'weighted_f1', 'accuracy'])\n",
        "    if m_xgb is not None:\n",
        "        clean_df.loc[len(clean_df)] = ['Clean', 'XGBoost (features only)', m_xgb['macro_f1'], m_xgb['micro_f1'], m_xgb['weighted_f1'], m_xgb['accuracy']]\n",
        "\n",
        "    rows = []\n",
        "    rows_mask = []\n",
        "    changed_stats = []\n",
        "\n",
        "    for name, fn in ATTACKS:\n",
        "        print(f\"\\n=== Generating attack: {name} ===\")\n",
        "        adv_texts = []\n",
        "        changed = 0\n",
        "        for _, r in tqdm(df_test.iterrows(), total=len(df_test)):\n",
        "            t = str(r['content'])\n",
        "            lang = r.get('lang', 'en')\n",
        "            adv = fn(t, lang) if fn.__code__.co_argcount >= 2 else fn(t)\n",
        "            adv_texts.append(adv)\n",
        "            if adv != t:\n",
        "                changed += 1\n",
        "        frac = changed / len(df_test)\n",
        "        print(f\"[{name}] Changed fraction: {frac:.3f}\")\n",
        "        changed_stats.append({'Attack': name, 'changed_fraction': frac})\n",
        "\n",
        "        df_adv = df_test.copy()\n",
        "        df_adv['content'] = adv_texts\n",
        "\n",
        "        y_x = predict_xlmr(args.xlmr_dir, df_adv, tok, batch=args.batch, max_len=args.max_len)\n",
        "        y_s = predict_fusion(args=args, pt_path=args.simple_pt, scaler_pkl=args.simple_scaler, df=df_adv, tok=tok, kind='simple', batch=args.batch, max_len=args.max_len)\n",
        "        y_g = predict_fusion(args=args, pt_path=args.gated_pt, scaler_pkl=args.gated_scaler, df=df_adv, tok=tok, kind='gated', batch=args.batch, max_len=args.max_len)\n",
        "\n",
        "        mx = f1_metrics(y_true, y_x)\n",
        "        ms = f1_metrics(y_true, y_s)\n",
        "        mg = f1_metrics(y_true, y_g)\n",
        "\n",
        "        rows.append([name, 'XLM-R Only', mx['macro_f1'], mx['micro_f1'], mx['weighted_f1'], mx['accuracy']])\n",
        "        rows.append([name, 'Simple Fusion', ms['macro_f1'], ms['micro_f1'], ms['weighted_f1'], ms['accuracy']])\n",
        "        rows.append([name, 'Gated Fusion', mg['macro_f1'], mg['micro_f1'], mg['weighted_f1'], mg['accuracy']])\n",
        "\n",
        "        y_s_m = predict_fusion(args=args, pt_path=args.simple_pt, scaler_pkl=args.simple_scaler, df=df_adv, tok=tok, kind='simple', batch=args.batch, max_len=args.max_len, mask_numeric=True)\n",
        "        y_g_m = predict_fusion(args=args, pt_path=args.gated_pt, scaler_pkl=args.gated_scaler, df=df_adv, tok=tok, kind='gated', batch=args.batch, max_len=args.max_len, mask_numeric=True)\n",
        "        ms_m = f1_metrics(y_true, y_s_m)\n",
        "        mg_m = f1_metrics(y_true, y_g_m)\n",
        "        rows_mask.append([name, 'Simple Fusion (mask)', ms_m['macro_f1'], ms_m['micro_f1'], ms_m['weighted_f1'], ms_m['accuracy']])\n",
        "        rows_mask.append([name, 'Gated Fusion (mask)', mg_m['macro_f1'], mg_m['micro_f1'], mg_m['weighted_f1'], mg_m['accuracy']])\n",
        "\n",
        "    adv_df = pd.DataFrame(rows, columns=['Attack', 'Model', 'macro_f1', 'micro_f1', 'weighted_f1', 'accuracy'])\n",
        "    adv_mask_df = pd.DataFrame(rows_mask, columns=['Attack', 'Model', 'macro_f1', 'micro_f1', 'weighted_f1', 'accuracy'])\n",
        "    changes_df = pd.DataFrame(changed_stats)\n",
        "\n",
        "    clean_path = os.path.join(args.out_dir, 'clean_eval.csv')\n",
        "    adv_path = os.path.join(args.out_dir, 'adversarial_eval.csv')\n",
        "    adv_mask_path = os.path.join(args.out_dir, 'adversarial_eval_feature_masked.csv')\n",
        "    changes_path = os.path.join(args.out_dir, 'attack_changed_fraction.csv')\n",
        "\n",
        "    clean_df.to_csv(clean_path, index=False)\n",
        "    adv_df.to_csv(adv_path, index=False)\n",
        "    adv_mask_df.to_csv(adv_mask_path, index=False)\n",
        "    changes_df.to_csv(changes_path, index=False)\n",
        "\n",
        "    def pick_metric(df, model_name, attack_name):\n",
        "        return float(df[(df['Model'] == model_name) & (df['Attack'] == attack_name)]['macro_f1'].iloc[0])\n",
        "\n",
        "    base_x = m_xlmr['macro_f1']\n",
        "    base_s = m_simple['macro_f1']\n",
        "    base_g = m_gated['macro_f1']\n",
        "\n",
        "    drop_rows = []\n",
        "    attacks = [n for n, _ in ATTACKS]\n",
        "    for a in attacks:\n",
        "        dx = base_x - pick_metric(adv_df, 'XLM-R Only', a)\n",
        "        ds = base_s - pick_metric(adv_df, 'Simple Fusion', a)\n",
        "        dg = base_g - pick_metric(adv_df, 'Gated Fusion', a)\n",
        "        drop_rows.append([a, dx, ds, dg])\n",
        "\n",
        "    drop_df = pd.DataFrame(drop_rows, columns=['Attack', 'Drop_XLMR', 'Drop_Simple', 'Drop_Gated'])\n",
        "    drop_path = os.path.join(args.out_dir, 'macroF1_drop_vs_clean.csv')\n",
        "    drop_df.to_csv(drop_path, index=False)\n",
        "\n",
        "    gap_rows = []\n",
        "    for a in attacks:\n",
        "        sm = pick_metric(adv_mask_df, 'Simple Fusion (mask)', a)\n",
        "        gm = pick_metric(adv_mask_df, 'Gated Fusion (mask)', a)\n",
        "        gap_rows.append([a, sm, gm, sm - gm])\n",
        "    gap_df = pd.DataFrame(gap_rows, columns=['Attack', 'Simple(mask)', 'Gated(mask)', 'Simple_minus_Gated'])\n",
        "    gap_path = os.path.join(args.out_dir, 'fusion_masked_gap.csv')\n",
        "    gap_df.to_csv(gap_path, index=False)\n",
        "\n",
        "    def table_for(df: pd.DataFrame, fname: str):\n",
        "        piv = df.pivot(index='Attack', columns='Model', values='macro_f1').reset_index()\n",
        "        piv = piv.fillna('')\n",
        "        for c in piv.columns[1:]:\n",
        "            piv[c] = piv[c].apply(lambda x: f\"{x:.3f}\" if isinstance(x, (int, float, np.floating)) else x)\n",
        "        tex_path = os.path.join(args.out_dir, fname)\n",
        "        to_latex_table(piv, tex_path)\n",
        "        return tex_path\n",
        "\n",
        "    tex_clean = table_for(clean_df, 'table_clean_macroF1.tex')\n",
        "    tex_adv = table_for(adv_df, 'table_attacked_macroF1.tex')\n",
        "    tex_mask = table_for(adv_mask_df, 'table_attacked_macroF1_feature_masked.tex')\n",
        "\n",
        "    summary = {\n",
        "        'clean': m_xlmr | {'model': 'XLM-R Only'},\n",
        "        'clean_simple': m_simple | {'model': 'Simple Fusion'},\n",
        "        'clean_gated': m_gated | {'model': 'Gated Fusion'},\n",
        "        'paths': {\n",
        "            'clean_csv': clean_path,\n",
        "            'adv_csv': adv_path,\n",
        "            'adv_mask_csv': adv_mask_path,\n",
        "            'changes_csv': changes_path,\n",
        "            'drop_csv': drop_path,\n",
        "            'gap_csv': gap_path,\n",
        "            'latex_clean': tex_clean,\n",
        "            'latex_attacked': tex_adv,\n",
        "            'latex_masked': tex_mask,\n",
        "        }\n",
        "    }\n",
        "    with open(os.path.join(args.out_dir, 'summary.json'), 'w') as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "\n",
        "    print(\"\\nSaved:\")\n",
        "    for k, v in summary['paths'].items():\n",
        "        print(f\"  - {k}: {v}\")\n",
        "    print(\"\\n✅ Done.\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        nltk.data.find('corpora/wordnet')\n",
        "    except LookupError:\n",
        "        print(\"Downloading NLTK 'wordnet'...\")\n",
        "        nltk.download('wordnet', quiet=True)\n",
        "    try:\n",
        "        nltk.data.find('corpora/omw-1.4')\n",
        "    except LookupError:\n",
        "        print(\"Downloading NLTK 'omw-1.4'...\")\n",
        "        nltk.download('omw-1.4', quiet=True)\n",
        "    main()"
      ],
      "metadata": {
        "id": "xH_psutVdOIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Adversarial evaluation for EMC (12 engineered features), covering:\n",
        "  - Typos (char)\n",
        "  - Synonyms (word)\n",
        "  - Structure (mix)\n",
        "  - Numbers/Units formatting\n",
        "  - Cue removal\n",
        "  - Numeric Perturbation (NEW)\n",
        "  - Keyword Removal (NEW)\n",
        "  - Unit Conversion (NEW)\n",
        "\n",
        "Evaluates 4 models:\n",
        "  1) XLM-R only (HF directory)\n",
        "  2) Simple Fusion (concat [pooled, feats])\n",
        "  3) Gated Fusion (gated pooled + feats)\n",
        "  4) Features-only XGBoost (optional; skipped if path not given)\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import math\n",
        "import argparse\n",
        "import random\n",
        "from typing import Tuple, List, Dict, Any\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Torch / HF\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModel,\n",
        "    AutoModelForSequenceClassification,\n",
        ")\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import joblib\n",
        "\n",
        "# NLTK\n",
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "# Optional XGBoost\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    _HAS_XGB = True\n",
        "except Exception:\n",
        "    _HAS_XGB = False\n",
        "\n",
        "# -----------------------------\n",
        "# Utilities\n",
        "# -----------------------------\n",
        "\n",
        "def seed_everything(seed=13):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# -----------------------------\n",
        "# Text helpers & engineered features\n",
        "# -----------------------------\n",
        "\n",
        "_HAS_TEXTSTAT = False\n",
        "try:\n",
        "    import textstat\n",
        "    _HAS_TEXTSTAT = True\n",
        "except Exception:\n",
        "    _HAS_TEXTSTAT = False\n",
        "\n",
        "STD_TERMS = {\"iso\", \"asme\", \"ieee\", \"din\", \"ansi\", \"iec\", \"ul\", \"astm\", \"en\"}\n",
        "SAFETY_TERMS = {\"safety\", \"hazard\", \"warning\", \"risk\", \"caution\", \"danger\", \"emergency\"}\n",
        "\n",
        "_WORD_RE = re.compile(r\"\\w+\", re.UNICODE)\n",
        "_NUM_RE = re.compile(r\"[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?\")\n",
        "\n",
        "\n",
        "def simple_words(text: str) -> List[str]:\n",
        "    return _WORD_RE.findall(text or \"\")\n",
        "\n",
        "\n",
        "def sent_count(text: str) -> int:\n",
        "    if not text:\n",
        "        return 0\n",
        "    return max(1, len(re.split(r'[.!?]+[\\s\\n]+', text)))\n",
        "\n",
        "\n",
        "def punct_count(text: str) -> int:\n",
        "    return sum(1 for ch in (text or \"\") if ch in \".,;:!?\")\n",
        "\n",
        "\n",
        "class TermsLexicon:\n",
        "    def __init__(self, csv_path: str, term_col=\"terms\", lang_col=\"lang\"):\n",
        "        if not os.path.exists(csv_path):\n",
        "            raise FileNotFoundError(f\"Terms CSV not found: {csv_path}\")\n",
        "        df = pd.read_csv(csv_path)\n",
        "        if term_col not in df.columns:\n",
        "            raise ValueError(f\"Expected column '{term_col}' in {csv_path}\")\n",
        "        if lang_col not in df.columns:\n",
        "            df[lang_col] = 'en'\n",
        "        self.by_lang = {}\n",
        "        for lg, sub in df.groupby(lang_col):\n",
        "            terms = set(str(t).strip().lower() for t in sub[term_col].dropna().tolist() if str(t).strip())\n",
        "            self.by_lang[str(lg).lower()] = terms\n",
        "\n",
        "    def pct_in_text(self, text: str, lang: str) -> float:\n",
        "        if not text:\n",
        "            return 0.0\n",
        "        lg = (lang or \"en\").lower()\n",
        "        terms = self.by_lang.get(lg, set())\n",
        "        if not terms:\n",
        "            return 0.0\n",
        "        ws = [w.lower() for w in simple_words(text)]\n",
        "        if not ws:\n",
        "            return 0.0\n",
        "        hits = sum(1 for w in ws if w in terms)\n",
        "        return hits / max(1, len(ws))\n",
        "\n",
        "\n",
        "def extract_numbers(text: str):\n",
        "    nums = []\n",
        "    dec_count = 0\n",
        "    for m in _NUM_RE.finditer(text or \"\"):\n",
        "        s = m.group(0)\n",
        "        try:\n",
        "            v = float(s)\n",
        "            if ('.' in s) or ('e' in s.lower()):\n",
        "                dec_count += 1\n",
        "            nums.append(abs(v))\n",
        "        except Exception:\n",
        "            pass\n",
        "    return nums, dec_count\n",
        "\n",
        "\n",
        "def _finite_or_zero(x: float) -> float:\n",
        "    return float(x) if np.isfinite(x) else 0.0\n",
        "\n",
        "\n",
        "class FeatureExtractor12:\n",
        "    \"\"\"12-feature extractor with robust clipping & finite guards.\"\"\"\n",
        "    MAX_CHARS      = 200_000\n",
        "    MAX_WORDS      = 40_000\n",
        "    MAX_SENTS      = 10_000\n",
        "    MAX_PUNCT      = 50_000\n",
        "    MAX_NUM_COUNT  = 10_000\n",
        "    MAX_NUM_ABS    = 1e12\n",
        "    MAX_AVG_MAG    = 1e12\n",
        "\n",
        "    def __init__(self, terms_lex: TermsLexicon):\n",
        "        self.tlex = terms_lex\n",
        "\n",
        "    def extract_one(self, text: str, lang: str) -> np.ndarray:\n",
        "        text = \"\" if text is None else str(text)\n",
        "        lang = (lang or \"en\").lower()\n",
        "        ws = simple_words(text)\n",
        "        n_words = len(ws)\n",
        "\n",
        "        chars = min(len(text), self.MAX_CHARS)\n",
        "        words = min(n_words, self.MAX_WORDS)\n",
        "        sents = min(sent_count(text), self.MAX_SENTS)\n",
        "\n",
        "        if lang == \"en\" and _HAS_TEXTSTAT and text.strip():\n",
        "            try:\n",
        "                fre = _finite_or_zero(textstat.flesch_reading_ease(text))\n",
        "                fog = _finite_or_zero(textstat.gunning_fog(text))\n",
        "            except Exception:\n",
        "                fre, fog = 0.0, 0.0\n",
        "        else:\n",
        "            fre, fog = 0.0, 0.0\n",
        "\n",
        "        eng_pct = self.tlex.pct_in_text(text, lang)\n",
        "        punc    = min(punct_count(text), self.MAX_PUNCT)\n",
        "\n",
        "        nums, dec_cnt = extract_numbers(text)\n",
        "        nnums = min(len(nums), self.MAX_NUM_COUNT)\n",
        "        if len(nums) > 0:\n",
        "            nums_clipped = [min(v, self.MAX_NUM_ABS) for v in nums]\n",
        "            avg_mag = float(np.mean(nums_clipped))\n",
        "            if not np.isfinite(avg_mag):\n",
        "                avg_mag = 0.0\n",
        "            avg_mag = min(avg_mag, self.MAX_AVG_MAG)\n",
        "        else:\n",
        "            avg_mag = 0.0\n",
        "        dec_ratio = float(dec_cnt / len(nums)) if len(nums) > 0 else 0.0\n",
        "        if not np.isfinite(dec_ratio):\n",
        "            dec_ratio = 0.0\n",
        "\n",
        "        has_std = 1.0 if any(t in text.lower() for t in STD_TERMS) else 0.0\n",
        "        has_saf = 1.0 if any(t in text.lower() for t in SAFETY_TERMS) else 0.0\n",
        "\n",
        "        feats = np.array([\n",
        "            float(chars),\n",
        "            float(words),\n",
        "            float(sents),\n",
        "            float(fre),\n",
        "            float(fog),\n",
        "            float(eng_pct),\n",
        "            float(punc),\n",
        "            float(nnums),\n",
        "            float(has_std),\n",
        "            float(has_saf),\n",
        "            float(avg_mag),\n",
        "            float(dec_ratio),\n",
        "        ], dtype=np.float32)\n",
        "\n",
        "        if not np.all(np.isfinite(feats)):\n",
        "            feats = np.nan_to_num(feats, nan=0.0, posinf=self.MAX_AVG_MAG, neginf=0.0).astype(np.float32)\n",
        "        return feats\n",
        "\n",
        "    def extract_df(self, df: pd.DataFrame) -> np.ndarray:\n",
        "        out = []\n",
        "        for _, r in tqdm(df.iterrows(), total=len(df), desc=\"Extracting features (eval)\"):\n",
        "            out.append(self.extract_one(r.get(\"content\", \"\"), r.get(\"lang\", \"en\")))\n",
        "        return np.stack(out, axis=0).astype(np.float32)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Datasets & collate\n",
        "# -----------------------------\n",
        "\n",
        "class TextFeatDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, tokenizer: AutoTokenizer, max_len=256,\n",
        "                 feats: np.ndarray = None, labels: np.ndarray = None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tok = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.feats = feats\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        row = self.df.iloc[i]\n",
        "        text = str(row.get('content', ''))\n",
        "        enc = self.tok(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding=False,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors=None,\n",
        "        )\n",
        "        item = {\n",
        "            'input_ids': torch.tensor(enc['input_ids'], dtype=torch.long),\n",
        "            'attention_mask': torch.tensor(enc['attention_mask'], dtype=torch.long),\n",
        "        }\n",
        "        if self.feats is not None:\n",
        "            item['feats'] = torch.tensor(self.feats[i], dtype=torch.float32)\n",
        "        if self.labels is not None:\n",
        "            item['labels'] = int(row['label'])\n",
        "        return item\n",
        "\n",
        "\n",
        "def collate_batch(batch: List[Dict[str, Any]]):\n",
        "    input_ids = [b['input_ids'] for b in batch]\n",
        "    attn = [b['attention_mask'] for b in batch]\n",
        "    input_ids = nn.utils.rnn.pad_sequence(input_ids, batch_first=True, padding_value=1)\n",
        "    attn = nn.utils.rnn.pad_sequence(attn, batch_first=True, padding_value=0)\n",
        "    out = {'input_ids': input_ids, 'attention_mask': attn}\n",
        "\n",
        "    if 'feats' in batch[0]:\n",
        "        feats = torch.stack([b['feats'] for b in batch], dim=0)\n",
        "        out['feats'] = feats\n",
        "    if 'labels' in batch[0]:\n",
        "        labels = torch.tensor([b['labels'] for b in batch], dtype=torch.long)\n",
        "        out['labels'] = labels\n",
        "    return out\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Models (pooling via masked mean)\n",
        "# -----------------------------\n",
        "\n",
        "def masked_mean_pool(last_hidden_state: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
        "    mask = attention_mask.unsqueeze(-1).float()\n",
        "    summed = (last_hidden_state * mask).sum(dim=1)\n",
        "    denom = mask.sum(dim=1).clamp(min=1e-6)\n",
        "    return summed / denom\n",
        "\n",
        "\n",
        "class SimpleFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + n_feats, n_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        pooled = masked_mean_pool(out.last_hidden_state, attention_mask)\n",
        "        fused = torch.cat([pooled, feats], dim=1)\n",
        "        logits = self.classifier(self.dropout(fused))\n",
        "        return logits\n",
        "\n",
        "\n",
        "class GatedFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2, feat_proj: int = 64):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.fe_proj = nn.Sequential(\n",
        "            nn.Linear(n_feats, feat_proj),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(H + n_feats, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + feat_proj, n_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        pooled = masked_mean_pool(out.last_hidden_state, attention_mask)\n",
        "        alpha = self.gate(torch.cat([pooled, feats], dim=1))\n",
        "        ef = self.fe_proj(feats)\n",
        "        fused = torch.cat([pooled, alpha * ef], dim=1)\n",
        "        logits = self.classifier(self.dropout(fused))\n",
        "        return logits\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Robust loader for fusion .pt checkpoints\n",
        "# -----------------------------\n",
        "\n",
        "def load_fusion_from_pt(model: nn.Module, pt_path: str) -> Tuple[int, int]:\n",
        "    sd = torch.load(pt_path, map_location=\"cpu\")\n",
        "    if isinstance(sd, dict) and 'state_dict' in sd:\n",
        "        sd = sd['state_dict']\n",
        "\n",
        "    missing, unexpected = model.load_state_dict(sd, strict=False)\n",
        "    if len(missing) == 0 and len(unexpected) == 0:\n",
        "        return (len(sd), 0)\n",
        "\n",
        "    def remap(keys_map: Dict[str, str], src: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
        "        out = {}\n",
        "        for k, v in src.items():\n",
        "            nk = k\n",
        "            for a, b in keys_map.items():\n",
        "                if k.startswith(a):\n",
        "                    nk = b + k[len(a):]\n",
        "                    break\n",
        "            out[nk] = v\n",
        "        return out\n",
        "\n",
        "    candidates = [\n",
        "        {'encoder.': 'encoder.'}, {'backbone.': 'encoder.'},\n",
        "        {'roberta.': 'encoder.'}, {'xlm_roberta.': 'encoder.'},\n",
        "        {'transformer.': 'encoder.'},\n",
        "    ]\n",
        "    for mp in candidates:\n",
        "        trial = remap(mp, sd)\n",
        "        missing, unexpected = model.load_state_dict(trial, strict=False)\n",
        "        if len(unexpected) == 0:\n",
        "            return (len(sd), len(missing))\n",
        "\n",
        "    model_sd = model.state_dict()\n",
        "    filtered = {k: v for k, v in sd.items() if k in model_sd and model_sd[k].shape == v.shape}\n",
        "    model_sd.update(filtered)\n",
        "    model.load_state_dict(model_sd, strict=False)\n",
        "    return (len(filtered), len(model_sd) - len(filtered))\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Attacks\n",
        "# -----------------------------\n",
        "\n",
        "def attack_typos(text: str, rate: float = 0.06) -> str:\n",
        "    if not text:\n",
        "        return text\n",
        "    rng = np.random.default_rng(123)\n",
        "    chars = list(text)\n",
        "\n",
        "    try:\n",
        "        n = max(1, int(len(chars) * rate))\n",
        "    except ValueError:\n",
        "        return text\n",
        "\n",
        "    for _ in range(n):\n",
        "        if not chars:\n",
        "            break\n",
        "        op = rng.integers(0, 3)\n",
        "        i = int(rng.integers(0, len(chars)))\n",
        "        if op == 0 and len(chars) > 1:\n",
        "            j = int(rng.integers(0, len(chars)))\n",
        "            chars[i], chars[j] = chars[j], chars[i]\n",
        "        elif op == 1:\n",
        "            del chars[i]\n",
        "        else:\n",
        "            c = chr(int(rng.integers(97, 123)))\n",
        "            chars.insert(i, c)\n",
        "    return ''.join(chars)\n",
        "\n",
        "\n",
        "def attack_synonyms(text: str, lang: str = 'en', p: float = 0.15) -> str:\n",
        "    if not text:\n",
        "        return text\n",
        "    if lang != 'en':\n",
        "        return text\n",
        "    try:\n",
        "        tokens = text.split()\n",
        "        rng = np.random.default_rng(123)\n",
        "        idxs = [i for i, w in enumerate(tokens) if w.isalpha()]\n",
        "        rng.shuffle(idxs)\n",
        "        k = max(1, int(len(tokens) * p))\n",
        "        replaced = 0\n",
        "        for i in idxs:\n",
        "            w = tokens[i]\n",
        "            syns = set()\n",
        "            for syn in wn.synsets(w):\n",
        "                for l in syn.lemmas():\n",
        "                    s = l.name().replace('_', ' ')\n",
        "                    if s.lower() != w.lower():\n",
        "                        syns.add(s)\n",
        "            if syns:\n",
        "                tokens[i] = sorted(syns, key=len)[0]\n",
        "                replaced += 1\n",
        "            if replaced >= k:\n",
        "                break\n",
        "        return ' '.join(tokens)\n",
        "    except Exception:\n",
        "        return text\n",
        "\n",
        "\n",
        "def attack_structure(text: str) -> str:\n",
        "    if not text:\n",
        "        return text\n",
        "    rng = np.random.default_rng(123)\n",
        "    out = []\n",
        "    for ch in text:\n",
        "        out.append(ch)\n",
        "        if ch.isalpha() and rng.random() < 0.08:\n",
        "            out.append('\\u200b')\n",
        "        if ch == ' ' and rng.random() < 0.2:\n",
        "            out.append(' ')\n",
        "    return ''.join(out)\n",
        "\n",
        "\n",
        "def _format_number_token(tok: str) -> str:\n",
        "    try:\n",
        "        if '.' in tok or 'e' in tok.lower():\n",
        "            v = float(tok)\n",
        "            return f\"{v:.3f}\"\n",
        "        else:\n",
        "            n = int(tok)\n",
        "            return f\"{n:,}\"\n",
        "    except Exception:\n",
        "        return tok\n",
        "\n",
        "\n",
        "def attack_numbers(text: str) -> str:\n",
        "    if not text:\n",
        "        return text\n",
        "    def repl(m):\n",
        "        return _format_number_token(m.group(0))\n",
        "    return _NUM_RE.sub(repl, text)\n",
        "\n",
        "\n",
        "def attack_cue_removal(text: str) -> str:\n",
        "    if not text:\n",
        "        return text\n",
        "    t = re.sub(r\"[#*_`>-]+\", \" \", text)\n",
        "    t = re.sub(r\"\\b(introduction|abstract|conclusion|overview|table of contents)\\b\", \" \", t, flags=re.I)\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "    return t\n",
        "\n",
        "\n",
        "def attack_numeric_perturbation(text: str, rate: float = 0.2) -> str:\n",
        "    if not text:\n",
        "        return text\n",
        "    rng = np.random.default_rng(123)\n",
        "    out = text\n",
        "    for m in _NUM_RE.finditer(text):\n",
        "        if rng.random() < rate:\n",
        "            s = m.group(0)\n",
        "            try:\n",
        "                v = float(s)\n",
        "                if rng.random() < 0.5:\n",
        "                    v = v + (rng.random() * 0.1)\n",
        "                else:\n",
        "                    v = round(v * 100) / 100\n",
        "                out = out.replace(s, str(v), 1)\n",
        "            except Exception:\n",
        "                pass\n",
        "    return out\n",
        "\n",
        "\n",
        "def attack_keyword_removal(text: str, keywords: List[str]) -> str:\n",
        "    if not text or not keywords:\n",
        "        return text\n",
        "\n",
        "    out = text\n",
        "    for keyword in keywords:\n",
        "        out = re.sub(r'\\b' + re.escape(keyword) + r'\\b', '', out, flags=re.IGNORECASE)\n",
        "\n",
        "    out = re.sub(r'\\s+', ' ', out).strip()\n",
        "    return out\n",
        "\n",
        "\n",
        "def attack_unit_conversion(text: str) -> str:\n",
        "    if not text:\n",
        "        return text\n",
        "\n",
        "    units = {\n",
        "        'cm': 'mm', 'mm': 'cm',\n",
        "        'm': 'km', 'km': 'm',\n",
        "        'kg': 'g', 'g': 'kg',\n",
        "        'c': 'f', 'f': 'c'\n",
        "    }\n",
        "\n",
        "    out = text\n",
        "    for unit, replacement in units.items():\n",
        "        pattern = r\"(\\d+\\.?\\d*)\\s*(\" + re.escape(unit) + r\")\"\n",
        "        out = re.sub(pattern, lambda m: f\"{float(m.group(1))} {replacement}\", out, flags=re.IGNORECASE)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "ATTACKS = [\n",
        "    (\"Typos (char)\", attack_typos),\n",
        "    (\"Synonyms (word)\", attack_synonyms),\n",
        "    (\"Structure (mix)\", attack_structure),\n",
        "    (\"Numbers/Units\", attack_numbers),\n",
        "    (\"Cue Removal\", attack_cue_removal),\n",
        "    (\"Numeric Perturbation (NEW)\", attack_numeric_perturbation),\n",
        "    (\"Keyword Removal (NEW)\", attack_keyword_removal),\n",
        "    (\"Unit Conversion (NEW)\", attack_unit_conversion)\n",
        "]\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Prediction wrappers\n",
        "# -----------------------------\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_xlmr(hf_dir: str, df: pd.DataFrame, tok: AutoTokenizer, batch=32, max_len=256) -> np.ndarray:\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(hf_dir).to(DEVICE).eval()\n",
        "    ds = TextFeatDataset(df, tok, max_len=max_len, feats=None, labels=None)\n",
        "    dl = DataLoader(ds, batch_size=batch, shuffle=False, collate_fn=collate_batch)\n",
        "    preds = []\n",
        "    for b in dl:\n",
        "        inp = {k: v.to(DEVICE) for k, v in b.items() if k in (\"input_ids\", \"attention_mask\")}\n",
        "        with torch.amp.autocast(\"cuda\", enabled=(DEVICE == \"cuda\")):\n",
        "            out = model(**inp)\n",
        "            logits = out.logits\n",
        "        p = logits.argmax(1)\n",
        "        preds.extend(p.cpu().tolist())\n",
        "    return np.array(preds, dtype=int)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_fusion(args, pt_path: str, scaler_pkl: str, df: pd.DataFrame, tok: AutoTokenizer,\n",
        "                   kind: str, batch=32, max_len=256, model_name='xlm-roberta-base',\n",
        "                   mask_numeric: bool = False) -> np.ndarray:\n",
        "    terms_lex = TermsLexicon(args.terms_csv)\n",
        "    fe = FeatureExtractor12(terms_lex)\n",
        "    feats = fe.extract_df(df)\n",
        "    if mask_numeric:\n",
        "        feats[:, [7, 10, 11]] = 0.0\n",
        "\n",
        "    scaler: StandardScaler = joblib.load(scaler_pkl)\n",
        "    feats = scaler.transform(feats).astype(np.float32)\n",
        "    n_feats = 12\n",
        "\n",
        "    if kind == 'simple':\n",
        "        model = SimpleFusion(model_name, n_feats).to(DEVICE).eval()\n",
        "    else:\n",
        "        model = GatedFusion(model_name, n_feats, feat_proj=64).to(DEVICE).eval()\n",
        "\n",
        "    _loaded, _missing = load_fusion_from_pt(model, pt_path)\n",
        "\n",
        "    ds = TextFeatDataset(df, tok, max_len=max_len, feats=feats, labels=None)\n",
        "    dl = DataLoader(ds, batch_size=batch, shuffle=False, collate_fn=collate_batch)\n",
        "\n",
        "    preds = []\n",
        "    for b in dl:\n",
        "        inp = {\n",
        "            'input_ids': b['input_ids'].to(DEVICE),\n",
        "            'attention_mask': b['attention_mask'].to(DEVICE),\n",
        "            'feats': b['feats'].to(DEVICE),\n",
        "        }\n",
        "        with torch.amp.autocast(\"cuda\", enabled=(DEVICE == \"cuda\")):\n",
        "            logits = model(**inp)\n",
        "        p = logits.argmax(1)\n",
        "        preds.extend(p.cpu().tolist())\n",
        "    return np.array(preds, dtype=int)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Metrics & tables\n",
        "# -----------------------------\n",
        "\n",
        "def f1_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:\n",
        "    return {\n",
        "        'macro_f1': f1_score(y_true, y_pred, average='macro'),\n",
        "        'micro_f1': f1_score(y_true, y_pred, average='micro'),\n",
        "        'weighted_f1': f1_score(y_true, y_pred, average='weighted'),\n",
        "        'accuracy': accuracy_score(y_true, y_pred),\n",
        "    }\n",
        "\n",
        "\n",
        "def to_latex_table(df: pd.DataFrame, path: str):\n",
        "    cols = [c for c in df.columns]\n",
        "    with open(path, 'w') as f:\n",
        "        f.write(\"\\\\begin{tabular}{l\" + \"c\" * (len(cols) - 1) + \"}\\n\\\\toprule\\n\")\n",
        "        f.write(\" \".join([cols[0]] + [\"& \" + c for c in cols[1:]]) + \" \\\\\\n\")\n",
        "        f.write(\"\\\\midrule\\n\")\n",
        "        for _, r in df.iterrows():\n",
        "            row = [str(r[c]) for c in cols]\n",
        "            f.write(\" \".join([row[0]] + [\"& \" + x for x in row[1:]]) + \" \\\\\\n\")\n",
        "        f.write(\"\\\\bottomrule\\n\\\\end{tabular}\\n\")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Main\n",
        "# -----------------------------\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--base_dir', type=str, default='/content/drive/MyDrive/emc')\n",
        "    parser.add_argument('--test_csv', type=str, default='/content/drive/MyDrive/emc/test.csv')\n",
        "    parser.add_argument('--terms_csv', type=str, default='/content/drive/MyDrive/emc/engineering_terms.csv')\n",
        "    parser.add_argument('--xlmr_dir', type=str, default='/content/drive/MyDrive/emc/xlmr_only_outputs/best_model')\n",
        "    parser.add_argument('--simple_pt', type=str, default='/content/drive/MyDrive/emc/simple_fusion_outputs/fusion_simple.pt')\n",
        "    parser.add_argument('--simple_scaler', type=str, default='/content/drive/MyDrive/emc/simple_fusion_outputs/scaler12.pkl')\n",
        "    parser.add_argument('--gated_pt', type=str, default='/content/drive/MyDrive/emc/gated_fusion_outputs/fusion_gated.pt')\n",
        "    parser.add_argument('--gated_scaler', type=str, default='/content/drive/MyDrive/emc/gated_fusion_outputs/scaler12.pkl')\n",
        "    parser.add_argument('--xgb_json', type=str, default=None)\n",
        "    parser.add_argument('--out_dir', type=str, default='/content/drive/MyDrive/emc/adv_eval_outputs')\n",
        "    parser.add_argument('--max_len', type=int, default=256)\n",
        "    parser.add_argument('--batch', type=int, default=32)\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    os.makedirs(args.out_dir, exist_ok=True)\n",
        "    seed_everything(13)\n",
        "    print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "    df_test = pd.read_csv(args.test_csv)\n",
        "    assert {'content', 'label'}.issubset(df_test.columns), \"test CSV must have 'content' and 'label'\"\n",
        "    if 'lang' not in df_test.columns:\n",
        "        df_test['lang'] = 'en'\n",
        "    y_true = df_test['label'].astype(int).values\n",
        "    tok = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
        "\n",
        "    print(\"\\n=== Clean evaluation ===\")\n",
        "    y_xlmr = predict_xlmr(args.xlmr_dir, df_test, tok, batch=args.batch, max_len=args.max_len)\n",
        "    m_xlmr = f1_metrics(y_true, y_xlmr)\n",
        "    print(\"[XLM-R]\", m_xlmr)\n",
        "\n",
        "    y_simple = predict_fusion(args=args, pt_path=args.simple_pt, scaler_pkl=args.simple_scaler, df=df_test, tok=tok, kind='simple', batch=args.batch, max_len=args.max_len)\n",
        "    m_simple = f1_metrics(y_true, y_simple)\n",
        "    print(\"[Simple]\", m_simple)\n",
        "\n",
        "    y_gated = predict_fusion(args=args, pt_path=args.gated_pt, scaler_pkl=args.gated_scaler, df=df_test, tok=tok, kind='gated', batch=args.batch, max_len=args.max_len)\n",
        "    m_gated = f1_metrics(y_true, y_gated)\n",
        "    print(\"[Gated ]\", m_gated)\n",
        "\n",
        "    m_xgb = None\n",
        "    if _HAS_XGB and args.xgb_json and os.path.exists(args.xgb_json):\n",
        "        terms_lex = TermsLexicon(args.terms_csv)\n",
        "        fe = FeatureExtractor12(terms_lex)\n",
        "        X = fe.extract_df(df_test)\n",
        "        clf = xgb.XGBClassifier()\n",
        "        clf.load_model(args.xgb_json)\n",
        "        prob = clf.predict_proba(X)\n",
        "        y_xgb = np.argmax(prob, axis=1)\n",
        "        m_xgb = f1_metrics(y_true, y_xgb)\n",
        "        print(\"[XGB  ]\", m_xgb)\n",
        "\n",
        "    clean_df = pd.DataFrame([\n",
        "        ['Clean', 'XLM-R Only', m_xlmr['macro_f1'], m_xlmr['micro_f1'], m_xlmr['weighted_f1'], m_xlmr['accuracy']],\n",
        "        ['Clean', 'Simple Fusion', m_simple['macro_f1'], m_simple['micro_f1'], m_simple['weighted_f1'], m_simple['accuracy']],\n",
        "        ['Clean', 'Gated Fusion', m_gated['macro_f1'], m_gated['micro_f1'], m_gated['weighted_f1'], m_gated['accuracy']],\n",
        "    ], columns=['Attack', 'Model', 'macro_f1', 'micro_f1', 'weighted_f1', 'accuracy'])\n",
        "    if m_xgb is not None:\n",
        "        clean_df.loc[len(clean_df)] = ['Clean', 'XGBoost (features only)', m_xgb['macro_f1'], m_xgb['micro_f1'], m_xgb['weighted_f1'], m_xgb['accuracy']]\n",
        "\n",
        "    rows = []\n",
        "    rows_mask = []\n",
        "    changed_stats = []\n",
        "\n",
        "    for name, fn in ATTACKS:\n",
        "        print(f\"\\n=== Generating attack: {name} ===\")\n",
        "        adv_texts = []\n",
        "        changed = 0\n",
        "        for _, r in tqdm(df_test.iterrows(), total=len(df_test)):\n",
        "            t = str(r['content'])\n",
        "            lang = r.get('lang', 'en')\n",
        "\n",
        "            if name == \"Keyword Removal (NEW)\":\n",
        "                adv = fn(t, keywords=list(STD_TERMS | SAFETY_TERMS))\n",
        "            elif name == \"Synonyms (word)\":\n",
        "                adv = fn(t, lang)\n",
        "            else:\n",
        "                adv = fn(t)\n",
        "\n",
        "            adv_texts.append(adv)\n",
        "            if adv != t:\n",
        "                changed += 1\n",
        "        frac = changed / len(df_test)\n",
        "        print(f\"[{name}] Changed fraction: {frac:.3f}\")\n",
        "        changed_stats.append({'Attack': name, 'changed_fraction': frac})\n",
        "\n",
        "        df_adv = df_test.copy()\n",
        "        df_adv['content'] = adv_texts\n",
        "\n",
        "        y_x = predict_xlmr(args.xlmr_dir, df_adv, tok, batch=args.batch, max_len=args.max_len)\n",
        "        y_s = predict_fusion(args=args, pt_path=args.simple_pt, scaler_pkl=args.simple_scaler, df=df_adv, tok=tok, kind='simple', batch=args.batch, max_len=args.max_len)\n",
        "        y_g = predict_fusion(args=args, pt_path=args.gated_pt, scaler_pkl=args.gated_scaler, df=df_adv, tok=tok, kind='gated', batch=args.batch, max_len=args.max_len)\n",
        "\n",
        "        mx = f1_metrics(y_true, y_x)\n",
        "        ms = f1_metrics(y_true, y_s)\n",
        "        mg = f1_metrics(y_true, y_g)\n",
        "\n",
        "        rows.append([name, 'XLM-R Only', mx['macro_f1'], mx['micro_f1'], mx['weighted_f1'], mx['accuracy']])\n",
        "        rows.append([name, 'Simple Fusion', ms['macro_f1'], ms['micro_f1'], ms['weighted_f1'], ms['accuracy']])\n",
        "        rows.append([name, 'Gated Fusion', mg['macro_f1'], mg['micro_f1'], mg['weighted_f1'], mg['accuracy']])\n",
        "\n",
        "        y_s_m = predict_fusion(args=args, pt_path=args.simple_pt, scaler_pkl=args.simple_scaler, df=df_adv, tok=tok, kind='simple', batch=args.batch, max_len=args.max_len, mask_numeric=True)\n",
        "        y_g_m = predict_fusion(args=args, pt_path=args.gated_pt, scaler_pkl=args.gated_scaler, df=df_adv, tok=tok, kind='gated', batch=args.batch, max_len=args.max_len, mask_numeric=True)\n",
        "        ms_m = f1_metrics(y_true, y_s_m)\n",
        "        mg_m = f1_metrics(y_true, y_g_m)\n",
        "        rows_mask.append([name, 'Simple Fusion (mask)', ms_m['macro_f1'], ms_m['micro_f1'], ms_m['weighted_f1'], ms_m['accuracy']])\n",
        "        rows_mask.append([name, 'Gated Fusion (mask)', mg_m['macro_f1'], mg_m['micro_f1'], mg_m['weighted_f1'], mg_m['accuracy']])\n",
        "\n",
        "    adv_df = pd.DataFrame(rows, columns=['Attack', 'Model', 'macro_f1', 'micro_f1', 'weighted_f1', 'accuracy'])\n",
        "    adv_mask_df = pd.DataFrame(rows_mask, columns=['Attack', 'Model', 'macro_f1', 'micro_f1', 'weighted_f1', 'accuracy'])\n",
        "    changes_df = pd.DataFrame(changed_stats)\n",
        "\n",
        "    clean_path = os.path.join(args.out_dir, 'clean_eval.csv')\n",
        "    adv_path = os.path.join(args.out_dir, 'adversarial_eval.csv')\n",
        "    adv_mask_path = os.path.join(args.out_dir, 'adversarial_eval_feature_masked.csv')\n",
        "    changes_path = os.path.join(args.out_dir, 'attack_changed_fraction.csv')\n",
        "\n",
        "    clean_df.to_csv(clean_path, index=False)\n",
        "    adv_df.to_csv(adv_path, index=False)\n",
        "    adv_mask_df.to_csv(adv_mask_path, index=False)\n",
        "    changes_df.to_csv(changes_path, index=False)\n",
        "\n",
        "    def pick_metric(df, model_name, attack_name):\n",
        "        return float(df[(df['Model'] == model_name) & (df['Attack'] == attack_name)]['macro_f1'].iloc[0])\n",
        "\n",
        "    base_x = m_xlmr['macro_f1']\n",
        "    base_s = m_simple['macro_f1']\n",
        "    base_g = m_gated['macro_f1']\n",
        "\n",
        "    drop_rows = []\n",
        "    attacks = [n for n, _ in ATTACKS]\n",
        "    for a in attacks:\n",
        "        dx = base_x - pick_metric(adv_df, 'XLM-R Only', a)\n",
        "        ds = base_s - pick_metric(adv_df, 'Simple Fusion', a)\n",
        "        dg = base_g - pick_metric(adv_df, 'Gated Fusion', a)\n",
        "        drop_rows.append([a, dx, ds, dg])\n",
        "\n",
        "    drop_df = pd.DataFrame(drop_rows, columns=['Attack', 'Drop_XLMR', 'Drop_Simple', 'Drop_Gated'])\n",
        "    drop_path = os.path.join(args.out_dir, 'macroF1_drop_vs_clean.csv')\n",
        "    drop_df.to_csv(drop_path, index=False)\n",
        "\n",
        "    gap_rows = []\n",
        "    for a in attacks:\n",
        "        sm = pick_metric(adv_mask_df, 'Simple Fusion (mask)', a)\n",
        "        gm = pick_metric(adv_mask_df, 'Gated Fusion (mask)', a)\n",
        "        gap_rows.append([a, sm, gm, sm - gm])\n",
        "    gap_df = pd.DataFrame(gap_rows, columns=['Attack', 'Simple(mask)', 'Gated(mask)', 'Simple_minus_Gated'])\n",
        "    gap_path = os.path.join(args.out_dir, 'fusion_masked_gap.csv')\n",
        "    gap_df.to_csv(gap_path, index=False)\n",
        "\n",
        "    def table_for(df: pd.DataFrame, fname: str):\n",
        "        piv = df.pivot(index='Attack', columns='Model', values='macro_f1').reset_index()\n",
        "        piv = piv.fillna('')\n",
        "        for c in piv.columns[1:]:\n",
        "            piv[c] = piv[c].apply(lambda x: f\"{x:.3f}\" if isinstance(x, (int, float, np.floating)) else x)\n",
        "        tex_path = os.path.join(args.out_dir, fname)\n",
        "        to_latex_table(piv, tex_path)\n",
        "        return tex_path\n",
        "\n",
        "    tex_clean = table_for(clean_df, 'table_clean_macroF1.tex')\n",
        "    tex_adv = table_for(adv_df, 'table_attacked_macroF1.tex')\n",
        "    tex_mask = table_for(adv_mask_df, 'table_attacked_macroF1_feature_masked.tex')\n",
        "\n",
        "    summary = {\n",
        "        'clean': m_xlmr | {'model': 'XLM-R Only'},\n",
        "        'clean_simple': m_simple | {'model': 'Simple Fusion'},\n",
        "        'clean_gated': m_gated | {'model': 'Gated Fusion'},\n",
        "        'paths': {\n",
        "            'clean_csv': clean_path,\n",
        "            'adv_csv': adv_path,\n",
        "            'adv_mask_csv': adv_mask_path,\n",
        "            'changes_csv': changes_path,\n",
        "            'drop_csv': drop_path,\n",
        "            'gap_csv': gap_path,\n",
        "            'latex_clean': tex_clean,\n",
        "            'latex_attacked': tex_adv,\n",
        "            'latex_masked': tex_mask,\n",
        "        }\n",
        "    }\n",
        "    with open(os.path.join(args.out_dir, 'summary.json'), 'w') as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "\n",
        "    print(\"\\nSaved:\")\n",
        "    for k, v in summary['paths'].items():\n",
        "        print(f\"  - {k}: {v}\")\n",
        "    print(\"\\n✅ Done.\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        nltk.data.find('corpora/wordnet')\n",
        "    except LookupError:\n",
        "        print(\"Downloading NLTK 'wordnet'...\")\n",
        "        nltk.download('wordnet', quiet=True)\n",
        "    try:\n",
        "        nltk.data.find('corpora/omw-1.4')\n",
        "    except LookupError:\n",
        "        print(\"Downloading NLTK 'omw-1.4'...\")\n",
        "        nltk.download('omw-1.4', quiet=True)\n",
        "    main()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rjtUg0nDvfiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def print_combined_results(output_dir):\n",
        "    \"\"\"\n",
        "    Reads clean and adversarial evaluation results, calculates performance drop,\n",
        "    and prints a combined table.\n",
        "    \"\"\"\n",
        "    clean_file = os.path.join(output_dir, 'clean_eval.csv')\n",
        "    adv_file = os.path.join(output_dir, 'adversarial_eval.csv')\n",
        "\n",
        "    # Read dataframes\n",
        "    try:\n",
        "        clean_df = pd.read_csv(clean_file)\n",
        "        adv_df = pd.read_csv(adv_file)\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}. Please ensure the files exist in the specified directory.\")\n",
        "        return\n",
        "\n",
        "    # Pivot clean data to get a baseline score for each model\n",
        "    clean_scores = clean_df.pivot(index='Model', columns='Attack', values='macro_f1')\n",
        "    clean_scores = clean_scores.rename(columns={'Clean': 'Clean Macro F1'})\n",
        "\n",
        "    # Pivot adversarial data to get scores per attack\n",
        "    adv_scores = adv_df.pivot(index='Model', columns='Attack', values='macro_f1')\n",
        "    adv_scores.columns.name = 'Attack'\n",
        "    adv_scores.index.name = 'Model'\n",
        "\n",
        "    # Combine clean and adversarial scores for comparison\n",
        "    combined = pd.concat([clean_scores, adv_scores], axis=1)\n",
        "\n",
        "    # Calculate the performance drop for each attack\n",
        "    for attack in adv_scores.columns:\n",
        "        combined[f'Drop from {attack}'] = combined['Clean Macro F1'] - combined[attack]\n",
        "\n",
        "    # Sort columns for a cleaner output\n",
        "    sorted_cols = ['Clean Macro F1'] + [col for col in combined.columns if col.startswith('Drop')] + [col for col in combined.columns if not (col.startswith('Clean') or col.startswith('Drop'))]\n",
        "    combined = combined[sorted_cols]\n",
        "\n",
        "    # Print the full table\n",
        "    print(\"\\n--- Combined Model Performance and Robustness (Macro F1) ---\")\n",
        "    print(combined.round(4).to_string())\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Specify the directory where your output files are saved\n",
        "    output_directory = '/content/drive/MyDrive/emc/adv_eval_outputs'\n",
        "    print_combined_results(output_directory)\n"
      ],
      "metadata": {
        "id": "jceaVOQFsEqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DOMAIN ADAPTION"
      ],
      "metadata": {
        "id": "h5IyQKKXFnTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import math\n",
        "import random\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Torch / HF\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModel,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoModelForMaskedLM,\n",
        "    AutoConfig,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n",
        "from torch.optim import AdamW\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim.swa_utils import AveragedModel, SWALR, update_bn\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "\n",
        "# Optional XGBoost\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    _HAS_XGB = True\n",
        "except Exception:\n",
        "    _HAS_XGB = False\n",
        "\n",
        "# -----------------------------\n",
        "# Repro & Device\n",
        "# -----------------------------\n",
        "def seed_everything(seed: int = 13):\n",
        "    random.seed(seed); np.random.seed(seed)\n",
        "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# -----------------------------\n",
        "# Config\n",
        "# -----------------------------\n",
        "class Config:\n",
        "    BASE_DIR = \"/content/drive/MyDrive/emc\"\n",
        "\n",
        "    # Data\n",
        "    TRAIN_PATH = os.path.join(BASE_DIR, \"train.csv\")\n",
        "    OOD_DATA_PATH = os.path.join(BASE_DIR, \"ood_dataset.csv\")\n",
        "    TERMS_PATH = os.path.join(BASE_DIR, \"engineering_terms.csv\")\n",
        "\n",
        "    # Artifacts\n",
        "    XLM_R_MODEL_PATH = os.path.join(BASE_DIR, \"xlmr_only_outputs/pytorch_model.bin\")\n",
        "    SIMPLE_PT_PATH   = os.path.join(BASE_DIR, \"simple_fusion_outputs/fusion_simple.pt\")\n",
        "    GATED_PT_PATH    = os.path.join(BASE_DIR, \"gated_fusion_outputs/fusion_gated.pt\")\n",
        "    SIMPLE_SCALER_PATH = os.path.join(BASE_DIR, \"simple_fusion_outputs/scaler12.pkl\")\n",
        "    GATED_SCALER_PATH  = os.path.join(BASE_DIR, \"gated_fusion_outputs/scaler12.pkl\")\n",
        "    RESULTS_CSV_PATH = os.path.join(BASE_DIR, \"domain_adaptation_results.csv\")\n",
        "\n",
        "    # Model\n",
        "    MODEL_NAME = \"xlm-roberta-base\"\n",
        "    MAX_LEN = 256\n",
        "    FEAT_DIM = 12\n",
        "    NUM_LABELS = 2\n",
        "\n",
        "    # ---------- Robust FT ----------\n",
        "    FT_EPOCHS = 6\n",
        "    FT_BATCH = 16\n",
        "    FT_LR = 2e-5\n",
        "    FT_WEIGHT_DECAY = 0.01\n",
        "    FT_WARMUP_RATIO = 0.06\n",
        "    FT_GRAD_ACCUM = 2\n",
        "    FT_MAX_GRAD_NORM = 1.0\n",
        "    FT_LABEL_SMOOTHING = 0.05\n",
        "    FT_LLRD_DECAY = 0.9\n",
        "    FT_FREEZE_EMBED = True\n",
        "    FT_FREEZE_BOTTOM_N = 4\n",
        "    FT_USE_FGM = True\n",
        "    FT_USE_EMA = True\n",
        "    FT_EMA_DECAY = 0.999\n",
        "    FT_EARLY_STOP_PATIENCE = 2\n",
        "    VAL_SPLIT = 0.1\n",
        "\n",
        "    # ---------- TAPT / DAPT ----------\n",
        "    USE_TAPT = True        # Task-Adaptive Pre-Training (train.csv text)\n",
        "    TAPT_EPOCHS = 1\n",
        "    TAPT_BATCH = 32\n",
        "    TAPT_LR = 5e-5\n",
        "    TAPT_WARMUP_RATIO = 0.06\n",
        "    TAPT_MAX_STEPS = None  # set to int to cap steps\n",
        "    TAPT_SAVE_PATH = os.path.join(BASE_DIR, \"tapt_mlm\")\n",
        "\n",
        "    USE_DAPT = True        # Domain-Adaptive Pre-Training (per-domain OOD text)\n",
        "    DAPT_EPOCHS = 1\n",
        "    DAPT_BATCH = 32\n",
        "    DAPT_LR = 5e-5\n",
        "    DAPT_WARMUP_RATIO = 0.06\n",
        "    DAPT_MAX_STEPS = None\n",
        "    DAPT_SAVE_DIR = os.path.join(BASE_DIR, \"dapt_mlm\")\n",
        "\n",
        "    # ---------- DAPT / MLM memory safety ----------\n",
        "    MLM_MAX_LEN = 192           # shorter seq len for MLM\n",
        "    MLM_GRAD_ACCUM = 1          # grad accumulation during MLM\n",
        "    MLM_BACKOFF_CPU = True      # fallback to CPU if CUDA backoffs exhausted\n",
        "\n",
        "    # ---------- R-Drop ----------\n",
        "    USE_RDROP = True\n",
        "    RDROP_ALPHA = 2.0  # KL weight\n",
        "\n",
        "    # ---------- SWA ----------\n",
        "    USE_SWA = True\n",
        "    SWA_START_EPOCH = 3       # begin SWA after this FT epoch (0-indexed)\n",
        "    SWA_LR = 1e-5\n",
        "\n",
        "    # ---------- Mixout (classifier only) ----------\n",
        "    USE_MIXOUT = True\n",
        "    MIXOUT_P = 0.9  # prob to use pretrain weights instead of learned ones\n",
        "\n",
        "    # ---------- Contrastive Head ----------\n",
        "    USE_CONTRASTIVE = True\n",
        "    CONTRASTIVE_TAU = 0.07\n",
        "    CONTRASTIVE_WEIGHT = 0.1  # added to CE loss\n",
        "\n",
        "    # Domain Adaptation\n",
        "    DA_ADAPT_RATIO = 0.1\n",
        "    DA_EPOCHS = 1\n",
        "    DA_LR = 5e-6\n",
        "    DA_BATCH_SIZE = 16\n",
        "    DA_UNFREEZE_TOP_N = 4\n",
        "\n",
        "    # Dataloaders\n",
        "    BATCH_SIZE = 32\n",
        "    NUM_WORKERS = 2\n",
        "    PIN_MEMORY = (DEVICE == \"cuda\")\n",
        "\n",
        "# -----------------------------\n",
        "# Text helpers & 12D features\n",
        "# -----------------------------\n",
        "_HAS_TEXTSTAT = False\n",
        "try:\n",
        "    import textstat\n",
        "    _HAS_TEXTSTAT = True\n",
        "except Exception:\n",
        "    _HAS_TEXTSTAT = False\n",
        "\n",
        "_WORD_RE = re.compile(r\"\\w+\", re.UNICODE)\n",
        "_NUM_RE = re.compile(r\"[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?\")\n",
        "STD_TERMS = {\"iso\", \"asme\", \"ieee\", \"din\", \"ansi\", \"iec\", \"ul\", \"astm\", \"en\"}\n",
        "SAFETY_TERMS = {\"safety\", \"hazard\", \"warning\", \"risk\", \"caution\", \"danger\", \"emergency\"}\n",
        "\n",
        "def simple_words(t: str) -> List[str]: return _WORD_RE.findall(t or \"\")\n",
        "def sent_count(t: str) -> int:\n",
        "    if not t: return 0\n",
        "    return max(1, len(re.split(r'[.!?]+[\\s\\n]+', t)))\n",
        "def punct_count(t: str) -> int: return sum(1 for ch in (t or \"\") if ch in \".,;:!?\")\n",
        "\n",
        "class TermsLexicon:\n",
        "    def __init__(self, csv_path: str, term_col=\"terms\", lang_col=\"lang\"):\n",
        "        if not os.path.exists(csv_path): raise FileNotFoundError(csv_path)\n",
        "        df = pd.read_csv(csv_path)\n",
        "        if term_col not in df.columns: raise ValueError(f\"Missing '{term_col}'\")\n",
        "        if lang_col not in df.columns: df[lang_col] = 'en'\n",
        "        self.by_lang = {str(l).lower(): set(str(x).strip().lower()\n",
        "                        for x in d[term_col].dropna().tolist() if str(x).strip())\n",
        "                        for l, d in df.groupby(lang_col)}\n",
        "    def pct_in_text(self, text: str, lang: str) -> float:\n",
        "        if not text: return 0.0\n",
        "        terms = self.by_lang.get((lang or \"en\").lower(), set())\n",
        "        if not terms: return 0.0\n",
        "        ws = [w.lower() for w in simple_words(text)]\n",
        "        if not ws: return 0.0\n",
        "        return sum(1 for w in ws if w in terms) / max(1, len(ws))\n",
        "\n",
        "def extract_numbers(text: str):\n",
        "    nums, dec = [], 0\n",
        "    for m in _NUM_RE.finditer(text or \"\"):\n",
        "        s = m.group(0)\n",
        "        try:\n",
        "            v = float(s)\n",
        "            if ('.' in s) or ('e' in s.lower()): dec += 1\n",
        "            nums.append(abs(v))\n",
        "        except: pass\n",
        "    return nums, dec\n",
        "\n",
        "def _finite_or_zero(x: float) -> float: return float(x) if np.isfinite(x) else 0.0\n",
        "\n",
        "class FeatureExtractor12:\n",
        "    MAX_CHARS, MAX_WORDS, MAX_SENTS, MAX_PUNCT, MAX_NUM_COUNT = 200_000, 40_000, 10_000, 50_000, 10_000\n",
        "    MAX_NUM_ABS, MAX_AVG_MAG = 1e12, 1e12\n",
        "    def __init__(self, tlex: TermsLexicon): self.tlex = tlex\n",
        "    def extract_one(self, text: str, lang: str) -> np.ndarray:\n",
        "        text = \"\" if text is None else str(text); lang = (lang or \"en\").lower()\n",
        "        ws = simple_words(text); n_words = len(ws)\n",
        "        chars = min(len(text), self.MAX_CHARS)\n",
        "        words = min(n_words, self.MAX_WORDS)\n",
        "        sents = min(sent_count(text), self.MAX_SENTS)\n",
        "        if lang == \"en\" and _HAS_TEXTSTAT and text.strip():\n",
        "            fre = _finite_or_zero(textstat.flesch_reading_ease(text))\n",
        "            fog = _finite_or_zero(textstat.gunning_fog(text))\n",
        "        else:\n",
        "            fre = fog = 0.0\n",
        "        eng_pct = self.tlex.pct_in_text(text, lang)\n",
        "        punc = min(punct_count(text), self.MAX_PUNCT)\n",
        "        nums, dec_cnt = extract_numbers(text)\n",
        "        nnums = min(len(nums), self.MAX_NUM_COUNT)\n",
        "        avg_mag = min(float(np.mean([min(v, self.MAX_NUM_ABS) for v in nums])) if nums else 0.0, self.MAX_AVG_MAG)\n",
        "        dec_ratio = float(dec_cnt / len(nums)) if nums else 0.0\n",
        "        low = text.lower()\n",
        "        has_std = 1.0 if any(t in low for t in STD_TERMS) else 0.0\n",
        "        has_saf = 1.0 if any(t in low for t in SAFETY_TERMS) else 0.0\n",
        "        feats = np.array([chars, words, sents, fre, fog, eng_pct, punc, nnums, has_std, has_saf, avg_mag, dec_ratio], dtype=np.float32)\n",
        "        if not np.all(np.isfinite(feats)):\n",
        "            feats = np.nan_to_num(feats, nan=0.0, posinf=self.MAX_AVG_MAG, neginf=0.0)\n",
        "        return feats.astype(np.float32)\n",
        "    def extract_df(self, df: pd.DataFrame) -> np.ndarray:\n",
        "        assert 'content' in df.columns\n",
        "        if 'lang' not in df.columns:\n",
        "            df = df.copy(); df['lang'] = 'en'\n",
        "        rows = [self.extract_one(r.get(\"content\",\"\"), r.get(\"lang\",\"en\")) for _, r in tqdm(df.iterrows(), total=len(df), desc=\"Extracting features\")]\n",
        "        return np.stack(rows, axis=0).astype(np.float32)\n",
        "\n",
        "# -----------------------------\n",
        "# Datasets\n",
        "# -----------------------------\n",
        "class TextFeatDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, tokenizer, feats: Optional[np.ndarray] = None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tok = tokenizer\n",
        "        self.feats = feats\n",
        "        self.labels = df['label'].values.astype(int) if 'label' in df.columns else None\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        enc = self.tok(str(row['content']), truncation=True, max_length=Config.MAX_LEN, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        item = {'input_ids': enc['input_ids'].squeeze(0), 'attention_mask': enc['attention_mask'].squeeze(0)}\n",
        "        if self.feats is not None: item['feats'] = torch.tensor(self.feats[idx], dtype=torch.float32)\n",
        "        if self.labels is not None: item['labels'] = torch.tensor(int(self.labels[idx]), dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "class UnlabeledTextDataset(Dataset):\n",
        "    def __init__(self, texts: List[str], tokenizer, max_len: int):\n",
        "        self.texts = texts\n",
        "        self.tok = tokenizer\n",
        "        self.max_len = max_len\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tok(\n",
        "            str(self.texts[idx]),\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,   # MLM-specific length\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {'input_ids': enc['input_ids'].squeeze(0), 'attention_mask': enc['attention_mask'].squeeze(0)}\n",
        "\n",
        "def make_loader(dataset, batch_size, sampler=None, shuffle=False):\n",
        "    return DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        sampler=sampler,\n",
        "        shuffle=(shuffle if sampler is None else False),\n",
        "        num_workers=Config.NUM_WORKERS,\n",
        "        pin_memory=Config.PIN_MEMORY,\n",
        "        drop_last=False\n",
        "    )\n",
        "\n",
        "# -----------------------------\n",
        "# Fusion models\n",
        "# -----------------------------\n",
        "def masked_mean_pool(last_hidden_state: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
        "    mask = attention_mask.unsqueeze(-1).float()\n",
        "    return (last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "\n",
        "class SimpleFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(model_name)\n",
        "        try: self.encoder.gradient_checkpointing_enable()\n",
        "        except Exception: pass\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + n_feats, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        pooled = masked_mean_pool(out.last_hidden_state, attention_mask)\n",
        "        fused = torch.cat([pooled, feats], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "\n",
        "class GatedFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2, feat_proj: int = 64):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(model_name)\n",
        "        try: self.encoder.gradient_checkpointing_enable()\n",
        "        except Exception: pass\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.fe_proj = nn.Sequential(nn.Linear(n_feats, feat_proj), nn.ReLU())\n",
        "        self.gate = nn.Sequential(nn.Linear(H + n_feats, 64), nn.ReLU(), nn.Linear(64, 1), nn.Sigmoid())\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + feat_proj, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        pooled = masked_mean_pool(out.last_hidden_state, attention_mask)\n",
        "        alpha = self.gate(torch.cat([pooled, feats], dim=1))\n",
        "        ef = self.fe_proj(feats)\n",
        "        fused = torch.cat([pooled, alpha * ef], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "\n",
        "def load_fusion_from_pt(model: nn.Module, pt_path: str):\n",
        "    if os.path.exists(pt_path):\n",
        "        sd = torch.load(pt_path, map_location=\"cpu\")\n",
        "        if isinstance(sd, dict) and 'state_dict' in sd: sd = sd['state_dict']\n",
        "        model.load_state_dict(sd, strict=False)\n",
        "\n",
        "# -----------------------------\n",
        "# Mixout (classifier)\n",
        "# -----------------------------\n",
        "class MixLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, bias=True, p=0.9, target_state_dict=None):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n",
        "        self.bias = nn.Parameter(torch.empty(out_features)) if bias else None\n",
        "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
        "        if self.bias is not None:\n",
        "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
        "            bound = 1 / math.sqrt(fan_in)\n",
        "            nn.init.uniform_(self.bias, -bound, bound)\n",
        "        self.p = p\n",
        "        self.target_w = None\n",
        "        self.target_b = None\n",
        "        if target_state_dict is not None and \"weight\" in target_state_dict:\n",
        "            self.target_w = target_state_dict[\"weight\"].detach().clone()\n",
        "            if self.bias is not None and \"bias\" in target_state_dict:\n",
        "                self.target_b = target_state_dict[\"bias\"].detach().clone()\n",
        "    def forward(self, x):\n",
        "        if self.training and self.target_w is not None:\n",
        "            mask_w = torch.bernoulli(torch.full_like(self.weight, self.p))\n",
        "            w = self.weight * (1 - mask_w) + self.target_w * mask_w\n",
        "            if self.bias is not None and self.target_b is not None:\n",
        "                mask_b = torch.bernoulli(torch.full_like(self.bias, self.p))\n",
        "                b = self.bias * (1 - mask_b) + self.target_b * mask_b\n",
        "            else:\n",
        "                b = self.bias\n",
        "        else:\n",
        "            w, b = self.weight, self.bias\n",
        "        return nn.functional.linear(x, w, b)\n",
        "\n",
        "def replace_classifier_with_mixout(model: AutoModelForSequenceClassification, p=0.9):\n",
        "    if hasattr(model.classifier, \"out_proj\"):   # XLM-R uses RobertaClassificationHead\n",
        "        old = model.classifier.out_proj\n",
        "        new = MixLinear(old.in_features, old.out_features, bias=(old.bias is not None),\n",
        "                        p=p, target_state_dict={\"weight\": old.weight.data, \"bias\": old.bias.data if old.bias is not None else None})\n",
        "        model.classifier.out_proj = new.to(DEVICE)\n",
        "    elif isinstance(model.classifier, nn.Linear):\n",
        "        old = model.classifier\n",
        "        new = MixLinear(old.in_features, old.out_features, bias=(old.bias is not None),\n",
        "                        p=p, target_state_dict={\"weight\": old.weight.data, \"bias\": old.bias.data if old.bias is not None else None})\n",
        "        model.classifier = new.to(DEVICE)\n",
        "\n",
        "# -----------------------------\n",
        "# Contrastive helper\n",
        "# -----------------------------\n",
        "def contrastive_loss_from_logits(hidden: torch.Tensor, labels: torch.Tensor, tau=0.07) -> torch.Tensor:\n",
        "    hidden = nn.functional.normalize(hidden, dim=1)\n",
        "    logits = hidden @ hidden.t() / tau  # [B,B]\n",
        "    B = labels.size(0)\n",
        "    mask = torch.ones(B, B, device=hidden.device, dtype=torch.bool)\n",
        "    mask.fill_diagonal_(False)\n",
        "    labels = labels.view(-1, 1)\n",
        "    positive_mask = (labels == labels.t()) & mask\n",
        "    logits_max = logits.max(dim=1, keepdim=True).values.detach()\n",
        "    logits = logits - logits_max\n",
        "    exp_logits = torch.exp(logits) * mask\n",
        "    log_prob = logits - torch.log(exp_logits.sum(dim=1, keepdim=True) + 1e-9)\n",
        "    pos_counts = positive_mask.sum(dim=1)\n",
        "    valid = pos_counts > 0\n",
        "    loss = torch.zeros(B, device=hidden.device)\n",
        "    if valid.any():\n",
        "        loss_pos = (-(log_prob * positive_mask).sum(dim=1) / pos_counts.clamp(min=1))\n",
        "        loss[valid] = loss_pos[valid]\n",
        "    return loss.mean()\n",
        "\n",
        "# -----------------------------\n",
        "# Optim utils\n",
        "# -----------------------------\n",
        "def compute_class_weights(labels: np.ndarray, num_classes: int) -> torch.Tensor:\n",
        "    counts = np.bincount(labels, minlength=num_classes).astype(np.float32)\n",
        "    weights = (counts.sum() / np.maximum(1.0, counts))\n",
        "    weights = weights / weights.mean()\n",
        "    return torch.tensor(weights, dtype=torch.float32, device=DEVICE)\n",
        "\n",
        "def get_llrd_optimizer_params(model: nn.Module, base_lr: float, weight_decay: float, llrd_decay: float):\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\", \"layer_norm.weight\"]\n",
        "    layers = []\n",
        "    # Classifier\n",
        "    head_params = [p for n,p in model.named_parameters() if n.startswith(\"classifier\") and p.requires_grad]\n",
        "    if head_params:\n",
        "        layers.append({\"params\": head_params, \"lr\": base_lr, \"weight_decay\": weight_decay})\n",
        "    # Encoder layers\n",
        "    enc = model.base_model if hasattr(model, \"base_model\") else model.roberta if hasattr(model, \"roberta\") else model.xlm_roberta if hasattr(model, \"xlm_roberta\") else model\n",
        "    enc_layers = list(getattr(getattr(enc, \"encoder\", None), \"layer\", []))\n",
        "    for i in reversed(range(len(enc_layers))):\n",
        "        lr = base_lr * (llrd_decay ** (len(enc_layers) - 1 - i))\n",
        "        layer = enc_layers[i]\n",
        "        params_decay, params_nodecay = [], []\n",
        "        for n,p in layer.named_parameters():\n",
        "            if not p.requires_grad: continue\n",
        "            if any(nd in n for nd in no_decay):\n",
        "                params_nodecay.append(p)\n",
        "            else:\n",
        "                params_decay.append(p)\n",
        "        if params_decay:\n",
        "            layers.append({\"params\": params_decay, \"lr\": lr, \"weight_decay\": weight_decay})\n",
        "        if params_nodecay:\n",
        "            layers.append({\"params\": params_nodecay, \"lr\": lr, \"weight_decay\": 0.0})\n",
        "    # Embeddings\n",
        "    if hasattr(enc, \"embeddings\"):\n",
        "        emb_params = [p for p in enc.embeddings.parameters() if p.requires_grad]\n",
        "        if emb_params:\n",
        "            layers.append({\"params\": emb_params, \"lr\": base_lr * (llrd_decay ** (len(enc_layers)+1)), \"weight_decay\": weight_decay})\n",
        "    return layers\n",
        "\n",
        "class EMA:\n",
        "    def __init__(self, model, decay=0.999):\n",
        "        self.decay = decay\n",
        "        self.shadow = {}\n",
        "        for n, p in model.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                self.shadow[n] = p.data.clone()\n",
        "    def update(self, model):\n",
        "        for n, p in model.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                self.shadow[n].mul_(self.decay).add_(p.data, alpha=1.0 - self.decay)\n",
        "    def apply_shadow(self, model):\n",
        "        self.backup = {}\n",
        "        for n, p in model.named_parameters():\n",
        "            if p.requires_grad and n in self.shadow:\n",
        "                self.backup[n] = p.data.clone()\n",
        "                p.data.copy_(self.shadow[n])\n",
        "    def restore(self, model):\n",
        "        for n, p in model.named_parameters():\n",
        "            if p.requires_grad and hasattr(self, \"backup\") and n in self.backup:\n",
        "                p.data.copy_(self.backup[n])\n",
        "        self.backup = {}\n",
        "\n",
        "class FGM:\n",
        "    def __init__(self, epsilon=1.0):\n",
        "        self.epsilon = epsilon\n",
        "        self.backup = {}\n",
        "    def attack(self, model):\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad and param.grad is not None and \"embeddings\" in name:\n",
        "                self.backup[name] = param.data.clone()\n",
        "                norm = torch.norm(param.grad)\n",
        "                if norm != 0:\n",
        "                    r_at = self.epsilon * param.grad / norm\n",
        "                    param.data.add_(r_at)\n",
        "    def restore(self, model):\n",
        "        for name, param in model.named_parameters():\n",
        "            if name in self.backup:\n",
        "                param.data = self.backup[name]\n",
        "        self.backup = {}\n",
        "\n",
        "def freeze_for_finetune(model: nn.Module, freeze_embed=True, freeze_bottom_n=0):\n",
        "    enc = model.base_model if hasattr(model, \"base_model\") else model.roberta if hasattr(model, \"roberta\") else model.xlm_roberta if hasattr(model, \"xlm_roberta\") else model\n",
        "    if freeze_embed and hasattr(enc, \"embeddings\"):\n",
        "        for p in enc.embeddings.parameters(): p.requires_grad = False\n",
        "    if hasattr(enc, \"encoder\") and hasattr(enc.encoder, \"layer\"):\n",
        "        layers = enc.encoder.layer\n",
        "        for i, layer in enumerate(layers):\n",
        "            if i < freeze_bottom_n:\n",
        "                for p in layer.parameters(): p.requires_grad = False\n",
        "\n",
        "def unfreeze_top_n(model: nn.Module, top_n: int):\n",
        "    enc = model.base_model if hasattr(model, \"base_model\") else model.roberta if hasattr(model, \"roberta\") else model.xlm_roberta if hasattr(model, \"xlm_roberta\") else model\n",
        "    if hasattr(enc, \"encoder\") and hasattr(enc.encoder, \"layer\"):\n",
        "        layers = enc.encoder.layer\n",
        "        K = len(layers)\n",
        "        for i, layer in enumerate(layers):\n",
        "            req = (i >= K - top_n)\n",
        "            for p in layer.parameters(): p.requires_grad = req\n",
        "    for p in model.classifier.parameters(): p.requires_grad = True\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluation\n",
        "# -----------------------------\n",
        "def evaluate_model(model, data_loader, model_type: str = 'transformer') -> float:\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(data_loader, desc=f\"Evaluating {model_type}\", leave=False):\n",
        "            inputs = {'input_ids': batch['input_ids'].to(DEVICE), 'attention_mask': batch['attention_mask'].to(DEVICE)}\n",
        "            if 'labels' in batch: all_labels.extend(batch['labels'].cpu().numpy().tolist())\n",
        "            if model_type in ['simple', 'gated']:\n",
        "                inputs['feats'] = batch['feats'].to(DEVICE)\n",
        "                logits = model(**inputs)\n",
        "            else:\n",
        "                with autocast(enabled=(DEVICE==\"cuda\")):\n",
        "                    out = model(**inputs, return_dict=True)\n",
        "                    logits = out.logits\n",
        "            preds = logits.argmax(1).cpu().tolist()\n",
        "            all_preds.extend(preds)\n",
        "    return f1_score(all_labels, all_preds, average='macro') if all_labels else float(\"nan\")\n",
        "\n",
        "# -----------------------------\n",
        "# TAPT / DAPT (MLM) – OOM tolerant with per-epoch save\n",
        "# -----------------------------\n",
        "def run_mlm_corpus_training(\n",
        "    texts: List[str],\n",
        "    save_dir: str,\n",
        "    epochs: int,\n",
        "    batch: int,\n",
        "    lr: float,\n",
        "    warmup_ratio: float,\n",
        "    max_steps: Optional[int],\n",
        "    tokenizer,\n",
        "):\n",
        "    if len(texts) == 0:\n",
        "        return\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    def _make_loader(bs, device_is_cuda=True):\n",
        "        ds = UnlabeledTextDataset(texts, tokenizer, max_len=Config.MLM_MAX_LEN)\n",
        "        # list-collate; collator will batch\n",
        "        return DataLoader(\n",
        "            ds,\n",
        "            batch_size=bs,\n",
        "            shuffle=True,\n",
        "            num_workers=Config.NUM_WORKERS if device_is_cuda else 0,\n",
        "            pin_memory=Config.PIN_MEMORY if device_is_cuda else False,\n",
        "            drop_last=False,\n",
        "            collate_fn=lambda b: b\n",
        "        )\n",
        "\n",
        "    def _train_once(device_str: str, start_bs: int):\n",
        "        mlm_device = torch.device(device_str)\n",
        "        model = AutoModelForMaskedLM.from_pretrained(Config.MODEL_NAME).to(mlm_device)\n",
        "        try: model.gradient_checkpointing_enable()\n",
        "        except Exception: pass\n",
        "\n",
        "        optimizer = AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
        "        collator = DataCollatorForLanguageModeling(tokenizer, mlm_probability=0.15)\n",
        "\n",
        "        bs = start_bs\n",
        "        while bs >= 1:\n",
        "            try:\n",
        "                dl = _make_loader(bs, device_is_cuda=(device_str == \"cuda\"))\n",
        "                total_steps = (len(dl) * epochs) if max_steps is None else max_steps\n",
        "                warmup = int(warmup_ratio * total_steps)\n",
        "                scheduler = get_linear_schedule_with_warmup(optimizer, warmup, total_steps)\n",
        "                scaler = GradScaler(enabled=(device_str == \"cuda\"))\n",
        "\n",
        "                step = 0\n",
        "                model.train()\n",
        "                for ep in range(epochs):\n",
        "                    try:\n",
        "                        for batch_list in tqdm(dl, desc=f\"MLM {device_str} bs={bs} Epoch {ep+1}/{epochs}\", leave=False):\n",
        "                            if max_steps is not None and step >= max_steps: break\n",
        "                            batch_collated = collator(batch_list)\n",
        "                            batch_collated = {k: v.to(mlm_device) for k, v in batch_collated.items()}\n",
        "                            optimizer.zero_grad(set_to_none=True)\n",
        "                            with autocast(enabled=(device_str == \"cuda\")):\n",
        "                                out = model(**batch_collated)\n",
        "                                loss = out.loss / max(1, Config.MLM_GRAD_ACCUM)\n",
        "                            scaler.scale(loss).backward()\n",
        "                            if ((step + 1) % max(1, Config.MLM_GRAD_ACCUM)) == 0:\n",
        "                                scaler.step(optimizer); scaler.update()\n",
        "                                scheduler.step(); optimizer.zero_grad(set_to_none=True)\n",
        "                            step += 1\n",
        "                        # save a checkpoint after each epoch\n",
        "                        model.save_pretrained(save_dir); tokenizer.save_pretrained(save_dir)\n",
        "                    except (torch.cuda.OutOfMemoryError, RuntimeError) as e:\n",
        "                        if isinstance(e, RuntimeError) and (\"out of memory\" not in str(e).lower()):\n",
        "                            raise\n",
        "                        torch.cuda.empty_cache()\n",
        "                        bs = bs // 2\n",
        "                        print(f\"⚠️ MLM OOM on {device_str}; reducing batch to {bs} and retrying epoch {ep+1}...\")\n",
        "                        if bs < 1: return False\n",
        "                        # rebuild loader with smaller batch and retry epoch\n",
        "                        dl = _make_loader(bs, device_is_cuda=(device_str == \"cuda\"))\n",
        "                        continue\n",
        "\n",
        "                return True\n",
        "\n",
        "            except torch.cuda.OutOfMemoryError:\n",
        "                torch.cuda.empty_cache()\n",
        "                bs = bs // 2\n",
        "                print(f\"⚠️ MLM OOM on {device_str}; reducing batch to {bs} and retrying...\")\n",
        "                continue\n",
        "\n",
        "        return False\n",
        "\n",
        "    # Try CUDA with backoff\n",
        "    ok = _train_once(\"cuda\" if torch.cuda.is_available() else \"cpu\", start_bs=batch)\n",
        "    if not ok and Config.MLM_BACKOFF_CPU:\n",
        "        print(\"↪️ Falling back to CPU for MLM pretraining...\")\n",
        "        _ = _train_once(\"cpu\", start_bs=max(1, batch // 2))\n",
        "\n",
        "# -----------------------------\n",
        "# Robust Supervised FT (TAPT, R-Drop, SWA, Mixout, FGM, EMA, Contrastive)\n",
        "# -----------------------------\n",
        "def train_transformer_supervised(train_df: pd.DataFrame, tokenizer: AutoTokenizer) -> None:\n",
        "    # TAPT (in-domain MLM)\n",
        "    if Config.USE_TAPT and not os.path.exists(Config.TAPT_SAVE_PATH):\n",
        "        print(\"🧪 Running TAPT (MLM on in-domain text)...\")\n",
        "        run_mlm_corpus_training(train_df['content'].astype(str).tolist(),\n",
        "                                save_dir=Config.TAPT_SAVE_PATH,\n",
        "                                epochs=Config.TAPT_EPOCHS, batch=Config.TAPT_BATCH,\n",
        "                                lr=Config.TAPT_LR, warmup_ratio=Config.TAPT_WARMUP_RATIO,\n",
        "                                max_steps=Config.TAPT_MAX_STEPS, tokenizer=tokenizer)\n",
        "\n",
        "    # pick init ckpt (TAPT if available else base)\n",
        "    init_ckpt = Config.TAPT_SAVE_PATH if (Config.USE_TAPT and os.path.exists(Config.TAPT_SAVE_PATH)) else Config.MODEL_NAME\n",
        "\n",
        "    # split labeled train/val\n",
        "    tr, va = train_test_split(train_df, test_size=Config.VAL_SPLIT, stratify=train_df['label'], random_state=13)\n",
        "    for c in ['content','label']:\n",
        "        assert c in tr.columns and c in va.columns\n",
        "    if 'lang' not in tr.columns: tr['lang']='en'\n",
        "    if 'lang' not in va.columns: va['lang']='en'\n",
        "\n",
        "    ds_tr = TextFeatDataset(tr, tokenizer, feats=None)\n",
        "    ds_va = TextFeatDataset(va, tokenizer, feats=None)\n",
        "    dl_tr = make_loader(ds_tr, batch_size=Config.FT_BATCH, shuffle=True)\n",
        "    dl_va = make_loader(ds_va, batch_size=Config.BATCH_SIZE)\n",
        "\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(init_ckpt, num_labels=Config.NUM_LABELS)\n",
        "    model.to(DEVICE)\n",
        "    try: model.gradient_checkpointing_enable()\n",
        "    except Exception: pass\n",
        "\n",
        "    # Optionally Mixout on classifier\n",
        "    if Config.USE_MIXOUT:\n",
        "        replace_classifier_with_mixout(model, p=Config.MIXOUT_P)\n",
        "\n",
        "    freeze_for_finetune(model, freeze_embed=Config.FT_FREEZE_EMBED, freeze_bottom_n=Config.FT_FREEZE_BOTTOM_N)\n",
        "    opt_params = get_llrd_optimizer_params(model, base_lr=Config.FT_LR, weight_decay=Config.FT_WEIGHT_DECAY, llrd_decay=Config.FT_LLRD_DECAY)\n",
        "    optimizer = AdamW(opt_params, lr=Config.FT_LR, weight_decay=Config.FT_WEIGHT_DECAY)\n",
        "    total_steps = (len(dl_tr) * Config.FT_EPOCHS) // max(1, Config.FT_GRAD_ACCUM)\n",
        "    warmup = int(Config.FT_WARMUP_RATIO * total_steps)\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup, num_training_steps=total_steps)\n",
        "\n",
        "    weights = compute_class_weights(tr['label'].values.astype(int), num_classes=Config.NUM_LABELS)\n",
        "    ce_loss = nn.CrossEntropyLoss(weight=weights, label_smoothing=Config.FT_LABEL_SMOOTHING)\n",
        "    kldiv = nn.KLDivLoss(reduction='batchmean')\n",
        "\n",
        "    scaler = GradScaler(enabled=(DEVICE==\"cuda\"))\n",
        "    ema = EMA(model, decay=Config.FT_EMA_DECAY) if Config.FT_USE_EMA else None\n",
        "    fgm = FGM(epsilon=1.0) if Config.FT_USE_FGM else None\n",
        "\n",
        "    # SWA wrapper\n",
        "    swa_model = AveragedModel(model) if Config.USE_SWA else None\n",
        "    swa_scheduler = None\n",
        "\n",
        "    best_f1, bad_epochs = -1.0, 0\n",
        "    global_step = 0\n",
        "\n",
        "    for epoch in range(Config.FT_EPOCHS):\n",
        "        model.train()\n",
        "        running = 0.0\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        # start SWA after certain epoch\n",
        "        if Config.USE_SWA and epoch == Config.SWA_START_EPOCH:\n",
        "            swa_scheduler = SWALR(optimizer, anneal_strategy=\"cos\", anneal_epochs=1, swa_lr=Config.SWA_LR)\n",
        "\n",
        "        for step, batch in enumerate(tqdm(dl_tr, desc=f\"FT Epoch {epoch+1}/{Config.FT_EPOCHS}\")):\n",
        "            ids = batch['input_ids'].to(DEVICE); am = batch['attention_mask'].to(DEVICE); y = batch['labels'].to(DEVICE)\n",
        "\n",
        "            # Forward 1\n",
        "            with autocast(enabled=(DEVICE==\"cuda\")):\n",
        "                out1 = model(input_ids=ids, attention_mask=am, labels=None, return_dict=True)\n",
        "                logits1 = out1.logits\n",
        "                loss_ce1 = ce_loss(logits1, y)\n",
        "\n",
        "            # Forward 2 for R-Drop\n",
        "            with autocast(enabled=(DEVICE==\"cuda\")):\n",
        "                out2 = model(input_ids=ids, attention_mask=am, labels=None, return_dict=True)\n",
        "                logits2 = out2.logits\n",
        "                loss_ce2 = ce_loss(logits2, y)\n",
        "\n",
        "            loss = (loss_ce1 + loss_ce2) / 2\n",
        "\n",
        "            if Config.USE_RDROP:\n",
        "                p1 = nn.functional.log_softmax(logits1, dim=-1)\n",
        "                p2 = nn.functional.log_softmax(logits2, dim=-1)\n",
        "                q1 = nn.functional.softmax(logits1, dim=-1)\n",
        "                q2 = nn.functional.softmax(logits2, dim=-1)\n",
        "                kl = (kldiv(p1, q2.detach()) + kldiv(p2, q1.detach())) / 2\n",
        "                loss = loss + Config.RDROP_ALPHA * kl\n",
        "\n",
        "            # contrastive on pooled CLS via mean-pool of last hidden states\n",
        "            if Config.USE_CONTRASTIVE:\n",
        "                with torch.no_grad():\n",
        "                    outc = model.base_model(input_ids=ids, attention_mask=am, output_hidden_states=True, return_dict=True)\n",
        "                    last = outc.last_hidden_state  # [B, L, H]\n",
        "                    pooled = masked_mean_pool(last, am)  # [B, H]\n",
        "                loss = loss + Config.CONTRASTIVE_WEIGHT * contrastive_loss_from_logits(pooled, y, tau=Config.CONTRASTIVE_TAU)\n",
        "\n",
        "            loss = loss / Config.FT_GRAD_ACCUM\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # FGM adversarial\n",
        "            if Config.FT_USE_FGM:\n",
        "                fgm.attack(model)\n",
        "                with autocast(enabled=(DEVICE==\"cuda\")):\n",
        "                    out_adv = model(input_ids=ids, attention_mask=am, labels=None, return_dict=True)\n",
        "                    loss_adv = ce_loss(out_adv.logits, y) / Config.FT_GRAD_ACCUM\n",
        "                scaler.scale(loss_adv).backward()\n",
        "                fgm.restore(model)\n",
        "\n",
        "            if (step + 1) % Config.FT_GRAD_ACCUM == 0:\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), Config.FT_MAX_GRAD_NORM)\n",
        "                scaler.step(optimizer); scaler.update()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                if swa_scheduler is not None:\n",
        "                    swa_scheduler.step()\n",
        "                else:\n",
        "                    scheduler.step()\n",
        "                global_step += 1\n",
        "                if ema is not None: ema.update(model)\n",
        "\n",
        "            running += float(loss.item()) * Config.FT_GRAD_ACCUM\n",
        "\n",
        "        # Validation (EMA shadow)\n",
        "        if ema is not None: ema.apply_shadow(model)\n",
        "        f1 = evaluate_model(model, dl_va, 'transformer')\n",
        "        if ema is not None: ema.restore(model)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: train_loss={running/len(dl_tr):.4f}  val_macroF1={f1:.4f}\")\n",
        "\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1; bad_epochs = 0\n",
        "            os.makedirs(os.path.dirname(Config.XLM_R_MODEL_PATH), exist_ok=True)\n",
        "            torch.save(model.state_dict(), Config.XLM_R_MODEL_PATH)\n",
        "            print(\"✅ Saved best model.\")\n",
        "        else:\n",
        "            bad_epochs += 1\n",
        "            if bad_epochs >= Config.FT_EARLY_STOP_PATIENCE:\n",
        "                print(\"⏹️ Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    # If SWA was used: update BN and save SWA weights too\n",
        "    if Config.USE_SWA and swa_model is not None:\n",
        "        swa_model.update_parameters(model)\n",
        "        print(\"🔁 Updating BN for SWA...\")\n",
        "        update_bn(make_loader(ds_tr, batch_size=Config.BATCH_SIZE), swa_model, device=DEVICE)\n",
        "        torch.save(swa_model.module.state_dict(), Config.XLM_R_MODEL_PATH)\n",
        "        print(\"✅ Saved SWA-averaged model.\")\n",
        "\n",
        "# -----------------------------\n",
        "# Robust DAPT → SeqCls loader (bin-only, no config.json needed)\n",
        "# -----------------------------\n",
        "def safe_load_seqcls_from_dapt(dapt_dir: str, num_labels: int, base_model_name: str) -> AutoModelForSequenceClassification:\n",
        "    \"\"\"\n",
        "    Build a SequenceClassification model that uses encoder weights from a DAPT MLM checkpoint.\n",
        "    Loads dapt_dir/pytorch_model.bin directly and copies overlapping encoder weights.\n",
        "    \"\"\"\n",
        "    bin_path = os.path.join(dapt_dir, \"pytorch_model.bin\")\n",
        "    if not os.path.isfile(bin_path):\n",
        "        print(f\"⚠️ No pytorch_model.bin in {dapt_dir}; skipping DAPT and using base model.\")\n",
        "        m = AutoModelForSequenceClassification.from_pretrained(base_model_name, num_labels=num_labels)\n",
        "        try: m.gradient_checkpointing_enable()\n",
        "        except Exception: pass\n",
        "        return m\n",
        "\n",
        "    m = AutoModelForSequenceClassification.from_pretrained(base_model_name, num_labels=num_labels)\n",
        "    try: m.gradient_checkpointing_enable()\n",
        "    except Exception: pass\n",
        "\n",
        "    enc = (m.base_model if hasattr(m, \"base_model\")\n",
        "           else m.roberta if hasattr(m, \"roberta\")\n",
        "           else m.xlm_roberta if hasattr(m, \"xlm_roberta\")\n",
        "           else None)\n",
        "    if enc is None:\n",
        "        raise RuntimeError(\"Could not locate base encoder in the classifier model.\")\n",
        "\n",
        "    try:\n",
        "        sd = torch.load(bin_path, map_location=\"cpu\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Could not load DAPT state dict: {e}. Using base encoder.\")\n",
        "        return m\n",
        "\n",
        "    enc_sd = enc.state_dict()\n",
        "    copied, total = 0, 0\n",
        "    for k in enc_sd.keys():\n",
        "        total += 1\n",
        "        if k in sd:\n",
        "            enc_sd[k] = sd[k]; copied += 1\n",
        "        else:\n",
        "            tail = \".\".join(k.split(\".\")[1:])  # drop first token (e.g., 'roberta')\n",
        "            for cand_prefix in (\"roberta.\", \"xlm_roberta.\", \"model.\", \"\"):\n",
        "                cand = cand_prefix + tail if cand_prefix else tail\n",
        "                if cand in sd:\n",
        "                    enc_sd[k] = sd[cand]; copied += 1; break\n",
        "    enc.load_state_dict(enc_sd, strict=False)\n",
        "    print(f\"✅ DAPT encoder load: copied {copied}/{total} encoder tensors from {bin_path}\")\n",
        "    return m\n",
        "\n",
        "# -----------------------------\n",
        "# Few-shot Domain Adaptation\n",
        "# -----------------------------\n",
        "def adapt_transformer_fewshot(model: AutoModelForSequenceClassification, ds_all: Dataset, adapt_idx: np.ndarray, lr=5e-6, epochs=1):\n",
        "    dl_da = make_loader(ds_all, batch_size=Config.DA_BATCH_SIZE, sampler=SubsetRandomSampler(adapt_idx))\n",
        "    optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=0.0)\n",
        "    steps = len(dl_da) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, 0, max(1, steps))\n",
        "    scaler = GradScaler(enabled=(DEVICE==\"cuda\"))\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.train()\n",
        "    for _ in range(epochs):\n",
        "        for batch in tqdm(dl_da, desc=\"Adapting\", leave=False):\n",
        "            ids = batch['input_ids'].to(DEVICE); am = batch['attention_mask'].to(DEVICE); y = batch['labels'].to(DEVICE)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with autocast(enabled=(DEVICE==\"cuda\")):\n",
        "                out = model(input_ids=ids, attention_mask=am, labels=None, return_dict=True)\n",
        "                loss = criterion(out.logits, y)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer); scaler.update(); scheduler.step()\n",
        "\n",
        "# -----------------------------\n",
        "# Uncertainty-based selection & Ensemble helpers\n",
        "# -----------------------------\n",
        "def pick_uncertain_indices(model, ds_all, idx_all, k, batch=64):\n",
        "    # returns adapt_idx (most uncertain) and test_idx\n",
        "    if k <= 0 or len(idx_all) <= k:\n",
        "        return np.array([], dtype=int), idx_all\n",
        "    dl = DataLoader(ds_all, batch_size=batch, sampler=SubsetRandomSampler(idx_all))\n",
        "    model.eval(); entropies = []\n",
        "    with torch.no_grad():\n",
        "        for b in dl:\n",
        "            ids = b['input_ids'].to(DEVICE); am = b['attention_mask'].to(DEVICE)\n",
        "            logits = model(input_ids=ids, attention_mask=am, return_dict=True).logits\n",
        "            p = torch.softmax(logits, dim=-1)\n",
        "            e = -(p * (p.clamp_min(1e-9).log())).sum(dim=1)  # entropy\n",
        "            entropies.extend(e.cpu().tolist())\n",
        "    entropies = np.array(entropies)\n",
        "    order = np.argsort(-entropies)  # descending uncertainty\n",
        "    topk_local = order[:k]\n",
        "    adapt_idx = idx_all[topk_local]\n",
        "    mask = np.ones(len(idx_all), dtype=bool); mask[topk_local] = False\n",
        "    test_idx = idx_all[mask]\n",
        "    return adapt_idx, test_idx\n",
        "\n",
        "def get_probs_transformer(model, ds, idx, batch=64):\n",
        "    dl = DataLoader(ds, batch_size=batch, sampler=SubsetRandomSampler(idx))\n",
        "    model.eval(); out = []\n",
        "    with torch.no_grad():\n",
        "        for b in dl:\n",
        "            ids = b['input_ids'].to(DEVICE); am = b['attention_mask'].to(DEVICE)\n",
        "            logits = model(input_ids=ids, attention_mask=am, return_dict=True).logits\n",
        "            p = torch.softmax(logits, dim=-1)[:, 1].cpu().numpy()  # positive class prob\n",
        "            out.append(p)\n",
        "    return np.concatenate(out) if len(out)>0 else np.array([])\n",
        "\n",
        "def get_probs_xgb(xgb_model, scaler, feats_raw, idx):\n",
        "    X = scaler.transform(feats_raw[idx])\n",
        "    return xgb_model.predict_proba(X)[:, 1]\n",
        "\n",
        "def tune_weight_and_threshold(p_t, p_x, y_true, weights=None, thresholds=None):\n",
        "    if len(p_t)==0 or len(p_x)==0: return (0.0, 1.0, 0.5)\n",
        "    if weights is None: weights = np.linspace(0.0, 1.0, 11)  # 0,0.1,...,1\n",
        "    if thresholds is None: thresholds = np.linspace(0.2, 0.8, 25)\n",
        "    best = (-1.0, 0.5, 0.5)  # f1, w, thr\n",
        "    for w in weights:\n",
        "        p = w * p_t + (1 - w) * p_x\n",
        "        for thr in thresholds:\n",
        "            preds = (p >= thr).astype(int)\n",
        "            f1 = f1_score(y_true, preds, average='macro')\n",
        "            if f1 > best[0]: best = (f1, w, thr)\n",
        "    return best  # returns best_f1, best_w, best_thr\n",
        "\n",
        "# -----------------------------\n",
        "# Main\n",
        "# -----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    seed_everything(13)\n",
        "    print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
        "    tlex = TermsLexicon(Config.TERMS_PATH)\n",
        "    fe = FeatureExtractor12(tlex)\n",
        "\n",
        "    # Load data\n",
        "    train_df = pd.read_csv(Config.TRAIN_PATH)\n",
        "    ood_df   = pd.read_csv(Config.OOD_DATA_PATH)\n",
        "    for c in ['content','label']: assert c in train_df.columns\n",
        "    for c in ['content','label','domain']: assert c in ood_df.columns\n",
        "    if 'lang' not in train_df.columns: train_df['lang']='en'\n",
        "    if 'lang' not in ood_df.columns: ood_df['lang']='en'\n",
        "    domains = ood_df['domain'].unique()\n",
        "\n",
        "    # =========================\n",
        "    # 1) Robust supervised FT\n",
        "    # =========================\n",
        "    if not os.path.exists(Config.XLM_R_MODEL_PATH):\n",
        "        train_transformer_supervised(train_df, tokenizer)\n",
        "    else:\n",
        "        print(\"ℹ️ Found existing fine-tuned checkpoint; skipping FT.\")\n",
        "\n",
        "    # Load best FT model (may be SWA-averaged)\n",
        "    init_ckpt = Config.XLM_R_MODEL_PATH\n",
        "    xlm_r_model = AutoModelForSequenceClassification.from_pretrained(Config.MODEL_NAME, num_labels=Config.NUM_LABELS)\n",
        "    xlm_r_model.load_state_dict(torch.load(init_ckpt, map_location=DEVICE), strict=False)\n",
        "    xlm_r_model.to(DEVICE)\n",
        "    try: xlm_r_model.gradient_checkpointing_enable()\n",
        "    except Exception: pass\n",
        "\n",
        "    # Fusion models & scalers\n",
        "    simple_model = SimpleFusion(Config.MODEL_NAME, Config.FEAT_DIM); load_fusion_from_pt(simple_model, Config.SIMPLE_PT_PATH); simple_model.to(DEVICE)\n",
        "    gated_model  = GatedFusion(Config.MODEL_NAME, Config.FEAT_DIM, feat_proj=64); load_fusion_from_pt(gated_model, Config.GATED_PT_PATH); gated_model.to(DEVICE)\n",
        "    simple_scaler = joblib.load(Config.SIMPLE_SCALER_PATH)\n",
        "    gated_scaler  = joblib.load(Config.GATED_SCALER_PATH)\n",
        "\n",
        "    # XGBoost baseline\n",
        "    print(\"Extracting features for in-domain training (XGB baseline)...\")\n",
        "    feats_tr_raw = fe.extract_df(train_df)\n",
        "    xgb_scaler = StandardScaler(); feats_tr_scaled = xgb_scaler.fit_transform(feats_tr_raw)\n",
        "    y_tr = train_df['label'].values.astype(int)\n",
        "    xgb_model = None\n",
        "    if _HAS_XGB:\n",
        "        xgb_model = xgb.XGBClassifier(n_estimators=1500, objective=\"binary:logistic\", tree_method=\"hist\", n_jobs=4, random_state=13, eval_metric=\"logloss\")\n",
        "        xgb_model.fit(feats_tr_scaled, y_tr)\n",
        "        print(\"XGBoost baseline trained.\")\n",
        "    else:\n",
        "        print(\"⚠️ xgboost not installed; skipping XGBoost baseline.\")\n",
        "\n",
        "    # =========================\n",
        "    # 2) Cross-domain eval + DAPT + DA + Ensemble\n",
        "    # =========================\n",
        "    results: List[Dict[str, Any]] = []\n",
        "\n",
        "    for domain in domains:\n",
        "        print(f\"\\n--- Processing domain: {domain} ---\")\n",
        "        ddf = ood_df[ood_df['domain']==domain].copy().reset_index(drop=True)\n",
        "        y_true = ddf['label'].values.astype(int)\n",
        "\n",
        "        # ---- DAPT on unlabeled OOD text (before adaptation) with OOM-safety\n",
        "        dapt_dir = os.path.join(Config.DAPT_SAVE_DIR, domain.replace(\" \", \"_\"))\n",
        "        torch.cuda.empty_cache()\n",
        "        need_dapt = Config.USE_DAPT and ((not os.path.exists(dapt_dir)) or (not os.path.isfile(os.path.join(dapt_dir, \"pytorch_model.bin\"))))\n",
        "        if need_dapt:\n",
        "            print(f\"🧪 Running DAPT (MLM) for domain '{domain}'...\")\n",
        "            run_mlm_corpus_training(\n",
        "                ddf['content'].astype(str).tolist(),\n",
        "                save_dir=dapt_dir,\n",
        "                epochs=Config.DAPT_EPOCHS,\n",
        "                batch=Config.DAPT_BATCH,\n",
        "                lr=Config.DAPT_LR,\n",
        "                warmup_ratio=Config.DAPT_WARMUP_RATIO,\n",
        "                max_steps=Config.DAPT_MAX_STEPS,\n",
        "                tokenizer=tokenizer,\n",
        "            )\n",
        "\n",
        "        # Build seq-cls using DAPT encoder (if present), then load FT head\n",
        "        xlm_r_base = safe_load_seqcls_from_dapt(\n",
        "            dapt_dir=dapt_dir,\n",
        "            num_labels=Config.NUM_LABELS,\n",
        "            base_model_name=Config.MODEL_NAME,\n",
        "        )\n",
        "        xlm_r_base.load_state_dict(torch.load(Config.XLM_R_MODEL_PATH, map_location=DEVICE), strict=False)\n",
        "        xlm_r_base.to(DEVICE)\n",
        "\n",
        "        # Prepare data & features\n",
        "        feats_ood_raw = fe.extract_df(ddf)\n",
        "        ds_all = TextFeatDataset(ddf, tokenizer, feats=None)\n",
        "\n",
        "        # Split for adaptation (uncertainty-based)\n",
        "        n = len(ddf); idx = np.arange(n)\n",
        "        np.random.shuffle(idx)\n",
        "        k = int(Config.DA_ADAPT_RATIO * n)\n",
        "        if k >= 1 and (n - k) >= 1:\n",
        "            adapt_idx, test_idx = pick_uncertain_indices(xlm_r_base, ds_all, idx, k, batch=Config.BATCH_SIZE)\n",
        "            can_adapt = True\n",
        "        else:\n",
        "            adapt_idx, test_idx = np.array([], dtype=int), idx\n",
        "            can_adapt = False\n",
        "\n",
        "        # ---- Zero-shot: XGB\n",
        "        if xgb_model is not None:\n",
        "            preds = xgb_model.predict(xgb_scaler.transform(feats_ood_raw))\n",
        "            f1 = f1_score(y_true, preds, average='macro')\n",
        "            results.append({'Domain':domain,'Model':'XGBoost + Features','Evaluation':'Zero-Shot','Macro F1-Score':float(f1)})\n",
        "\n",
        "        # ---- Zero-shot: Transformer\n",
        "        dl_ood = make_loader(ds_all, batch_size=Config.BATCH_SIZE, sampler=SubsetRandomSampler(idx))\n",
        "        f1 = evaluate_model(xlm_r_base, dl_ood, 'transformer')\n",
        "        results.append({'Domain':domain,'Model':'XLM-R Only','Evaluation':'Zero-Shot','Macro F1-Score':float(f1)})\n",
        "\n",
        "        # ---- Zero-shot: Simple Fusion\n",
        "        ds_simple = TextFeatDataset(ddf, tokenizer, feats=simple_scaler.transform(feats_ood_raw))\n",
        "        dl_simple = make_loader(ds_simple, batch_size=Config.BATCH_SIZE, sampler=SubsetRandomSampler(idx))\n",
        "        f1 = evaluate_model(simple_model, dl_simple, 'simple')\n",
        "        results.append({'Domain':domain,'Model':'Simple Fusion','Evaluation':'Zero-Shot','Macro F1-Score':float(f1)})\n",
        "\n",
        "        # ---- Zero-shot: Gated Fusion\n",
        "        ds_gated = TextFeatDataset(ddf, tokenizer, feats=gated_scaler.transform(feats_ood_raw))\n",
        "        dl_gated = make_loader(ds_gated, batch_size=Config.BATCH_SIZE, sampler=SubsetRandomSampler(idx))\n",
        "        f1 = evaluate_model(gated_model, dl_gated, 'gated')\n",
        "        results.append({'Domain':domain,'Model':'Gated Fusion','Evaluation':'Zero-Shot','Macro F1-Score':float(f1)})\n",
        "\n",
        "        # ---- Zero-shot Ensemble (tuned on adapt split if available)\n",
        "        if (xgb_model is not None) and (len(adapt_idx) > 0):\n",
        "            p_t_adapt = get_probs_transformer(xlm_r_base, ds_all, adapt_idx, batch=Config.BATCH_SIZE)\n",
        "            p_x_adapt = get_probs_xgb(xgb_model, xgb_scaler, feats_ood_raw, adapt_idx)\n",
        "            y_adapt = y_true[adapt_idx]\n",
        "            best_f1, best_w, best_thr = tune_weight_and_threshold(p_t_adapt, p_x_adapt, y_adapt)\n",
        "\n",
        "            p_t_test = get_probs_transformer(xlm_r_base, ds_all, test_idx, batch=Config.BATCH_SIZE)\n",
        "            p_x_test = get_probs_xgb(xgb_model, xgb_scaler, feats_ood_raw, test_idx)\n",
        "            p_blend = best_w * p_t_test + (1 - best_w) * p_x_test\n",
        "            preds = (p_blend >= best_thr).astype(int)\n",
        "            f1_blend = f1_score(y_true[test_idx], preds, average='macro')\n",
        "            results.append({'Domain': domain, 'Model': f'Ensemble(T+XGB) w={best_w:.2f} thr={best_thr:.2f}',\n",
        "                            'Evaluation': 'Zero-Shot (tuned on adapt)', 'Macro F1-Score': float(f1_blend)})\n",
        "\n",
        "        # ---- Few-shot Domain Adaptation (unfreeze top blocks + head)\n",
        "        if can_adapt:\n",
        "            print(\"  Running Domain Adaptation...\")\n",
        "            unfreeze_top_n(xlm_r_base, Config.DA_UNFREEZE_TOP_N)\n",
        "            adapt_transformer_fewshot(xlm_r_base, ds_all, adapt_idx, lr=Config.DA_LR, epochs=Config.DA_EPOCHS)\n",
        "            dl_test = make_loader(ds_all, batch_size=Config.BATCH_SIZE, sampler=SubsetRandomSampler(test_idx))\n",
        "            f1 = evaluate_model(xlm_r_base, dl_test, 'transformer')\n",
        "            results.append({'Domain':domain,'Model':'XLM-R Only','Evaluation':'Domain Adapted','Macro F1-Score':float(f1)})\n",
        "\n",
        "            # Domain-adapted Ensemble (retune on adapt set with adapted transformer)\n",
        "            if xgb_model is not None:\n",
        "                p_t_adapt2 = get_probs_transformer(xlm_r_base, ds_all, adapt_idx, batch=Config.BATCH_SIZE)\n",
        "                p_x_adapt2 = get_probs_xgb(xgb_model, xgb_scaler, feats_ood_raw, adapt_idx)\n",
        "                best_f1, best_w, best_thr = tune_weight_and_threshold(p_t_adapt2, p_x_adapt2, y_true[adapt_idx])\n",
        "\n",
        "                p_t_test2 = get_probs_transformer(xlm_r_base, ds_all, test_idx, batch=Config.BATCH_SIZE)\n",
        "                p_x_test2 = get_probs_xgb(xgb_model, xgb_scaler, feats_ood_raw, test_idx)\n",
        "                p_blend2 = best_w * p_t_test2 + (1 - best_w) * p_x_test2\n",
        "                preds2 = (p_blend2 >= best_thr).astype(int)\n",
        "                f1_blend2 = f1_score(y_true[test_idx], preds2, average='macro')\n",
        "                results.append({'Domain': domain, 'Model': f'Ensemble(T+XGB) w={best_w:.2f} thr={best_thr:.2f}',\n",
        "                                'Evaluation': 'Domain Adapted (tuned)', 'Macro F1-Score': float(f1_blend2)})\n",
        "        else:\n",
        "            print(\"  Skipping adaptation due to insufficient samples.\")\n",
        "\n",
        "    # =========================\n",
        "    # 3) Save & Print Results\n",
        "    # =========================\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(Config.RESULTS_CSV_PATH, index=False)\n",
        "\n",
        "    print(\"\\n\\n\" + \"=\"*80)\n",
        "    print(\"CROSS-DOMAIN GENERALIZATION FINAL RESULTS\")\n",
        "    print(\"=\"*80)\n",
        "    if not results_df.empty:\n",
        "        pivot_df = results_df.pivot_table(index=['Model','Evaluation'], columns='Domain', values='Macro F1-Score')\n",
        "        print(pivot_df.round(4).to_string())\n",
        "    else:\n",
        "        print(\"No results to display.\")\n",
        "    print(f\"\\n✅ Results summary saved to: {Config.RESULTS_CSV_PATH}\")\n"
      ],
      "metadata": {
        "id": "1KeBOps4FqTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBOOST EVALUATION"
      ],
      "metadata": {
        "id": "vREf8WA4dL8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import random\n",
        "from typing import Optional, Dict, Tuple, List, Any\n",
        "from dataclasses import dataclass, field\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    f1_score, accuracy_score, precision_score, recall_score,\n",
        "    roc_auc_score, classification_report, roc_curve, auc\n",
        ")\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.inspection import permutation_importance\n",
        "import joblib\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    XLMRobertaForSequenceClassification,\n",
        "    XLMRobertaTokenizerFast,\n",
        "    DataCollatorWithPadding,\n",
        "    AutoConfig\n",
        ")\n",
        "\n",
        "try:\n",
        "    import textstat\n",
        "    _HAS_TEXTSTAT = True\n",
        "except Exception:\n",
        "    _HAS_TEXTSTAT = False\n",
        "\n",
        "\n",
        "# ===================== Config =====================\n",
        "@dataclass\n",
        "class Config:\n",
        "    BASE_DIR: str = \"/content/drive/MyDrive/emc\"\n",
        "    TRAIN_CSV: str = os.path.join(BASE_DIR, \"train.csv\")\n",
        "    TEST_CSV: str = os.path.join(BASE_DIR, \"test.csv\")\n",
        "    TERMS_CSV: str = os.path.join(BASE_DIR, \"engineering_terms.csv\")\n",
        "\n",
        "    XGB_MODEL_JSON: str = os.path.join(BASE_DIR, \"xgb_outputs/xgb_model.json\")\n",
        "    XGB_SCALER_PATH: str = os.path.join(BASE_DIR, \"xgb_outputs/scaler12.pkl\")\n",
        "    XGB_AUC_ROC_PLOT_PATH: str = os.path.join(BASE_DIR, \"xgb_outputs/auc_roc_plot.png\")\n",
        "    XGB_PERMUTATION_IMPORTANCE_PLOT_PATH: str = os.path.join(BASE_DIR, \"xgb_outputs/permutation_importance.png\")\n",
        "\n",
        "    XLMR_MODEL_PATH: str = os.path.join(BASE_DIR, \"xlmr_only_outputs/best_model\")\n",
        "    XLMR_AUC_ROC_PLOT_PATH: str = os.path.join(BASE_DIR, \"xlmr_only_outputs/auc_roc_plot.png\")\n",
        "\n",
        "    TEXT_COL: str = \"content\"\n",
        "    LABEL_COL: str = \"label\"\n",
        "    LANG_COL: str = \"lang\"\n",
        "\n",
        "    N_FEATURES: int = 12\n",
        "    N_CLASSES: int = 2\n",
        "    MAX_LEN: int = 256\n",
        "    BATCH_SIZE: int = 32\n",
        "\n",
        "    LABEL2ID: Dict[str, int] = field(default_factory=lambda: {\"0\": 0, \"1\": 1})\n",
        "    ID2LABEL: Dict[int, str] = field(default_factory=lambda: {0: \"Real\", 1: \"Misinformation\"})\n",
        "\n",
        "    DEVICE: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    MODEL_NAME: str = \"xlm-roberta-base\"\n",
        "\n",
        "\n",
        "# ===================== Reproducibility =====================\n",
        "def set_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# ===================== Data & Feature Extraction =====================\n",
        "STD_TERMS = {\"iso\", \"asme\", \"ieee\", \"din\", \"ansi\", \"iec\", \"ul\", \"astm\", \"en\"}\n",
        "SAFETY_TERMS = {\"safety\", \"hazard\", \"warning\", \"risk\", \"caution\", \"danger\", \"emergency\"}\n",
        "_WORD_RE = re.compile(r\"\\w+\", re.UNICODE)\n",
        "_NUM_RE = re.compile(r'[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?')\n",
        "\n",
        "def simple_words(t: str) -> List[str]: return _WORD_RE.findall(t or \"\")\n",
        "def sent_count(t: str) -> int:\n",
        "    if not t: return 0\n",
        "    return max(1, len(re.split(r'[.!?]+[\\s\\n]+', t)))\n",
        "def punct_count(t: str) -> int: return sum(1 for ch in (t or \"\") if ch in \".,;:!?\")\n",
        "def extract_numbers(text: str):\n",
        "    nums, dec = [], 0\n",
        "    for m in _NUM_RE.finditer(text or \"\"):\n",
        "        s = m.group(0)\n",
        "        try:\n",
        "            v = float(s)\n",
        "            if ('.' in s) or ('e' in s.lower()): dec += 1\n",
        "            nums.append(abs(v))\n",
        "        except: pass\n",
        "    return nums, dec\n",
        "def _finite_or_zero(x: float) -> float: return float(x) if np.isfinite(x) else 0.0\n",
        "\n",
        "class TermsLexicon:\n",
        "    def __init__(self, csv_path: str, term_col=\"terms\", lang_col=\"lang\"):\n",
        "        if not os.path.exists(csv_path): raise FileNotFoundError(csv_path)\n",
        "        df = pd.read_csv(csv_path)\n",
        "        if term_col not in df.columns: raise ValueError(f\"Missing '{term_col}'\")\n",
        "        if lang_col not in df.columns: df[lang_col] = 'en'\n",
        "        self.by_lang = {str(l).lower(): set(str(x).strip().lower() for x in d[term_col].dropna().tolist() if str(x).strip()) for l, d in df.groupby(lang_col)}\n",
        "    def pct_in_text(self, text: str, lang: str) -> float:\n",
        "        if not text: return 0.0\n",
        "        terms = self.by_lang.get((lang or \"en\").lower(), set())\n",
        "        if not terms: return 0.0\n",
        "        ws = [w.lower() for w in simple_words(text)]\n",
        "        if not ws: return 0.0\n",
        "        return sum(1 for w in ws if w in terms) / max(1, len(ws))\n",
        "\n",
        "class FeatureExtractor12:\n",
        "    def __init__(self, tlex: TermsLexicon): self.tlex = tlex\n",
        "    def extract_one(self, text: str, lang: str) -> np.ndarray:\n",
        "        text = \"\" if text is None else str(text); lang = (lang or \"en\").lower()\n",
        "        ws = simple_words(text); n_words = len(simple_words(text))\n",
        "\n",
        "        chars = len(text)\n",
        "        words = n_words\n",
        "        sents = sent_count(text)\n",
        "\n",
        "        if lang == \"en\" and _HAS_TEXTSTAT and text.strip():\n",
        "            fre, fog = _finite_or_zero(textstat.flesch_reading_ease(text)), _finite_or_zero(textstat.gunning_fog(text))\n",
        "        else: fre, fog = 0.0, 0.0\n",
        "\n",
        "        eng_pct = self.tlex.pct_in_text(text, lang)\n",
        "        punc = punct_count(text)\n",
        "        nums, dec_cnt = extract_numbers(text)\n",
        "        nnums = len(nums)\n",
        "        avg_mag = float(np.mean(nums)) if nums else 0.0\n",
        "        dec_ratio = float(dec_cnt / len(nums)) if nums else 0.0\n",
        "\n",
        "        low = text.lower()\n",
        "        has_std = 1.0 if any(t in low for t in STD_TERMS) else 0.0\n",
        "        has_saf = 1.0 if any(t in low for t in SAFETY_TERMS) else 0.0\n",
        "\n",
        "        feats = np.array([chars, words, sents, fre, fog, eng_pct, punc, nnums, has_std, has_saf, avg_mag, dec_ratio], dtype=np.float32)\n",
        "        if not np.all(np.isfinite(feats)): feats = np.nan_to_num(feats, nan=0.0, posinf=1e12, neginf=0.0)\n",
        "        return feats.astype(np.float32)\n",
        "\n",
        "    def extract_df(self, df: pd.DataFrame) -> np.ndarray:\n",
        "        assert 'content' in df.columns\n",
        "        if 'lang' not in df.columns: df = df.copy(); df['lang'] = 'en'\n",
        "        rows = [self.extract_one(r.get(\"content\",\"\"), r.get(\"lang\",\"en\")) for _, r in tqdm(df.iterrows(), total=len(df), desc=\"Extracting features\")]\n",
        "        return np.stack(rows, axis=0).astype(np.float32)\n",
        "\n",
        "def build_feature_matrix(df: pd.DataFrame, cfg: Config, lex: TermsLexicon) -> Tuple[np.ndarray, np.ndarray, list]:\n",
        "    fe = FeatureExtractor12(lex)\n",
        "    X = fe.extract_df(df)\n",
        "    y = np.array([cfg.LABEL2ID[str(x)] for x in df[cfg.LABEL_COL].astype(str).tolist()], dtype=np.int32)\n",
        "    return X, y, df[cfg.TEXT_COL].tolist()\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, tokenizer, max_len: int, label2id: Dict[str, int]):\n",
        "        self.texts = df[\"content\"].astype(str).tolist()\n",
        "        self.labels = [label2id[str(x)] for x in df[\"label\"].astype(str).tolist()]\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tokenizer(self.texts[idx], truncation=True, max_length=self.max_len, padding=False, return_tensors=\"pt\")\n",
        "        enc = {k: v.squeeze(0) for k, v in enc.items()}\n",
        "        enc[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return enc\n",
        "\n",
        "# ===================== Metrics / CIs =====================\n",
        "def compute_metrics(y_true, y_pred, y_prob):\n",
        "    metrics = {\n",
        "        \"precision_real\": precision_score(y_true, y_pred, pos_label=0),\n",
        "        \"recall_real\": recall_score(y_true, y_pred, pos_label=0),\n",
        "        \"f1_real\": f1_score(y_true, y_pred, pos_label=0),\n",
        "        \"precision_misinfo\": precision_score(y_true, y_pred, pos_label=1),\n",
        "        \"recall_misinfo\": recall_score(y_true, y_pred, pos_label=1),\n",
        "        \"f1_misinfo\": f1_score(y_true, y_pred, pos_label=1),\n",
        "        \"macro_f1\": f1_score(y_true, y_pred, average='macro'),\n",
        "        \"micro_f1\": f1_score(y_true, y_pred, average='micro'),\n",
        "        \"weighted_f1\": f1_score(y_true, y_pred, average='weighted'),\n",
        "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "def bootstrap_ci(y_true, y_pred, y_prob, n_resamples=1000, alpha=0.95):\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_pred = np.asarray(y_pred)\n",
        "    N = len(y_true)\n",
        "    lo, hi = (1 - alpha) / 2, 1 - (1 - alpha) / 2\n",
        "    f1_real_vals, f1_misinfo_vals, macro_vals, micro_vals, weighted_vals = [], [], [], [], []\n",
        "\n",
        "    for _ in range(n_resamples):\n",
        "        idx = resample(np.arange(N), n_samples=N, replace=True)\n",
        "        yt, yp = y_true[idx], y_pred[idx]\n",
        "        with np.errstate(divide='ignore', invalid='ignore'):\n",
        "            f1_real_vals.append(f1_score(yt, yp, pos_label=0, average='binary', zero_division=0))\n",
        "            f1_misinfo_vals.append(f1_score(yt, yp, pos_label=1, average='binary', zero_division=0))\n",
        "            macro_vals.append(f1_score(yt, yp, average='macro', zero_division=0))\n",
        "            micro_vals.append(f1_score(yt, yp, average='micro', zero_division=0))\n",
        "            weighted_vals.append(f1_score(yt, yp, average='weighted', zero_division=0))\n",
        "    results = {\n",
        "        'F1-score Real (0)': np.percentile(f1_real_vals, [lo * 100, hi * 100]).tolist(),\n",
        "        'F1-score Misinformation (1)': np.percentile(f1_misinfo_vals, [lo * 100, hi * 100]).tolist(),\n",
        "        'Macro F1': np.percentile(macro_vals, [lo * 100, hi * 100]).tolist(),\n",
        "        'Micro F1': np.percentile(micro_vals, [lo * 100, hi * 100]).tolist(),\n",
        "        'Weighted F1': np.percentile(weighted_vals, [lo * 100, hi * 100]).tolist(),\n",
        "    }\n",
        "    return results\n",
        "\n",
        "def run_xlmr_evaluation(model, dataloader, device):\n",
        "    model.eval()\n",
        "    all_labels, all_preds, all_probs = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating XLM-R\", leave=False):\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n",
        "            labels = batch['labels'].to(device)\n",
        "            outputs = model(**inputs, labels=None)\n",
        "            logits = outputs.logits\n",
        "            probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
        "            preds = np.argmax(probs, axis=-1)\n",
        "            all_labels.extend(labels.cpu().tolist())\n",
        "            all_preds.extend(preds.tolist())\n",
        "            all_probs.extend(probs.tolist())\n",
        "    return np.array(all_labels), np.array(all_preds), np.array(all_probs)\n",
        "\n",
        "# ===================== Main Execution =====================\n",
        "if __name__ == \"__main__\":\n",
        "    set_seed(42)\n",
        "    cfg = Config()\n",
        "\n",
        "    # Check for file existence\n",
        "    if not all(os.path.exists(p) for p in [cfg.TRAIN_CSV, cfg.TEST_CSV]):\n",
        "        print(f\"Error: Missing data files in {cfg.BASE_DIR}\")\n",
        "        exit()\n",
        "\n",
        "    # --- Part 1: Data Leakage Check ---\n",
        "    print(\"--- Running Data Leakage Check ---\")\n",
        "    train_df = pd.read_csv(cfg.TRAIN_CSV)\n",
        "    test_df = pd.read_csv(cfg.TEST_CSV)\n",
        "\n",
        "    train_texts = set(train_df['content'].astype(str))\n",
        "    test_texts = set(test_df['content'].astype(str))\n",
        "\n",
        "    leakage_count = len(train_texts.intersection(test_texts))\n",
        "    if leakage_count > 0:\n",
        "        print(f\"⚠️ Warning: Found {leakage_count} overlapping texts between train and test sets!\")\n",
        "        print(\"This may be the cause of your high scores.\")\n",
        "    else:\n",
        "        print(\"✅ No direct text overlap found between train and test sets.\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # --- Part 2: XGBoost Evaluation ---\n",
        "    print(\"\\n--- Running XGBoost + Features Evaluation ---\")\n",
        "\n",
        "    if not all(os.path.exists(p) for p in [cfg.XGB_MODEL_JSON, cfg.XGB_SCALER_PATH]):\n",
        "        print(\"⚠️ Skipping XGBoost evaluation: model or scaler files not found.\")\n",
        "    else:\n",
        "        try:\n",
        "            clf = xgb.XGBClassifier(); clf.load_model(cfg.XGB_MODEL_JSON)\n",
        "            lex = TermsLexicon(cfg.TERMS_CSV)\n",
        "            scaler = joblib.load(cfg.XGB_SCALER_PATH)\n",
        "            X_test, y_true, _ = build_feature_matrix(test_df, cfg, lex)\n",
        "            X_test_scaled = scaler.transform(X_test)\n",
        "            y_prob = clf.predict_proba(X_test_scaled)\n",
        "            y_pred = y_prob.argmax(axis=1)\n",
        "\n",
        "            metrics = compute_metrics(y_true, y_pred, y_prob)\n",
        "            cis = bootstrap_ci(y_true, y_pred, y_prob)\n",
        "\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(\"XGBoost + Features on EMC Test Set\")\n",
        "            print(\"=\"*50)\n",
        "            print(f\"AUC-ROC Score: {roc_auc_score(y_true, y_prob[:, 1]):.4f}\\n\")\n",
        "\n",
        "            table_data = [\n",
        "                (\"Precision\", \"Real (0)\", f\"{metrics['precision_real']:.3f}\"),\n",
        "                (\"Recall\", \"Real (0)\", f\"{metrics['recall_real']:.3f}\"),\n",
        "                (\"F1-score\", \"Real (0)\", f\"{metrics['f1_real']:.3f} [{cis['F1-score Real (0)'][0]:.4f}, {cis['F1-score Real (0)'][1]:.4f}]\"),\n",
        "                (\"\", \"\", \"\"),\n",
        "                (\"Precision\", \"Misinformation (1)\", f\"{metrics['precision_misinfo']:.3f}\"),\n",
        "                (\"Recall\", \"Misinformation (1)\", f\"{metrics['recall_misinfo']:.3f}\"),\n",
        "                (\"F1-score\", \"Misinformation (1)\", f\"{metrics['f1_misinfo']:.3f} [{cis['F1-score Misinformation (1)'][0]:.4f}, {cis['F1-score Misinformation (1)'][1]:.4f}]\"),\n",
        "                (\"\", \"\", \"\"),\n",
        "                (\"Macro F1\", \"--\", f\"{metrics['macro_f1']:.3f} [{cis['Macro F1'][0]:.4f}, {cis['Macro F1'][1]:.4f}]\"),\n",
        "                (\"Micro F1\", \"--\", f\"{metrics['micro_f1']:.3f} [{cis['Micro F1'][0]:.4f}, {cis['Micro F1'][1]:.4f}]\"),\n",
        "                (\"Weighted F1\", \"--\", f\"{metrics['weighted_f1']:.3f} [{cis['Weighted F1'][0]:.4f}, {cis['Weighted F1'][1]:.4f}]\"),\n",
        "            ]\n",
        "            print(f\"{'Metric':<25} {'Class':<20} {'Value [95% CI]':<30}\")\n",
        "            print(\"-\" * 75)\n",
        "            for row in table_data:\n",
        "                if row[0]: print(f\"{row[0]:<25} {row[1]:<20} {row[2]:<30}\")\n",
        "                else: print(\"\")\n",
        "\n",
        "            os.makedirs(os.path.dirname(cfg.XGB_AUC_ROC_PLOT_PATH), exist_ok=True)\n",
        "            fpr, tpr, _ = roc_curve(y_true, y_prob[:, 1])\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "            plt.figure(figsize=(8, 6)); plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})'); plt.plot([0, 1], [0, 1], '--'); plt.legend(); plt.title('XGBoost ROC Curve'); plt.savefig(cfg.XGB_AUC_ROC_PLOT_PATH)\n",
        "            print(f\"✅ AUC-ROC plot saved to: {cfg.XGB_AUC_ROC_PLOT_PATH}\")\n",
        "\n",
        "            result = permutation_importance(clf, X_test_scaled, y_true, n_repeats=10, random_state=42, n_jobs=-1)\n",
        "            feat_names = [\"Chars\", \"Words\", \"Sents\", \"Flesch RE (en)\", \"Gunning Fog (en)\", \"% Eng Terms\", \"Punctuation\", \"Number Count\", \"Contains Standard\", \"Contains Safety\", \"Avg Number Mag\", \"Decimal Ratio\"]\n",
        "            importance_df = pd.DataFrame({'Feature': feat_names, 'Importance_Mean': result.importances_mean, 'Importance_Std': result.importances_std}).sort_values('Importance_Mean', ascending=True)\n",
        "            plt.figure(figsize=(10, 8)); plt.barh(importance_df['Feature'], importance_df['Importance_Mean'], xerr=importance_df['Importance_Std']); plt.title('XGBoost Permutation Importance'); plt.tight_layout(); plt.savefig(cfg.XGB_PERMUTATION_IMPORTANCE_PLOT_PATH)\n",
        "            print(f\"✅ Permutation Importance plot saved to: {cfg.XGB_PERMUTATION_IMPORTANCE_PLOT_PATH}\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during XGBoost evaluation: {e}\")\n",
        "\n",
        "    # --- Part 3: XLM-R Only Evaluation ---\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"--- Running XLM-R Only Evaluation ---\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    if not os.path.exists(cfg.XLMR_MODEL_PATH):\n",
        "        print(\"⚠️ Skipping XLM-R evaluation: model files not found.\")\n",
        "    else:\n",
        "        try:\n",
        "            model = XLMRobertaForSequenceClassification.from_pretrained(cfg.XLMR_MODEL_PATH).to(cfg.DEVICE)\n",
        "            tokenizer = XLMRobertaTokenizerFast.from_pretrained(cfg.XLMR_MODEL_PATH)\n",
        "            test_ds = TextDataset(test_df, cfg.TEXT_COL, cfg.LABEL_COL, tokenizer, cfg.MAX_LEN, cfg.LABEL2ID)\n",
        "            collator = DataCollatorWithPadding(tokenizer)\n",
        "            test_loader = DataLoader(test_ds, batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
        "\n",
        "            y_true, y_pred, y_prob = run_xlmr_evaluation(model, test_loader, cfg.DEVICE)\n",
        "            metrics = compute_metrics(y_true, y_pred, y_prob)\n",
        "            cis = bootstrap_ci(y_true, y_pred, y_prob)\n",
        "\n",
        "            print(f\"AUC-ROC Score: {roc_auc_score(y_true, y_prob[:, 1]):.4f}\\n\")\n",
        "            table_data = [\n",
        "                (\"Precision\", \"Real (0)\", f\"{metrics['precision_real']:.3f}\"),\n",
        "                (\"Recall\", \"Real (0)\", f\"{metrics['recall_real']:.3f}\"),\n",
        "                (\"F1-score\", \"Real (0)\", f\"{metrics['f1_real']:.3f} [{cis['F1-score Real (0)'][0]:.4f}, {cis['F1-score Real (0)'][1]:.4f}]\"),\n",
        "                (\"\", \"\", \"\"),\n",
        "                (\"Precision\", \"Misinformation (1)\", f\"{metrics['precision_misinfo']:.3f}\"),\n",
        "                (\"Recall\", \"Misinformation (1)\", f\"{metrics['recall_misinfo']:.3f}\"),\n",
        "                (\"F1-score\", \"Misinformation (1)\", f\"{metrics['f1_misinfo']:.3f} [{cis['F1-score Misinformation (1)'][0]:.4f}, {cis['F1-score Misinformation (1)'][1]:.4f}]\"),\n",
        "                (\"\", \"\", \"\"),\n",
        "                (\"Macro F1\", \"--\", f\"{metrics['macro_f1']:.3f} [{cis['Macro F1'][0]:.4f}, {cis['Macro F1'][1]:.4f}]\"),\n",
        "                (\"Micro F1\", \"--\", f\"{metrics['micro_f1']:.3f} [{cis['Micro F1'][0]:.4f}, {cis['Micro F1'][1]:.4f}]\"),\n",
        "                (\"Weighted F1\", \"--\", f\"{metrics['weighted_f1']:.3f} [{cis['Weighted F1'][0]:.4f}, {cis['Weighted F1'][1]:.4f}]\"),\n",
        "            ]\n",
        "            print(f\"{'Metric':<25} {'Class':<20} {'Value [95% CI]':<30}\")\n",
        "            print(\"-\" * 75)\n",
        "            for row in table_data:\n",
        "                if row[0]: print(f\"{row[0]:<25} {row[1]:<20} {row[2]:<30}\")\n",
        "                else: print(\"\")\n",
        "\n",
        "            os.makedirs(os.path.dirname(cfg.XLMR_AUC_ROC_PLOT_PATH), exist_ok=True)\n",
        "            fpr, tpr, _ = roc_curve(y_true, y_prob[:, 1])\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "            plt.figure(figsize=(8, 6)); plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})'); plt.plot([0, 1], [0, 1], '--'); plt.legend(); plt.title('XLM-R ROC Curve'); plt.savefig(cfg.XLMR_AUC_ROC_PLOT_PATH)\n",
        "            print(f\"✅ AUC-ROC plot saved to: {cfg.XLMR_AUC_ROC_PLOT_PATH}\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during XLM-R evaluation: {e}\")\n",
        "\n",
        "    print(\"\\n✅ All evaluations complete.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ISWVfA1edRe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XLM-R TEXT ONLY"
      ],
      "metadata": {
        "id": "M1nu1ReSjVXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import random\n",
        "from typing import Optional, Dict, Tuple, List, Any\n",
        "from dataclasses import dataclass, field\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import (\n",
        "    f1_score, accuracy_score, precision_score, recall_score,\n",
        "    roc_auc_score, classification_report, roc_curve, auc\n",
        ")\n",
        "from sklearn.utils import resample\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    XLMRobertaForSequenceClassification,\n",
        "    XLMRobertaTokenizerFast,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "\n",
        "\n",
        "# ===================== Config =====================\n",
        "@dataclass\n",
        "class Config:\n",
        "    BASE_DIR: str = \"/content/drive/MyDrive/emc\"\n",
        "    TEST_CSV: str = os.path.join(BASE_DIR, \"test.csv\")\n",
        "    MODEL_PATH: str = os.path.join(BASE_DIR, \"xlmr_only_outputs/best_model\")\n",
        "    MODEL_NAME: str = \"xlm-roberta-base\"\n",
        "\n",
        "    TEXT_COL: str = \"content\"\n",
        "    LABEL_COL: str = \"label\"\n",
        "    LANG_COL: str = \"lang\"\n",
        "\n",
        "    N_CLASSES: int = 2\n",
        "    MAX_LEN: int = 256\n",
        "    BATCH_SIZE: int = 32\n",
        "\n",
        "    # Output paths for figures\n",
        "    AUC_ROC_PLOT_PATH: str = os.path.join(BASE_DIR, \"xlmr_only_outputs/auc_roc_plot.png\")\n",
        "\n",
        "    # Use the same label mapping as training\n",
        "    LABEL2ID: Dict[str, int] = field(default_factory=lambda: {\"0\": 0, \"1\": 1})\n",
        "    ID2LABEL: Dict[int, str] = field(default_factory=lambda: {0: \"Real\", 1: \"Misinformation\"})\n",
        "\n",
        "    DEVICE: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ===================== Reproducibility =====================\n",
        "def set_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# ===================== Dataset & DataLoader =====================\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, text_col: str, label_col: str, tokenizer, max_len: int, label2id: Dict[str, int]):\n",
        "        self.texts = df[text_col].astype(str).tolist()\n",
        "        self.labels_raw = df[label_col].tolist()\n",
        "        self.label2id = label2id\n",
        "        self.ids = [self.label2id[str(x)] if str(x) in self.label2id else self.label2id[x] for x in map(str, self.labels_raw)]\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            padding=False,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        enc = {k: v.squeeze(0) for k, v in enc.items()}\n",
        "        enc[\"labels\"] = torch.tensor(self.ids[idx], dtype=torch.long)\n",
        "        return enc\n",
        "\n",
        "# ===================== Metrics / CIs =====================\n",
        "def compute_metrics(y_true, y_pred, y_prob):\n",
        "    metrics = {\n",
        "        \"precision_real\": precision_score(y_true, y_pred, pos_label=0),\n",
        "        \"recall_real\": recall_score(y_true, y_pred, pos_label=0),\n",
        "        \"f1_real\": f1_score(y_true, y_pred, pos_label=0),\n",
        "        \"precision_misinfo\": precision_score(y_true, y_pred, pos_label=1),\n",
        "        \"recall_misinfo\": recall_score(y_true, y_pred, pos_label=1),\n",
        "        \"f1_misinfo\": f1_score(y_true, y_pred, pos_label=1),\n",
        "        \"macro_f1\": f1_score(y_true, y_pred, average='macro'),\n",
        "        \"micro_f1\": f1_score(y_true, y_pred, average='micro'),\n",
        "        \"weighted_f1\": f1_score(y_true, y_pred, average='weighted'),\n",
        "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "def bootstrap_ci(y_true, y_pred, y_prob, n_resamples=1000, alpha=0.95):\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_pred = np.asarray(y_pred)\n",
        "    N = len(y_true)\n",
        "    lo = (1 - alpha) / 2\n",
        "    hi = 1 - lo\n",
        "\n",
        "    f1_real_vals, f1_misinfo_vals, macro_vals, micro_vals, weighted_vals = [], [], [], [], []\n",
        "\n",
        "    for _ in range(n_resamples):\n",
        "        idx = resample(np.arange(N), n_samples=N, replace=True)\n",
        "        yt, yp = y_true[idx], y_pred[idx]\n",
        "\n",
        "        with np.errstate(divide='ignore', invalid='ignore'):\n",
        "            f1_real_vals.append(f1_score(yt, yp, pos_label=0, average='binary', zero_division=0))\n",
        "            f1_misinfo_vals.append(f1_score(yt, yp, pos_label=1, average='binary', zero_division=0))\n",
        "            macro_vals.append(f1_score(yt, yp, average='macro', zero_division=0))\n",
        "            micro_vals.append(f1_score(yt, yp, average='micro', zero_division=0))\n",
        "            weighted_vals.append(f1_score(yt, yp, average='weighted', zero_division=0))\n",
        "\n",
        "    results = {\n",
        "        'F1-score Real (0)': np.percentile(f1_real_vals, [lo * 100, hi * 100]).tolist(),\n",
        "        'F1-score Misinformation (1)': np.percentile(f1_misinfo_vals, [lo * 100, hi * 100]).tolist(),\n",
        "        'Macro F1': np.percentile(macro_vals, [lo * 100, hi * 100]).tolist(),\n",
        "        'Micro F1': np.percentile(micro_vals, [lo * 100, hi * 100]).tolist(),\n",
        "        'Weighted F1': np.percentile(weighted_vals, [lo * 100, hi * 100]).tolist(),\n",
        "    }\n",
        "    return results\n",
        "\n",
        "# ===================== Evaluation Loop =====================\n",
        "def run_evaluation(model, dataloader, device):\n",
        "    model.eval()\n",
        "    all_labels, all_preds, all_probs = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(**inputs, labels=None)\n",
        "            logits = outputs.logits\n",
        "            probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
        "            preds = np.argmax(probs, axis=-1)\n",
        "\n",
        "            all_labels.extend(labels.cpu().tolist())\n",
        "            all_preds.extend(preds.tolist())\n",
        "            all_probs.extend(probs.tolist())\n",
        "\n",
        "    return np.array(all_labels), np.array(all_preds), np.array(all_probs)\n",
        "\n",
        "\n",
        "# ===================== Main Execution =====================\n",
        "if __name__ == \"__main__\":\n",
        "    set_seed(42)\n",
        "    cfg = Config()\n",
        "\n",
        "    os.makedirs(os.path.dirname(cfg.AUC_ROC_PLOT_PATH), exist_ok=True)\n",
        "\n",
        "    if not os.path.exists(cfg.MODEL_PATH):\n",
        "        print(f\"Error: Model directory not found at {cfg.MODEL_PATH}\")\n",
        "        exit()\n",
        "    if not os.path.exists(cfg.TEST_CSV):\n",
        "        print(f\"Error: Test data not found at {cfg.TEST_CSV}\")\n",
        "        exit()\n",
        "\n",
        "    print(\"--- Loading models and data for evaluation ---\")\n",
        "\n",
        "    try:\n",
        "        model = XLMRobertaForSequenceClassification.from_pretrained(cfg.MODEL_PATH).to(cfg.DEVICE)\n",
        "        tokenizer = XLMRobertaTokenizerFast.from_pretrained(cfg.MODEL_PATH)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load model or tokenizer from {cfg.MODEL_PATH}: {e}\")\n",
        "        exit()\n",
        "\n",
        "    test_df = pd.read_csv(cfg.TEST_CSV)\n",
        "\n",
        "    test_ds = TextDataset(test_df, cfg.TEXT_COL, cfg.LABEL_COL, tokenizer, cfg.MAX_LEN, cfg.LABEL2ID)\n",
        "    collator = DataCollatorWithPadding(tokenizer)\n",
        "    test_loader = DataLoader(test_ds, batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
        "\n",
        "    print(\"\\n--- Running evaluation on test set ---\")\n",
        "    y_true, y_pred, y_prob = run_evaluation(model, test_loader, cfg.DEVICE)\n",
        "\n",
        "    # --- Compute and print general F1 scores ---\n",
        "    metrics = compute_metrics(y_true, y_pred, y_prob)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"XLM-R Only on EMC Test Set\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Macro F1-Score: {metrics['macro_f1']:.4f}\")\n",
        "    print(f\"Micro F1-Score: {metrics['micro_f1']:.4f}\")\n",
        "    print(f\"Weighted F1-Score: {metrics['weighted_f1']:.4f}\")\n",
        "\n",
        "    # --- Compute and print metrics table with CIs ---\n",
        "    print(\"\\n--- Bootstrapping Confidence Intervals ---\")\n",
        "    cis = bootstrap_ci(y_true, y_pred, y_prob)\n",
        "\n",
        "    print(\"\\n\" + \"-\"*75)\n",
        "    print(f\"{'Metric':<25} {'Class':<20} {'Value [95% CI]':<30}\")\n",
        "    print(\"-\" * 75)\n",
        "\n",
        "    table_data = [\n",
        "        (\"Precision\", \"Real (0)\", f\"{metrics['precision_real']:.3f}\"),\n",
        "        (\"Recall\", \"Real (0)\", f\"{metrics['recall_real']:.3f}\"),\n",
        "        (\"F1-score\", \"Real (0)\", f\"{metrics['f1_real']:.3f} [{cis['F1-score Real (0)'][0]:.4f}, {cis['F1-score Real (0)'][1]:.4f}]\"),\n",
        "        (\"\", \"\", \"\"), # Spacer\n",
        "        (\"Precision\", \"Misinformation (1)\", f\"{metrics['precision_misinfo']:.3f}\"),\n",
        "        (\"Recall\", \"Misinformation (1)\", f\"{metrics['recall_misinfo']:.3f}\"),\n",
        "        (\"F1-score\", \"Misinformation (1)\", f\"{metrics['f1_misinfo']:.3f} [{cis['F1-score Misinformation (1)'][0]:.4f}, {cis['F1-score Misinformation (1)'][1]:.4f}]\"),\n",
        "        (\"\", \"\", \"\"), # Spacer\n",
        "        (\"Macro F1\", \"--\", f\"{metrics['macro_f1']:.3f} [{cis['Macro F1'][0]:.4f}, {cis['Macro F1'][1]:.4f}]\"),\n",
        "        (\"Micro F1\", \"--\", f\"{metrics['micro_f1']:.3f} [{cis['Micro F1'][0]:.4f}, {cis['Micro F1'][1]:.4f}]\"),\n",
        "        (\"Weighted F1\", \"--\", f\"{metrics['weighted_f1']:.3f} [{cis['Weighted F1'][0]:.4f}, {cis['Weighted F1'][1]:.4f}]\"),\n",
        "    ]\n",
        "\n",
        "    for row in table_data:\n",
        "        if row[0]:\n",
        "            print(f\"{row[0]:<25} {row[1]:<20} {row[2]:<30}\")\n",
        "        else:\n",
        "            print(\"\")\n",
        "\n",
        "    # --- Generate AUC-ROC Curve ---\n",
        "    print(\"\\n--- Generating AUC-ROC plot... ---\")\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_prob[:, 1])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate', fontsize=12)\n",
        "    plt.ylabel('True Positive Rate', fontsize=12)\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=14, fontweight='bold')\n",
        "    plt.legend(loc='lower right', fontsize=10)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(cfg.AUC_ROC_PLOT_PATH, dpi=300)\n",
        "    print(f\"✅ AUC-ROC plot saved to: {cfg.AUC_ROC_PLOT_PATH}\")\n",
        "\n",
        "    print(\"\\n✅ Evaluation complete.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rvspB6hejcz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import random\n",
        "from typing import Optional, Dict, Tuple, List, Any\n",
        "from dataclasses import dataclass, field\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    f1_score, accuracy_score, precision_score, recall_score,\n",
        "    roc_auc_score, classification_report, roc_curve, auc\n",
        ")\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.inspection import permutation_importance\n",
        "import joblib\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost.callback import EarlyStopping\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    XLMRobertaForSequenceClassification,\n",
        "    XLMRobertaModel,\n",
        "    XLMRobertaTokenizerFast,\n",
        "    DataCollatorWithPadding,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "\n",
        "try:\n",
        "    import textstat\n",
        "    _HAS_TEXTSTAT = True\n",
        "except Exception:\n",
        "    _HAS_TEXTSTAT = False\n",
        "\n",
        "# ===================== Config =====================\n",
        "@dataclass\n",
        "class Config:\n",
        "    BASE_DIR: str = \"/content/drive/MyDrive/emc\"\n",
        "    RAW_CORPUS_CSV: str = os.path.join(BASE_DIR, \"all_data.csv\")\n",
        "    TERMS_CSV: str = os.path.join(BASE_DIR, \"engineering_terms.csv\")\n",
        "\n",
        "    CLEAN_TRAIN_CSV: str = os.path.join(BASE_DIR, \"train.csv\")\n",
        "    CLEAN_VAL_CSV: str = os.path.join(BASE_DIR, \"val.csv\")\n",
        "    CLEAN_TEST_CSV: str = os.path.join(BASE_DIR, \"test.csv\")\n",
        "\n",
        "    XGB_OUTPUTS: str = os.path.join(BASE_DIR, \"xgb_outputs_clean\")\n",
        "    XLM_R_OUTPUTS: str = os.path.join(BASE_DIR, \"xlmr_only_outputs_clean\")\n",
        "    SIMPLE_OUTPUTS: str = os.path.join(BASE_DIR, \"simple_fusion_outputs_clean\")\n",
        "    GATED_OUTPUTS: str = os.path.join(BASE_DIR, \"gated_fusion_outputs_clean\")\n",
        "\n",
        "    TEXT_COL: str = \"content\"\n",
        "    LABEL_COL: str = \"label\"\n",
        "    LANG_COL: str = \"lang\"\n",
        "\n",
        "    N_FEATURES: int = 12\n",
        "    N_CLASSES: int = 2\n",
        "    MAX_LEN: int = 256\n",
        "    BATCH_SIZE: int = 16\n",
        "\n",
        "    XLM_R_EPOCHS: int = 5\n",
        "    XLM_R_LR: float = 2e-5\n",
        "    XLM_R_PATIENCE: int = 3\n",
        "\n",
        "    XGB_ESTIMATORS: int = 2000\n",
        "    XGB_LR: float = 0.03\n",
        "    XGB_MAX_DEPTH: int = 6\n",
        "    XGB_EARLY_STOP: int = 100\n",
        "\n",
        "    LABEL2ID: Dict[str, int] = field(default_factory=lambda: {\"0\": 0, \"1\": 1})\n",
        "    ID2LABEL: Dict[int, str] = field(default_factory=lambda: {0: \"Real\", 1: \"Misinformation\"})\n",
        "\n",
        "    DEVICE: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    MODEL_NAME: str = \"xlm-roberta-base\"\n",
        "\n",
        "    COMBINED_AUC_ROC_PLOT_PATH: str = os.path.join(BASE_DIR, \"combined_auc_roc.png\")\n",
        "\n",
        "# ===================== Reproducibility =====================\n",
        "def set_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# ===================== Data & Feature Extraction =====================\n",
        "def clean_and_split_data(raw_csv_path, train_path, val_path, test_path):\n",
        "    print(\"--- Cleaning and splitting data ---\")\n",
        "    if not os.path.exists(raw_csv_path):\n",
        "        print(f\"Error: Raw corpus not found at {raw_csv_path}\")\n",
        "        return\n",
        "\n",
        "    df = pd.read_csv(raw_csv_path)\n",
        "    df.dropna(subset=['content', 'label'], inplace=True)\n",
        "    df.drop_duplicates(subset=['content'], inplace=True)\n",
        "\n",
        "    X, y = df, df['label']\n",
        "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
        "    train_idx, test_val_idx = next(sss.split(X, y))\n",
        "\n",
        "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
        "    X_test_val, y_test_val = X.iloc[test_val_idx], y.iloc[test_val_idx]\n",
        "\n",
        "    sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
        "    val_idx, test_idx = next(sss2.split(X_test_val, y_test_val))\n",
        "\n",
        "    X_train, X_val, X_test = X.iloc[train_idx], X_test_val.iloc[val_idx], X_test_val.iloc[test_idx]\n",
        "\n",
        "    train_texts = set(X_train['content'].astype(str))\n",
        "    val_texts = set(X_val['content'].astype(str))\n",
        "    test_texts = set(X_test['content'].astype(str))\n",
        "\n",
        "    if train_texts.intersection(test_texts) or train_texts.intersection(val_texts) or val_texts.intersection(test_texts):\n",
        "        print(\"⚠️ Warning: Data leakage detected after splitting. This should not happen with StratifiedShuffleSplit. Review your data.\")\n",
        "    else:\n",
        "        print(\"✅ No direct text overlap found between train, val, and test sets.\")\n",
        "\n",
        "    X_train.to_csv(train_path, index=False)\n",
        "    X_val.to_csv(val_path, index=False)\n",
        "    X_test.to_csv(test_path, index=False)\n",
        "\n",
        "    print(f\"✅ Data splits saved: Train ({len(X_train)}), Val ({len(X_val)}), Test ({len(X_test)})\")\n",
        "\n",
        "STD_TERMS = {\"iso\", \"asme\", \"ieee\", \"din\", \"ansi\", \"iec\", \"ul\", \"astm\", \"en\"}\n",
        "SAFETY_TERMS = {\"safety\", \"hazard\", \"warning\", \"risk\", \"caution\", \"danger\", \"emergency\"}\n",
        "_WORD_RE = re.compile(r\"\\w+\", re.UNICODE)\n",
        "_NUM_RE = re.compile(r'[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?')\n",
        "\n",
        "def simple_words(t: str) -> List[str]: return _WORD_RE.findall(t or \"\")\n",
        "def sent_count(t: str) -> int:\n",
        "    if not t: return 0\n",
        "    return max(1, len(re.split(r'[.!?]+[\\s\\n]+', t)))\n",
        "def punct_count(t: str) -> int: return sum(1 for ch in (t or \"\") if ch in \".,;:!?\")\n",
        "def extract_numbers(text: str):\n",
        "    nums, dec = [], 0\n",
        "    for m in _NUM_RE.finditer(text or \"\"):\n",
        "        s = m.group(0)\n",
        "        try:\n",
        "            v = float(s)\n",
        "            if ('.' in s) or ('e' in s.lower()): dec += 1\n",
        "            nums.append(abs(v))\n",
        "        except: pass\n",
        "    return nums, dec\n",
        "def _finite_or_zero(x: float) -> float: return float(x) if np.isfinite(x) else 0.0\n",
        "\n",
        "class TermsLexicon:\n",
        "    def __init__(self, csv_path: str, term_col=\"terms\", lang_col=\"lang\"):\n",
        "        if not os.path.exists(csv_path): raise FileNotFoundError(csv_path)\n",
        "        df = pd.read_csv(csv_path)\n",
        "        if term_col not in df.columns: raise ValueError(f\"Missing '{term_col}'\")\n",
        "        if lang_col not in df.columns: df[lang_col] = 'en'\n",
        "        self.by_lang = {str(l).lower(): set(str(x).strip().lower() for x in d[term_col].dropna().tolist() if str(x).strip()) for l, d in df.groupby(lang_col)}\n",
        "    def pct_in_text(self, text: str, lang: str) -> float:\n",
        "        if not text: return 0.0\n",
        "        terms = self.by_lang.get((lang or \"en\").lower(), set())\n",
        "        if not terms: return 0.0\n",
        "        ws = [w.lower() for w in simple_words(text)]\n",
        "        if not ws: return 0.0\n",
        "        return sum(1 for w in ws if w in terms) / max(1, len(ws))\n",
        "\n",
        "class FeatureExtractor12:\n",
        "    def __init__(self, tlex: TermsLexicon): self.tlex = tlex\n",
        "    def extract_one(self, text: str, lang: str) -> np.ndarray:\n",
        "        text = \"\" if text is None else str(text); lang = (lang or \"en\").lower()\n",
        "        ws = simple_words(text); n_words = len(simple_words(text))\n",
        "\n",
        "        chars = len(text)\n",
        "        words = n_words\n",
        "        sents = sent_count(text)\n",
        "\n",
        "        if lang == \"en\" and _HAS_TEXTSTAT and text.strip():\n",
        "            fre, fog = _finite_or_zero(textstat.flesch_reading_ease(text)), _finite_or_zero(textstat.gunning_fog(text))\n",
        "        else: fre, fog = 0.0, 0.0\n",
        "\n",
        "        eng_pct = self.tlex.pct_in_text(text, lang)\n",
        "        punc = punct_count(text)\n",
        "        nums, dec_cnt = extract_numbers(text)\n",
        "        nnums = len(nums)\n",
        "        avg_mag = float(np.mean(nums)) if nums else 0.0\n",
        "        dec_ratio = float(dec_cnt / len(nums)) if nums else 0.0\n",
        "\n",
        "        low = text.lower()\n",
        "        has_std = 1.0 if any(t in low for t in STD_TERMS) else 0.0\n",
        "        has_saf = 1.0 if any(t in low for t in SAFETY_TERMS) else 0.0\n",
        "\n",
        "        feats = np.array([chars, words, sents, fre, fog, eng_pct, punc, nnums, has_std, has_saf, avg_mag, dec_ratio], dtype=np.float32)\n",
        "        if not np.all(np.isfinite(feats)): feats = np.nan_to_num(feats, nan=0.0, posinf=1e12, neginf=0.0)\n",
        "        return feats.astype(np.float32)\n",
        "\n",
        "    def extract_df(self, df: pd.DataFrame) -> np.ndarray:\n",
        "        assert 'content' in df.columns\n",
        "        if 'lang' not in df.columns: df = df.copy(); df['lang'] = 'en'\n",
        "        rows = [self.extract_one(r.get(\"content\",\"\"), r.get(\"lang\",\"en\")) for _, r in tqdm(df.iterrows(), total=len(df), desc=\"Extracting features\")]\n",
        "        return np.stack(rows, axis=0).astype(np.float32)\n",
        "\n",
        "def build_feature_matrix(df: pd.DataFrame, cfg: Config, lex: TermsLexicon) -> Tuple[np.ndarray, np.ndarray, list]:\n",
        "    fe = FeatureExtractor12(lex)\n",
        "    X = fe.extract_df(df)\n",
        "    y = np.array([cfg.LABEL2ID[str(x)] for x in df[cfg.LABEL_COL].astype(str).tolist()], dtype=np.int32)\n",
        "    return X, y, df[cfg.TEXT_COL].tolist()\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, text_col: str, label_col: str, tokenizer, max_len: int, label2id: Dict[str, int]):\n",
        "        self.texts = df[text_col].astype(str).tolist()\n",
        "        self.labels_raw = df[label_col].tolist()\n",
        "        self.label2id = label2id\n",
        "        self.ids = [self.label2id[str(x)] if str(x) in self.label2id else self.label2id[x] for x in map(str, self.labels_raw)]\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tokenizer(self.texts[idx], truncation=True, max_length=self.max_len, padding=False, return_tensors=\"pt\")\n",
        "        enc = {k: v.squeeze(0) for k, v in enc.items()}\n",
        "        enc[\"labels\"] = torch.tensor(self.ids[idx], dtype=torch.long)\n",
        "        return enc\n",
        "\n",
        "class TextFeatDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, tokenizer, feats: Optional[np.ndarray] = None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tok = tokenizer\n",
        "        self.feats = feats\n",
        "        self.labels = df['label'].values.astype(int) if 'label' in df.columns else None\n",
        "\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        enc = self.tok(str(row['content']), truncation=True, max_length=Config.MAX_LEN, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        item = {'input_ids': enc['input_ids'].squeeze(0), 'attention_mask': enc['attention_mask'].squeeze(0)}\n",
        "        if self.feats is not None: item['feats'] = torch.tensor(self.feats[idx], dtype=torch.float32)\n",
        "        if self.labels is not None: item['labels'] = torch.tensor(int(self.labels[idx]), dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "def masked_mean_pool(last_hidden_state: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
        "    mask = attention_mask.unsqueeze(-1).float()\n",
        "    return (last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "\n",
        "class SimpleFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + n_feats, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        pooled = masked_mean_pool(out.last_hidden_state, attention_mask)\n",
        "        fused = torch.cat([pooled, feats], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "\n",
        "class GatedFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2, feat_proj: int = 64):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.fe_proj = nn.Sequential(nn.Linear(n_feats, feat_proj), nn.ReLU())\n",
        "        self.gate = nn.Sequential(nn.Linear(H + n_feats, 64), nn.ReLU(), nn.Linear(64, 1), nn.Sigmoid())\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + feat_proj, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        pooled = masked_mean_pool(out.last_hidden_state, attention_mask)\n",
        "        alpha = self.gate(torch.cat([pooled, feats], dim=1))\n",
        "        ef = self.fe_proj(feats)\n",
        "        fused = torch.cat([pooled, alpha * ef], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "\n",
        "# ===================== Evaluation & Metrics =====================\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    return {\n",
        "        \"macro_f1\": f1_score(y_true, y_pred, average=\"macro\"),\n",
        "        \"micro_f1\": f1_score(y_true, y_pred, average=\"micro\"),\n",
        "        \"weighted_f1\": f1_score(y_true, y_pred, average=\"weighted\"),\n",
        "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "    }\n",
        "\n",
        "def bootstrap_ci(y_true, y_pred, n_resamples=1000, alpha=0.95):\n",
        "    y_true, y_pred = np.asarray(y_true), np.asarray(y_pred)\n",
        "    N = len(y_true)\n",
        "    lo, hi = (1 - alpha) / 2, 1 - (1 - alpha) / 2\n",
        "    macro_vals, micro_vals, weighted_vals = [], [], []\n",
        "\n",
        "    for _ in range(n_resamples):\n",
        "        idx = resample(np.arange(N), n_samples=N, replace=True)\n",
        "        yt, yp = y_true[idx], y_pred[idx]\n",
        "        with np.errstate(divide='ignore', invalid='ignore'):\n",
        "            macro_vals.append(f1_score(yt, yp, average='macro', zero_division=0))\n",
        "            micro_vals.append(f1_score(yt, yp, average='micro', zero_division=0))\n",
        "            weighted_vals.append(f1_score(yt, yp, average='weighted', zero_division=0))\n",
        "    results = {\n",
        "        'Macro F1': np.percentile(macro_vals, [lo * 100, hi * 100]).tolist(),\n",
        "        'Micro F1': np.percentile(micro_vals, [lo * 100, hi * 100]).tolist(),\n",
        "        'Weighted F1': np.percentile(weighted_vals, [lo * 100, hi * 100]).tolist(),\n",
        "    }\n",
        "    return results\n",
        "\n",
        "def run_evaluation_loop(model, dataloader, device, model_type='xlmr'):\n",
        "    model.eval()\n",
        "    all_labels, all_preds, all_probs = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=f\"Evaluating {model_type}\", leave=False):\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n",
        "            if model_type in ['simple', 'gated']:\n",
        "                inputs['feats'] = batch['engineered'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            if model_type == 'xlmr':\n",
        "                outputs = model(**inputs, labels=None)\n",
        "                logits = outputs.logits\n",
        "            else:\n",
        "                logits = model(**inputs)\n",
        "\n",
        "            probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
        "            preds = np.argmax(probs, axis=-1)\n",
        "            all_labels.extend(labels.cpu().tolist())\n",
        "            all_preds.extend(preds.tolist())\n",
        "            all_probs.extend(probs.tolist())\n",
        "    return np.array(all_labels), np.array(all_preds), np.array(all_probs)\n",
        "\n",
        "def train_xlmr_only(cfg: Config, train_df: pd.DataFrame, val_df: pd.DataFrame, tokenizer: XLMRobertaTokenizerFast):\n",
        "    print(\"--- Training XLM-R Only model ---\")\n",
        "    os.makedirs(cfg.XLM_R_OUTPUTS, exist_ok=True)\n",
        "\n",
        "    label_map_json = os.path.join(cfg.XLM_R_OUTPUTS, \"label_map.json\")\n",
        "    with open(label_map_json, \"w\") as f:\n",
        "        json.dump({\"label2id\": cfg.LABEL2ID, \"id2label\": cfg.ID2LABEL}, f, indent=2)\n",
        "\n",
        "    train_ds = TextDataset(train_df, cfg.TEXT_COL, cfg.LABEL_COL, tokenizer, cfg.MAX_LEN, cfg.LABEL2ID)\n",
        "    val_ds = TextDataset(val_df, cfg.TEXT_COL, cfg.LABEL_COL, tokenizer, cfg.MAX_LEN, cfg.LABEL2ID)\n",
        "    collator = DataCollatorWithPadding(tokenizer)\n",
        "    train_loader = DataLoader(train_ds, batch_size=cfg.BATCH_SIZE, shuffle=True, collate_fn=collator)\n",
        "    val_loader = DataLoader(val_ds, batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
        "\n",
        "    model = XLMRobertaForSequenceClassification.from_pretrained(cfg.MODEL_NAME, num_labels=cfg.N_CLASSES).to(cfg.DEVICE)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.XLM_R_LR)\n",
        "    total_steps = len(train_loader) * cfg.XLM_R_EPOCHS\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "    best_val_macro = -1.0; patience_left = cfg.XLM_R_PATIENCE\n",
        "    for epoch in range(cfg.XLM_R_EPOCHS):\n",
        "        model.train()\n",
        "        for batch in tqdm(train_loader, desc=f\"XLM-R Training Epoch {epoch+1}\"):\n",
        "            optimizer.zero_grad()\n",
        "            inputs = {k: v.to(cfg.DEVICE) for k, v in batch.items()}\n",
        "            outputs = model(**inputs)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step(); scheduler.step()\n",
        "\n",
        "        y_true_val, y_pred_val, _ = run_evaluation_loop(model, val_loader, cfg.DEVICE, 'xlmr')\n",
        "        val_macro = f1_score(y_true_val, y_pred_val, average='macro')\n",
        "        print(f\"Epoch {epoch+1} Val Macro F1: {val_macro:.4f}\")\n",
        "\n",
        "        if val_macro > best_val_macro:\n",
        "            best_val_macro = val_macro\n",
        "            patience_left = cfg.XLM_R_PATIENCE\n",
        "            model.save_pretrained(cfg.XLM_R_OUTPUTS)\n",
        "            tokenizer.save_pretrained(cfg.XLM_R_OUTPUTS)\n",
        "            print(\"✅ New best XLM-R model saved.\")\n",
        "        else:\n",
        "            patience_left -= 1\n",
        "            if patience_left <= 0:\n",
        "                print(\"⏹️ Early stopping triggered.\")\n",
        "                break\n",
        "    print(\"✅ XLM-R Only trained successfully.\")\n",
        "\n",
        "def train_simple_fusion(cfg: Config, train_df: pd.DataFrame, val_df: pd.DataFrame, feats_tr, feats_v, lex):\n",
        "    print(\"\\n--- Training Simple Fusion model ---\")\n",
        "    os.makedirs(cfg.SIMPLE_OUTPUTS, exist_ok=True)\n",
        "\n",
        "    tokenizer = XLMRobertaTokenizerFast.from_pretrained(cfg.MODEL_NAME)\n",
        "    train_ds = TextFeatDataset(train_df, tokenizer, feats_tr)\n",
        "    val_ds = TextFeatDataset(val_df, tokenizer, feats_v)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=cfg.BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=cfg.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    model = SimpleFusion(cfg.MODEL_NAME, cfg.N_FEATURES).to(cfg.DEVICE)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.XLM_R_LR)\n",
        "    total_steps = len(train_loader) * cfg.XLM_R_EPOCHS\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_val_macro = -1.0; patience_left = cfg.XLM_R_PATIENCE\n",
        "    for epoch in range(cfg.XLM_R_EPOCHS):\n",
        "        model.train()\n",
        "        for batch in tqdm(train_loader, desc=f\"Simple Fusion Training Epoch {epoch+1}\"):\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(batch['input_ids'].to(cfg.DEVICE), batch['attention_mask'].to(cfg.DEVICE), batch['feats'].to(cfg.DEVICE))\n",
        "            loss = criterion(logits, batch['labels'].to(cfg.DEVICE))\n",
        "            loss.backward()\n",
        "            optimizer.step(); scheduler.step()\n",
        "\n",
        "        y_true_val, y_pred_val, _ = run_evaluation_loop(model, val_loader, cfg.DEVICE, 'simple')\n",
        "        val_macro = f1_score(y_true_val, y_pred_val, average='macro')\n",
        "        print(f\"Epoch {epoch+1} Val Macro F1: {val_macro:.4f}\")\n",
        "\n",
        "        if val_macro > best_val_macro:\n",
        "            best_val_macro = val_macro\n",
        "            patience_left = cfg.XLM_R_PATIENCE\n",
        "            torch.save(model.state_dict(), os.path.join(cfg.SIMPLE_OUTPUTS, \"fusion_simple.pt\"))\n",
        "            print(\"✅ New best Simple Fusion model saved.\")\n",
        "        else:\n",
        "            patience_left -= 1\n",
        "            if patience_left <= 0:\n",
        "                print(\"⏹️ Early stopping triggered.\")\n",
        "                break\n",
        "    print(\"✅ Simple Fusion trained successfully.\")\n",
        "\n",
        "def train_gated_fusion(cfg: Config, train_df: pd.DataFrame, val_df: pd.DataFrame, feats_tr, feats_v, lex):\n",
        "    print(\"\\n--- Training Gated Fusion model ---\")\n",
        "    os.makedirs(cfg.GATED_OUTPUTS, exist_ok=True)\n",
        "\n",
        "    tokenizer = XLMRobertaTokenizerFast.from_pretrained(cfg.MODEL_NAME)\n",
        "    train_ds = TextFeatDataset(train_df, tokenizer, feats_tr)\n",
        "    val_ds = TextFeatDataset(val_df, tokenizer, feats_v)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=cfg.BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=cfg.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    model = GatedFusion(cfg.MODEL_NAME, cfg.N_FEATURES).to(cfg.DEVICE)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.XLM_R_LR)\n",
        "    total_steps = len(train_loader) * cfg.XLM_R_EPOCHS\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_val_macro = -1.0; patience_left = cfg.XLM_R_PATIENCE\n",
        "    for epoch in range(cfg.XLM_R_EPOCHS):\n",
        "        model.train()\n",
        "        for batch in tqdm(train_loader, desc=f\"Gated Fusion Training Epoch {epoch+1}\"):\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(batch['input_ids'].to(cfg.DEVICE), batch['attention_mask'].to(cfg.DEVICE), batch['feats'].to(cfg.DEVICE))\n",
        "            loss = criterion(logits, batch['labels'].to(cfg.DEVICE))\n",
        "            loss.backward()\n",
        "            optimizer.step(); scheduler.step()\n",
        "\n",
        "        y_true_val, y_pred_val, _ = run_evaluation_loop(model, val_loader, cfg.DEVICE, 'gated')\n",
        "        val_macro = f1_score(y_true_val, y_pred_val, average='macro')\n",
        "        print(f\"Epoch {epoch+1} Val Macro F1: {val_macro:.4f}\")\n",
        "\n",
        "        if val_macro > best_val_macro:\n",
        "            best_val_macro = val_macro\n",
        "            patience_left = cfg.XLM_R_PATIENCE\n",
        "            torch.save(model.state_dict(), os.path.join(cfg.GATED_OUTPUTS, \"fusion_gated.pt\"))\n",
        "            print(\"✅ New best Gated Fusion model saved.\")\n",
        "        else:\n",
        "            patience_left -= 1\n",
        "            if patience_left <= 0:\n",
        "                print(\"⏹️ Early stopping triggered.\")\n",
        "                break\n",
        "    print(\"✅ Gated Fusion trained successfully.\")\n",
        "\n",
        "def train_xgboost(cfg: Config, train_df: pd.DataFrame, val_df: pd.DataFrame, feats_tr, feats_v):\n",
        "    print(\"\\n--- Training XGBoost model ---\")\n",
        "    os.makedirs(cfg.XGB_OUTPUTS, exist_ok=True)\n",
        "\n",
        "    y_train = train_df['label'].values.astype(int)\n",
        "    y_val = val_df['label'].values.astype(int)\n",
        "\n",
        "    scaler = StandardScaler(); X_train_scaled = scaler.fit_transform(feats_tr); X_val_scaled = scaler.transform(feats_v)\n",
        "    joblib.dump(scaler, os.path.join(cfg.XGB_OUTPUTS, \"scaler12.pkl\"))\n",
        "\n",
        "    clf = xgb.XGBClassifier(n_estimators=cfg.XGB_ESTIMATORS, learning_rate=cfg.XGB_LR, max_depth=cfg.XGB_MAX_DEPTH, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "    early_stopping_callback = EarlyStopping(rounds=cfg.XGB_EARLY_STOP)\n",
        "    clf.fit(X_train_scaled, y_train, eval_set=[(X_val_scaled, y_val)], callbacks=[early_stopping_callback], verbose=False)\n",
        "    clf.save_model(os.path.join(cfg.XGB_OUTPUTS, \"xgb_model.json\"))\n",
        "    print(\"✅ XGBoost model trained and saved.\")\n",
        "\n",
        "\n",
        "# ===================== Main Execution =====================\n",
        "if __name__ == \"__main__\":\n",
        "    set_seed(42)\n",
        "    cfg = Config()\n",
        "\n",
        "    # --- Step 1: Clean Data ---\n",
        "    # This step is commented out to use your existing clean splits\n",
        "    # clean_and_split_data(cfg.RAW_CORPUS_CSV, cfg.CLEAN_TRAIN_CSV, cfg.CLEAN_VAL_CSV, cfg.CLEAN_TEST_CSV)\n",
        "\n",
        "    train_df = pd.read_csv(cfg.CLEAN_TRAIN_CSV)\n",
        "    val_df = pd.read_csv(cfg.CLEAN_VAL_CSV)\n",
        "    test_df = pd.read_csv(cfg.CLEAN_TEST_CSV)\n",
        "    lex = TermsLexicon(cfg.TERMS_CSV)\n",
        "    fe = FeatureExtractor12(lex)\n",
        "\n",
        "    # --- Step 2: Extract features for all models ---\n",
        "    print(\"\\n--- Extracting features for all models... ---\")\n",
        "    feats_tr = fe.extract_df(train_df)\n",
        "    feats_v = fe.extract_df(val_df)\n",
        "    feats_te = fe.extract_df(test_df)\n",
        "\n",
        "    # --- Step 3: Train All Models ---\n",
        "    train_xgboost(cfg, train_df, val_df, feats_tr, feats_v)\n",
        "    train_xlmr_only(cfg, train_df, val_df, XLMRobertaTokenizerFast.from_pretrained(cfg.MODEL_NAME))\n",
        "    train_simple_fusion(cfg, train_df, val_df, feats_tr, feats_v, lex)\n",
        "    train_gated_fusion(cfg, train_df, val_df, feats_tr, feats_v, lex)\n",
        "\n",
        "    # --- Step 4: Final Evaluation ---\n",
        "    print(\"\\n--- Running final evaluation on clean test set for all models ---\")\n",
        "\n",
        "    # --- Load Models for Eval ---\n",
        "    clf_xgb = xgb.XGBClassifier(); clf_xgb.load_model(os.path.join(cfg.XGB_OUTPUTS, \"xgb_model.json\"))\n",
        "    scaler_xgb = joblib.load(os.path.join(cfg.XGB_OUTPUTS, \"scaler12.pkl\"))\n",
        "\n",
        "    model_xlmr = XLMRobertaForSequenceClassification.from_pretrained(cfg.XLM_R_OUTPUTS).to(cfg.DEVICE)\n",
        "    tokenizer_xlmr = XLMRobertaTokenizerFast.from_pretrained(cfg.XLM_R_OUTPUTS)\n",
        "\n",
        "    model_simple = SimpleFusion(cfg.MODEL_NAME, cfg.N_FEATURES).to(cfg.DEVICE)\n",
        "    model_simple.load_state_dict(torch.load(os.path.join(cfg.SIMPLE_OUTPUTS, \"fusion_simple.pt\")), strict=False)\n",
        "    scaler_simple = joblib.load(os.path.join(cfg.SIMPLE_OUTPUTS, \"scaler12.pkl\"))\n",
        "\n",
        "    model_gated = GatedFusion(cfg.MODEL_NAME, cfg.N_FEATURES).to(cfg.DEVICE)\n",
        "    model_gated.load_state_dict(torch.load(os.path.join(cfg.GATED_OUTPUTS, \"fusion_gated.pt\")), strict=False)\n",
        "    scaler_gated = joblib.load(os.path.join(cfg.GATED_OUTPUTS, \"scaler12.pkl\"))\n",
        "\n",
        "    # --- Prepare Test Data ---\n",
        "    X_test_xgb, y_true_xgb, _ = build_feature_matrix(test_df, cfg, lex)\n",
        "    X_test_scaled_xgb = scaler_xgb.transform(X_test_xgb)\n",
        "\n",
        "    X_test_simple, y_true_simple, _ = build_feature_matrix(test_df, cfg, lex)\n",
        "    X_test_scaled_simple = scaler_simple.transform(X_test_simple)\n",
        "\n",
        "    X_test_gated, y_true_gated, _ = build_feature_matrix(test_df, cfg, lex)\n",
        "    X_test_scaled_gated = scaler_gated.transform(X_test_gated)\n",
        "\n",
        "    test_ds_xlmr = TextFeatDataset(test_df, tokenizer_xlmr, feats=None)\n",
        "    test_loader_xlmr = DataLoader(test_ds_xlmr, batch_size=cfg.BATCH_SIZE, collate_fn=DataCollatorWithPadding(tokenizer_xlmr))\n",
        "\n",
        "    # --- Run Evaluations & Collect Results ---\n",
        "    results_dict = {}\n",
        "\n",
        "    # XGBoost\n",
        "    print(\"\\nEvaluating XGBoost...\")\n",
        "    y_prob_xgb = clf_xgb.predict_proba(X_test_scaled_xgb); y_pred_xgb = y_prob_xgb.argmax(axis=1)\n",
        "    results_dict['XGBoost + Features'] = {'y_true': y_true_xgb, 'y_pred': y_pred_xgb, 'y_prob': y_prob_xgb[:,1]}\n",
        "\n",
        "    # XLM-R\n",
        "    print(\"\\nEvaluating XLM-R Only...\")\n",
        "    y_true_xlmr, y_pred_xlmr, y_prob_xlmr = run_evaluation_loop(model_xlmr, test_loader_xlmr, cfg.DEVICE, 'xlmr')\n",
        "    results_dict['XLM-R Only'] = {'y_true': y_true_xlmr, 'y_pred': y_pred_xlmr, 'y_prob': y_prob_xlmr[:,1]}\n",
        "\n",
        "    # Simple Fusion\n",
        "    print(\"\\nEvaluating Simple Fusion...\")\n",
        "    test_ds_simple = TextFeatDataset(test_df, tokenizer_xlmr, feats=X_test_scaled_simple)\n",
        "    test_loader_simple = DataLoader(test_ds_simple, batch_size=cfg.BATCH_SIZE)\n",
        "    y_true_simple, y_pred_simple, y_prob_simple = run_evaluation_loop(model_simple, test_loader_simple, cfg.DEVICE, 'simple')\n",
        "    results_dict['Simple Fusion'] = {'y_true': y_true_simple, 'y_pred': y_pred_simple, 'y_prob': y_prob_simple[:,1]}\n",
        "\n",
        "    # Gated Fusion\n",
        "    print(\"\\nEvaluating Gated Fusion...\")\n",
        "    test_ds_gated = TextFeatDataset(test_df, tokenizer_xlmr, feats=X_test_scaled_gated)\n",
        "    test_loader_gated = DataLoader(test_ds_gated, batch_size=cfg.BATCH_SIZE)\n",
        "    y_true_gated, y_pred_gated, y_prob_gated = run_evaluation_loop(model_gated, test_loader_gated, cfg.DEVICE, 'gated')\n",
        "    results_dict['Gated Fusion'] = {'y_true': y_true_gated, 'y_pred': y_pred_gated, 'y_prob': y_prob_gated[:,1]}\n",
        "\n",
        "    # --- Print Final Table and Plots ---\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"Final Model Performance on Clean Test Set\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    table_data = []\n",
        "    for name, res in results_dict.items():\n",
        "        y_true, y_pred, y_prob = res['y_true'], res['y_pred'], res['y_prob']\n",
        "\n",
        "        metrics = compute_metrics(y_true, y_pred)\n",
        "        cis = bootstrap_ci(y_true, y_pred)\n",
        "\n",
        "        table_data.append({\n",
        "            \"Model\": name,\n",
        "            \"AUC-ROC\": roc_auc_score(y_true, y_prob),\n",
        "            \"Precision_Real\": precision_score(y_true, y_pred, pos_label=0),\n",
        "            \"Recall_Real\": recall_score(y_true, y_pred, pos_label=0),\n",
        "            \"F1_Real\": f1_score(y_true, y_pred, pos_label=0),\n",
        "            \"CI_F1_Real_low\": cis['F1-score Real (0)'][0],\n",
        "            \"CI_F1_Real_high\": cis['F1-score Real (0)'][1],\n",
        "            \"Precision_Misinfo\": precision_score(y_true, y_pred, pos_label=1),\n",
        "            \"Recall_Misinfo\": recall_score(y_true, y_pred, pos_label=1),\n",
        "            \"F1_Misinfo\": f1_score(y_true, y_pred, pos_label=1),\n",
        "            \"CI_F1_Misinfo_low\": cis['F1-score Misinformation (1)'][0],\n",
        "            \"CI_F1_Misinfo_high\": cis['F1-score Misinformation (1)'][1],\n",
        "            \"Macro_F1\": metrics['macro_f1'],\n",
        "            \"CI_Macro_F1_low\": cis['Macro F1'][0],\n",
        "            \"CI_Macro_F1_high\": cis['Macro F1'][1],\n",
        "            \"Micro_F1\": metrics['micro_f1'],\n",
        "            \"CI_Micro_F1_low\": cis['Micro F1'][0],\n",
        "            \"CI_Micro_F1_high\": cis['Micro F1'][1],\n",
        "            \"Weighted_F1\": metrics['weighted_f1'],\n",
        "            \"CI_Weighted_F1_low\": cis['Weighted F1'][0],\n",
        "            \"CI_Weighted_F1_high\": cis['Weighted F1'][1],\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(table_data)\n",
        "\n",
        "    # --- Combined AUC-ROC Plot ---\n",
        "    print(\"\\n--- Generating combined AUC-ROC plot... ---\")\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    for name, res in results_dict.items():\n",
        "        y_true, y_prob = res['y_true'], res['y_prob']\n",
        "        fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, lw=2, label=f'{name} (AUC = {roc_auc:.4f})')\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
        "    plt.title('Combined Model ROC Curves')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(cfg.COMBINED_AUC_ROC_PLOT_PATH, dpi=300)\n",
        "    print(f\"✅ Combined AUC-ROC plot saved to: {cfg.COMBINED_AUC_ROC_PLOT_PATH}\")\n",
        "\n",
        "    # --- Permutation Importance for XGBoost ---\n",
        "    print(\"\\n--- Generating Permutation Importance plot for XGBoost... ---\")\n",
        "    feat_names = [\"Chars\", \"Words\", \"Sents\", \"Flesch RE (en)\", \"Gunning Fog (en)\", \"% Eng Terms\", \"Punctuation\", \"Number Count\", \"Contains Standard\", \"Contains Safety\", \"Avg Number Mag\", \"Decimal Ratio\"]\n",
        "    result = permutation_importance(clf_xgb, X_test_scaled_xgb, y_true_xgb, n_repeats=10, random_state=42, n_jobs=-1)\n",
        "    importance_df = pd.DataFrame({'Feature': feat_names, 'Importance_Mean': result.importances_mean}).sort_values('Importance_Mean', ascending=True)\n",
        "    plt.figure(figsize=(10, 8)); plt.barh(importance_df['Feature'], importance_df['Importance_Mean'], color='darkblue'); plt.title('XGBoost Permutation Feature Importance'); plt.tight_layout(); plt.savefig(os.path.join(cfg.XGB_OUTPUTS, \"permutation_importance.png\"))\n",
        "    print(f\"✅ XGBoost Permutation Importance plot saved.\")\n",
        "\n",
        "    print(\"\\n✅ All training and evaluation complete.\")\n"
      ],
      "metadata": {
        "id": "UPRwCPzEr26m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import random\n",
        "from typing import Optional, Dict, Tuple, List, Any\n",
        "from dataclasses import dataclass, field\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns  # (unused is fine)\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    f1_score, accuracy_score, precision_score, recall_score,\n",
        "    roc_auc_score, classification_report, roc_curve, auc\n",
        ")\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.inspection import permutation_importance\n",
        "import joblib\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost.callback import EarlyStopping  # (unused)\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    XLMRobertaForSequenceClassification,\n",
        "    XLMRobertaModel,\n",
        "    XLMRobertaTokenizerFast,\n",
        "    DataCollatorWithPadding,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "\n",
        "try:\n",
        "    import textstat\n",
        "    _HAS_TEXTSTAT = True\n",
        "except Exception:\n",
        "    _HAS_TEXTSTAT = False\n",
        "\n",
        "# ===================== Config =====================\n",
        "@dataclass\n",
        "class Config:\n",
        "    BASE_DIR: str = \"/content/drive/MyDrive/emc\"\n",
        "    RAW_CORPUS_CSV: str = os.path.join(BASE_DIR, \"all_data.csv\")\n",
        "    TERMS_CSV: str = os.path.join(BASE_DIR, \"engineering_terms.csv\")\n",
        "\n",
        "    CLEAN_TRAIN_CSV: str = os.path.join(BASE_DIR, \"train.csv\")\n",
        "    CLEAN_VAL_CSV: str = os.path.join(BASE_DIR, \"val.csv\")\n",
        "    CLEAN_TEST_CSV: str = os.path.join(BASE_DIR, \"test.csv\")\n",
        "\n",
        "    XGB_OUTPUTS: str = os.path.join(BASE_DIR, \"xgb_outputs_clean\")\n",
        "    XLM_R_OUTPUTS: str = os.path.join(BASE_DIR, \"xlmr_only_outputs_clean\")\n",
        "    SIMPLE_OUTPUTS: str = os.path.join(BASE_DIR, \"simple_fusion_outputs_clean\")\n",
        "    GATED_OUTPUTS: str = os.path.join(BASE_DIR, \"gated_fusion_outputs_clean\")\n",
        "\n",
        "    TEXT_COL: str = \"content\"\n",
        "    LABEL_COL: str = \"label\"\n",
        "    LANG_COL: str = \"lang\"\n",
        "\n",
        "    N_FEATURES: int = 12\n",
        "    N_CLASSES: int = 2\n",
        "    MAX_LEN: int = 256\n",
        "    BATCH_SIZE: int = 16\n",
        "\n",
        "    XLM_R_EPOCHS: int = 5\n",
        "    XLM_R_LR: float = 2e-5\n",
        "    XLM_R_PATIENCE: int = 3\n",
        "\n",
        "    XGB_ESTIMATORS: int = 2000\n",
        "    XGB_LR: float = 0.03\n",
        "    XGB_MAX_DEPTH: int = 6\n",
        "    XGB_EARLY_STOP: int = 100\n",
        "\n",
        "    LABEL2ID: Dict[str, int] = field(default_factory=lambda: {\"0\": 0, \"1\": 1})\n",
        "    ID2LABEL: Dict[int, str] = field(default_factory=lambda: {0: \"Real\", 1: \"Misinformation\"})\n",
        "\n",
        "    DEVICE: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    MODEL_NAME: str = \"xlm-roberta-base\"\n",
        "\n",
        "    COMBINED_AUC_ROC_PLOT_PATH: str = os.path.join(BASE_DIR, \"combined_auc_roc.png\")\n",
        "\n",
        "# ===================== Reproducibility =====================\n",
        "def set_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    # FIX: correct CUDA seeding call\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# ===================== Data & Feature Extraction =====================\n",
        "def clean_and_split_data(raw_csv_path, train_path, val_path, test_path):\n",
        "    print(\"--- Cleaning and splitting data ---\")\n",
        "    if not os.path.exists(raw_csv_path):\n",
        "        print(f\"Error: Raw corpus not found at {raw_csv_path}\")\n",
        "        return\n",
        "\n",
        "    df = pd.read_csv(raw_csv_path)\n",
        "    df.dropna(subset=['content', 'label'], inplace=True)\n",
        "    df.drop_duplicates(subset=['content'], inplace=True)\n",
        "\n",
        "    X, y = df, df['label']\n",
        "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
        "    train_idx, test_val_idx = next(sss.split(X, y))\n",
        "\n",
        "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
        "    X_test_val, y_test_val = X.iloc[test_val_idx], y.iloc[test_val_idx]\n",
        "\n",
        "    sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
        "    val_idx, test_idx = next(sss2.split(X_test_val, y_test_val))\n",
        "\n",
        "    X_train, X_val, X_test = X.iloc[train_idx], X_test_val.iloc[val_idx], X_test_val.iloc[test_idx]\n",
        "\n",
        "    train_texts = set(X_train['content'].astype(str))\n",
        "    val_texts = set(X_val['content'].astype(str))\n",
        "    test_texts = set(X_test['content'].astype(str))\n",
        "\n",
        "    if train_texts.intersection(test_texts) or train_texts.intersection(val_texts) or val_texts.intersection(test_texts):\n",
        "        print(\"⚠️ Warning: Data leakage detected after splitting. This should not happen with StratifiedShuffleSplit. Review your data.\")\n",
        "    else:\n",
        "        print(\"✅ No direct text overlap found between train, val, and test sets.\")\n",
        "\n",
        "    X_train.to_csv(train_path, index=False)\n",
        "    X_val.to_csv(val_path, index=False)\n",
        "    X_test.to_csv(test_path, index=False)\n",
        "\n",
        "    print(f\"✅ Data splits saved: Train ({len(X_train)}), Val ({len(X_val)}), Test ({len(X_test)})\")\n",
        "\n",
        "STD_TERMS = {\"iso\", \"asme\", \"ieee\", \"din\", \"ansi\", \"iec\", \"ul\", \"astm\", \"en\"}\n",
        "SAFETY_TERMS = {\"safety\", \"hazard\", \"warning\", \"risk\", \"caution\", \"danger\", \"emergency\"}\n",
        "_WORD_RE = re.compile(r\"\\w+\", re.UNICODE)\n",
        "_NUM_RE = re.compile(r'[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?')\n",
        "\n",
        "def simple_words(t: str) -> List[str]: return _WORD_RE.findall(t or \"\")\n",
        "def sent_count(t: str) -> int:\n",
        "    if not t: return 0\n",
        "    return max(1, len(re.split(r'[.!?]+[\\s\\n]+', t)))\n",
        "def punct_count(t: str) -> int: return sum(1 for ch in (t or \"\") if ch in \".,;:!?\")\n",
        "def extract_numbers(text: str):\n",
        "    nums, dec = [], 0\n",
        "    for m in _NUM_RE.finditer(text or \"\"):\n",
        "        s = m.group(0)\n",
        "        try:\n",
        "            v = float(s)\n",
        "            if ('.' in s) or ('e' in s.lower()): dec += 1\n",
        "            nums.append(abs(v))\n",
        "        except: pass\n",
        "    return nums, dec\n",
        "def _finite_or_zero(x: float) -> float: return float(x) if np.isfinite(x) else 0.0\n",
        "\n",
        "class TermsLexicon:\n",
        "    def __init__(self, csv_path: str, term_col=\"terms\", lang_col=\"lang\"):\n",
        "        if not os.path.exists(csv_path): raise FileNotFoundError(csv_path)\n",
        "        df = pd.read_csv(csv_path)\n",
        "        if term_col not in df.columns: raise ValueError(f\"Missing '{term_col}'\")\n",
        "        if lang_col not in df.columns: df[lang_col] = 'en'\n",
        "        self.by_lang = {str(l).lower(): set(str(x).strip().lower() for x in d[term_col].dropna().tolist() if str(x).strip()) for l, d in df.groupby(lang_col)}\n",
        "    def pct_in_text(self, text: str, lang: str) -> float:\n",
        "        if not text: return 0.0\n",
        "        terms = self.by_lang.get((lang or \"en\").lower(), set())\n",
        "        if not terms: return 0.0\n",
        "        ws = [w.lower() for w in simple_words(text)]\n",
        "        if not ws: return 0.0\n",
        "        return sum(1 for w in ws if w in terms) / max(1, len(ws))\n",
        "class FeatureExtractor12:\n",
        "    def __init__(self, tlex: TermsLexicon):\n",
        "        self.tlex = tlex\n",
        "\n",
        "    def extract_one(self, text: str, lang: str) -> np.ndarray:\n",
        "        # normalize inputs\n",
        "        text = \"\" if text is None else str(text)\n",
        "        lang = (lang or \"en\").lower()\n",
        "\n",
        "        # basic counts\n",
        "        ws = simple_words(text)\n",
        "        n_words = len(ws)\n",
        "        chars = len(text)\n",
        "        words = n_words\n",
        "        sents = sent_count(text)\n",
        "\n",
        "        # readability (English only, if textstat available)\n",
        "        if lang == \"en\" and _HAS_TEXTSTAT and text.strip():\n",
        "            fre = _finite_or_zero(textstat.flesch_reading_ease(text))\n",
        "            fog = _finite_or_zero(textstat.gunning_fog(text))\n",
        "        else:\n",
        "            fre, fog = 0.0, 0.0\n",
        "\n",
        "        # lexical & numeric features\n",
        "        eng_pct = self.tlex.pct_in_text(text, lang)\n",
        "        punc = punct_count(text)\n",
        "        nums, dec_cnt = extract_numbers(text)\n",
        "        nnums = len(nums)\n",
        "        avg_mag = float(np.mean(nums)) if nums else 0.0\n",
        "        dec_ratio = float(dec_cnt / max(1, len(nums)))  # avoid div-by-zero\n",
        "\n",
        "        # keyword flags\n",
        "        low = text.lower()\n",
        "        has_std = 1.0 if any(t in low for t in STD_TERMS) else 0.0\n",
        "        has_saf = 1.0 if any(t in low for t in SAFETY_TERMS) else 0.0\n",
        "\n",
        "        # build in float64, sanitize, then cast to float32 to avoid overflow warnings\n",
        "        vals = [chars, words, sents, fre, fog, eng_pct, punc, nnums, has_std, has_saf, avg_mag, dec_ratio]\n",
        "        feats = np.asarray([_finite_or_zero(v) for v in vals], dtype=np.float64)\n",
        "        feats = np.nan_to_num(feats, nan=0.0, posinf=1e12, neginf=0.0)\n",
        "        feats = np.clip(feats, -1e12, 1e12).astype(np.float32)\n",
        "        return feats\n",
        "\n",
        "\n",
        "\n",
        "    def extract_df(self, df: pd.DataFrame) -> np.ndarray:\n",
        "        assert 'content' in df.columns\n",
        "        if 'lang' not in df.columns: df = df.copy(); df['lang'] = 'en'\n",
        "        rows = [self.extract_one(r.get(\"content\",\"\"), r.get(\"lang\",\"en\")) for _, r in tqdm(df.iterrows(), total=len(df), desc=\"Extracting features\")]\n",
        "        return np.stack(rows, axis=0).astype(np.float32)\n",
        "\n",
        "def build_feature_matrix(df: pd.DataFrame, cfg: Config, lex: TermsLexicon) -> Tuple[np.ndarray, np.ndarray, list]:\n",
        "    fe = FeatureExtractor12(lex)\n",
        "    X = fe.extract_df(df)\n",
        "    y = np.array([cfg.LABEL2ID.get(str(x), int(x)) for x in df[cfg.LABEL_COL].astype(str).tolist()], dtype=np.int32)  # FIX: more robust mapping\n",
        "    return X, y, df[cfg.TEXT_COL].tolist()\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, text_col: str, label_col: str, tokenizer, max_len: int, label2id: Dict[str, int]):\n",
        "        self.texts = df[text_col].astype(str).tolist()\n",
        "        self.labels_raw = df[label_col].tolist()\n",
        "        self.label2id = label2id\n",
        "        # FIX: robust label mapping\n",
        "        self.ids = []\n",
        "        for v in self.labels_raw:\n",
        "            s = str(v)\n",
        "            if s in self.label2id:\n",
        "                self.ids.append(self.label2id[s])\n",
        "            else:\n",
        "                try:\n",
        "                    self.ids.append(int(s))\n",
        "                except:\n",
        "                    # fallback if dataset uses words like \"Real\"/\"Misinformation\"\n",
        "                    self.ids.append(1 if s.lower().startswith(\"mis\") else 0)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tokenizer(self.texts[idx], truncation=True, max_length=self.max_len, padding=False, return_tensors=\"pt\")\n",
        "        enc = {k: v.squeeze(0) for k, v in enc.items()}\n",
        "        enc[\"labels\"] = torch.tensor(self.ids[idx], dtype=torch.long)\n",
        "        return enc\n",
        "\n",
        "class TextFeatDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, tokenizer, feats: Optional[np.ndarray] = None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tok = tokenizer\n",
        "        self.feats = feats\n",
        "        self.labels = df['label'].values.astype(int) if 'label' in df.columns else None\n",
        "\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        enc = self.tok(str(row['content']), truncation=True, max_length=Config.MAX_LEN, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        item = {'input_ids': enc['input_ids'].squeeze(0), 'attention_mask': enc['attention_mask'].squeeze(0)}\n",
        "        if self.feats is not None: item['feats'] = torch.tensor(self.feats[idx], dtype=torch.float32)\n",
        "        if self.labels is not None: item['labels'] = torch.tensor(int(self.labels[idx]), dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "def masked_mean_pool(last_hidden_state: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
        "    mask = attention_mask.unsqueeze(-1).float()\n",
        "    return (last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "\n",
        "class SimpleFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + n_feats, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        pooled = masked_mean_pool(out.last_hidden_state, attention_mask)\n",
        "        fused = torch.cat([pooled, feats], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "\n",
        "class GatedFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2, feat_proj: int = 64):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.fe_proj = nn.Sequential(nn.Linear(n_feats, feat_proj), nn.ReLU())\n",
        "        self.gate = nn.Sequential(nn.Linear(H + n_feats, 64), nn.ReLU(), nn.Linear(64, 1), nn.Sigmoid())\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + feat_proj, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        pooled = masked_mean_pool(out.last_hidden_state, attention_mask)\n",
        "        alpha = self.gate(torch.cat([pooled, feats], dim=1))\n",
        "        ef = self.fe_proj(feats)\n",
        "        fused = torch.cat([pooled, alpha * ef], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "\n",
        "# ===================== Evaluation & Metrics =====================\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    return {\n",
        "        \"macro_f1\": f1_score(y_true, y_pred, average=\"macro\"),\n",
        "        \"micro_f1\": f1_score(y_true, y_pred, average=\"micro\"),\n",
        "        \"weighted_f1\": f1_score(y_true, y_pred, average=\"weighted\"),\n",
        "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "    }\n",
        "\n",
        "def bootstrap_ci(y_true, y_pred, n_resamples=1000, alpha=0.95):\n",
        "    y_true, y_pred = np.asarray(y_true), np.asarray(y_pred)\n",
        "    N = len(y_true)\n",
        "    lo, hi = (1 - alpha) / 2, 1 - (1 - alpha) / 2\n",
        "    macro_vals, micro_vals, weighted_vals = [], [], []\n",
        "    f1_real_vals, f1_mis_vals = [], []\n",
        "\n",
        "    for _ in range(n_resamples):\n",
        "        idx = resample(np.arange(N), n_samples=N, replace=True)\n",
        "        yt, yp = y_true[idx], y_pred[idx]\n",
        "        with np.errstate(divide='ignore', invalid='ignore'):\n",
        "            macro_vals.append(f1_score(yt, yp, average='macro', zero_division=0))\n",
        "            micro_vals.append(f1_score(yt, yp, average='micro', zero_division=0))\n",
        "            weighted_vals.append(f1_score(yt, yp, average='weighted', zero_division=0))\n",
        "            f1_real_vals.append(f1_score(yt, yp, pos_label=0, zero_division=0))\n",
        "            f1_mis_vals.append(f1_score(yt, yp, pos_label=1, zero_division=0))\n",
        "    results = {\n",
        "        'Macro F1': np.percentile(macro_vals, [lo * 100, hi * 100]).tolist(),\n",
        "        'Micro F1': np.percentile(micro_vals, [lo * 100, hi * 100]).tolist(),\n",
        "        'Weighted F1': np.percentile(weighted_vals, [lo * 100, hi * 100]).tolist(),\n",
        "        # FIX: add per-class CIs used by the table below\n",
        "        'F1-score Real (0)': np.percentile(f1_real_vals, [lo * 100, hi * 100]).tolist(),\n",
        "        'F1-score Misinformation (1)': np.percentile(f1_mis_vals, [lo * 100, hi * 100]).tolist(),\n",
        "    }\n",
        "    return results\n",
        "\n",
        "def run_evaluation_loop(model, dataloader, device, model_type='xlmr'):\n",
        "    model.eval()\n",
        "    all_labels, all_preds, all_probs = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=f\"Evaluating {model_type}\", leave=False):\n",
        "            # FIX: correct batch keys\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n",
        "            if model_type in ['simple', 'gated']:\n",
        "                inputs['feats'] = batch['feats'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            if model_type == 'xlmr':\n",
        "                outputs = model(**inputs)  # no labels during eval\n",
        "                logits = outputs.logits\n",
        "            else:\n",
        "                logits = model(**inputs)\n",
        "\n",
        "            probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
        "            preds = np.argmax(probs, axis=-1)\n",
        "            all_labels.extend(labels.cpu().tolist())\n",
        "            all_preds.extend(preds.tolist())\n",
        "            all_probs.extend(probs.tolist())\n",
        "    return np.array(all_labels), np.array(all_preds), np.array(all_probs)\n",
        "\n",
        "def train_xlmr_only(cfg: Config, train_df: pd.DataFrame, val_df: pd.DataFrame, tokenizer: XLMRobertaTokenizerFast):\n",
        "    print(\"--- Training XLM-R Only model ---\")\n",
        "    os.makedirs(cfg.XLM_R_OUTPUTS, exist_ok=True)\n",
        "\n",
        "    label_map_json = os.path.join(cfg.XLM_R_OUTPUTS, \"label_map.json\")\n",
        "    with open(label_map_json, \"w\") as f:\n",
        "        json.dump({\"label2id\": cfg.LABEL2ID, \"id2label\": cfg.ID2LABEL}, f, indent=2)\n",
        "\n",
        "    train_ds = TextDataset(train_df, cfg.TEXT_COL, cfg.LABEL_COL, tokenizer, cfg.MAX_LEN, cfg.LABEL2ID)\n",
        "    val_ds = TextDataset(val_df, cfg.TEXT_COL, cfg.LABEL_COL, tokenizer, cfg.MAX_LEN, cfg.LABEL2ID)\n",
        "    collator = DataCollatorWithPadding(tokenizer)\n",
        "    train_loader = DataLoader(train_ds, batch_size=cfg.BATCH_SIZE, shuffle=True, collate_fn=collator)\n",
        "    val_loader = DataLoader(val_ds, batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
        "\n",
        "    model = XLMRobertaForSequenceClassification.from_pretrained(cfg.MODEL_NAME, num_labels=cfg.N_CLASSES).to(cfg.DEVICE)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.XLM_R_LR)\n",
        "    total_steps = len(train_loader) * cfg.XLM_R_EPOCHS\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "    best_val_macro = -1.0; patience_left = cfg.XLM_R_PATIENCE\n",
        "    for epoch in range(cfg.XLM_R_EPOCHS):\n",
        "        model.train()\n",
        "        for batch in tqdm(train_loader, desc=f\"XLM-R Training Epoch {epoch+1}\"):\n",
        "            optimizer.zero_grad()\n",
        "            inputs = {k: v.to(cfg.DEVICE) for k, v in batch.items()}\n",
        "            outputs = model(**inputs)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step(); scheduler.step()\n",
        "\n",
        "        y_true_val, y_pred_val, _ = run_evaluation_loop(model, val_loader, cfg.DEVICE, 'xlmr')\n",
        "        val_macro = f1_score(y_true_val, y_pred_val, average='macro')\n",
        "        print(f\"Epoch {epoch+1} Val Macro F1: {val_macro:.4f}\")\n",
        "\n",
        "        if val_macro > best_val_macro:\n",
        "            best_val_macro = val_macro\n",
        "            patience_left = cfg.XLM_R_PATIENCE\n",
        "            model.save_pretrained(cfg.XLM_R_OUTPUTS)\n",
        "            tokenizer.save_pretrained(cfg.XLM_R_OUTPUTS)\n",
        "            print(\"✅ New best XLM-R model saved.\")\n",
        "        else:\n",
        "            patience_left -= 1\n",
        "            if patience_left <= 0:\n",
        "                print(\"⏹️ Early stopping triggered.\")\n",
        "                break\n",
        "    print(\"✅ XLM-R Only trained successfully.\")\n",
        "\n",
        "def train_simple_fusion(cfg: Config, train_df: pd.DataFrame, val_df: pd.DataFrame, feats_tr, feats_v, lex):\n",
        "    print(\"\\n--- Training Simple Fusion model ---\")\n",
        "    os.makedirs(cfg.SIMPLE_OUTPUTS, exist_ok=True)\n",
        "\n",
        "    # FIX: scale & persist scaler to match eval\n",
        "    scaler = StandardScaler()\n",
        "    feats_tr_sc = scaler.fit_transform(feats_tr).astype(np.float32)\n",
        "    feats_v_sc = scaler.transform(feats_v).astype(np.float32)\n",
        "    joblib.dump(scaler, os.path.join(cfg.SIMPLE_OUTPUTS, \"scaler12.pkl\"))\n",
        "\n",
        "    tokenizer = XLMRobertaTokenizerFast.from_pretrained(cfg.MODEL_NAME)\n",
        "    train_ds = TextFeatDataset(train_df, tokenizer, feats_tr_sc)\n",
        "    val_ds = TextFeatDataset(val_df, tokenizer, feats_v_sc)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=cfg.BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=cfg.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    model = SimpleFusion(cfg.MODEL_NAME, cfg.N_FEATURES).to(cfg.DEVICE)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.XLM_R_LR)\n",
        "    total_steps = len(train_loader) * cfg.XLM_R_EPOCHS\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_val_macro = -1.0; patience_left = cfg.XLM_R_PATIENCE\n",
        "    for epoch in range(cfg.XLM_R_EPOCHS):\n",
        "        model.train()\n",
        "        for batch in tqdm(train_loader, desc=f\"Simple Fusion Training Epoch {epoch+1}\"):\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(batch['input_ids'].to(cfg.DEVICE), batch['attention_mask'].to(cfg.DEVICE), batch['feats'].to(cfg.DEVICE))\n",
        "            loss = criterion(logits, batch['labels'].to(cfg.DEVICE))\n",
        "            loss.backward()\n",
        "            optimizer.step(); scheduler.step()\n",
        "\n",
        "        y_true_val, y_pred_val, _ = run_evaluation_loop(model, val_loader, cfg.DEVICE, 'simple')\n",
        "        val_macro = f1_score(y_true_val, y_pred_val, average='macro')\n",
        "        print(f\"Epoch {epoch+1} Val Macro F1: {val_macro:.4f}\")\n",
        "\n",
        "        if val_macro > best_val_macro:\n",
        "            best_val_macro = val_macro\n",
        "            patience_left = cfg.XLM_R_PATIENCE\n",
        "            torch.save(model.state_dict(), os.path.join(cfg.SIMPLE_OUTPUTS, \"fusion_simple.pt\"))\n",
        "            print(\"✅ New best Simple Fusion model saved.\")\n",
        "        else:\n",
        "            patience_left -= 1\n",
        "            if patience_left <= 0:\n",
        "                print(\"⏹️ Early stopping triggered.\")\n",
        "                break\n",
        "    print(\"✅ Simple Fusion trained successfully.\")\n",
        "\n",
        "def train_gated_fusion(cfg: Config, train_df: pd.DataFrame, val_df: pd.DataFrame, feats_tr, feats_v, lex):\n",
        "    print(\"\\n--- Training Gated Fusion model ---\")\n",
        "    os.makedirs(cfg.GATED_OUTPUTS, exist_ok=True)\n",
        "\n",
        "    # FIX: scale & persist scaler to match eval\n",
        "    scaler = StandardScaler()\n",
        "    feats_tr_sc = scaler.fit_transform(feats_tr).astype(np.float32)\n",
        "    feats_v_sc = scaler.transform(feats_v).astype(np.float32)\n",
        "    joblib.dump(scaler, os.path.join(cfg.GATED_OUTPUTS, \"scaler12.pkl\"))\n",
        "\n",
        "    tokenizer = XLMRobertaTokenizerFast.from_pretrained(cfg.MODEL_NAME)\n",
        "    train_ds = TextFeatDataset(train_df, tokenizer, feats_tr_sc)\n",
        "    val_ds = TextFeatDataset(val_df, tokenizer, feats_v_sc)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=cfg.BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=cfg.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    model = GatedFusion(cfg.MODEL_NAME, cfg.N_FEATURES).to(cfg.DEVICE)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.XLM_R_LR)\n",
        "    total_steps = len(train_loader) * cfg.XLM_R_EPOCHS\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_val_macro = -1.0; patience_left = cfg.XLM_R_PATIENCE\n",
        "    for epoch in range(cfg.XLM_R_EPOCHS):\n",
        "        model.train()\n",
        "        for batch in tqdm(train_loader, desc=f\"Gated Fusion Training Epoch {epoch+1}\"):\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(batch['input_ids'].to(cfg.DEVICE), batch['attention_mask'].to(cfg.DEVICE), batch['feats'].to(cfg.DEVICE))\n",
        "            loss = criterion(logits, batch['labels'].to(cfg.DEVICE))\n",
        "            loss.backward()\n",
        "            optimizer.step(); scheduler.step()\n",
        "\n",
        "        y_true_val, y_pred_val, _ = run_evaluation_loop(model, val_loader, cfg.DEVICE, 'gated')\n",
        "        val_macro = f1_score(y_true_val, y_pred_val, average='macro')\n",
        "        print(f\"Epoch {epoch+1} Val Macro F1: {val_macro:.4f}\")\n",
        "\n",
        "        if val_macro > best_val_macro:\n",
        "            best_val_macro = val_macro\n",
        "            patience_left = cfg.XLM_R_PATIENCE\n",
        "            torch.save(model.state_dict(), os.path.join(cfg.GATED_OUTPUTS, \"fusion_gated.pt\"))\n",
        "            print(\"✅ New best Gated Fusion model saved.\")\n",
        "        else:\n",
        "            patience_left -= 1\n",
        "            if patience_left <= 0:\n",
        "                print(\"⏹️ Early stopping triggered.\")\n",
        "                break\n",
        "    print(\"✅ Gated Fusion trained successfully.\")\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "def train_xgboost(cfg, train_df, val_df, feats_tr, feats_v):\n",
        "    print(\"\\n--- Training XGBoost model ---\")\n",
        "    os.makedirs(cfg.XGB_OUTPUTS, exist_ok=True)\n",
        "\n",
        "    y_train = train_df['label'].astype(int).values\n",
        "    y_val   = val_df['label'].astype(int).values\n",
        "\n",
        "    # scale features\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    import joblib\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(feats_tr)\n",
        "    X_val_scaled   = scaler.transform(feats_v)\n",
        "    joblib.dump(scaler, os.path.join(cfg.XGB_OUTPUTS, \"scaler12.pkl\"))\n",
        "\n",
        "    # key: pass early_stopping_rounds to .fit() (works in 1.x)\n",
        "    clf = XGBClassifier(\n",
        "        n_estimators=cfg.XGB_ESTIMATORS,\n",
        "        learning_rate=cfg.XGB_LR,\n",
        "        max_depth=cfg.XGB_MAX_DEPTH,\n",
        "        random_state=42,\n",
        "        use_label_encoder=False,\n",
        "        eval_metric=\"logloss\",\n",
        "    )\n",
        "\n",
        "    clf.fit(\n",
        "        X_train_scaled, y_train,\n",
        "        eval_set=[(X_val_scaled, y_val)],\n",
        "        early_stopping_rounds=cfg.XGB_EARLY_STOP,  # ✅ valid in xgboost 1.x\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    clf.save_model(os.path.join(cfg.XGB_OUTPUTS, \"xgb_model.json\"))\n",
        "    print(\"✅ XGBoost model trained and saved.\")\n",
        "    print(f\"Best iteration: {clf.best_iteration}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ===================== Main Execution =====================\n",
        "if __name__ == \"__main__\":\n",
        "    set_seed(42)\n",
        "    cfg = Config()\n",
        "\n",
        "    # --- Step 1: Clean Data ---\n",
        "    # clean_and_split_data(cfg.RAW_CORPUS_CSV, cfg.CLEAN_TRAIN_CSV, cfg.CLEAN_VAL_CSV, cfg.CLEAN_TEST_CSV)\n",
        "\n",
        "    train_df = pd.read_csv(cfg.CLEAN_TRAIN_CSV)\n",
        "    val_df = pd.read_csv(cfg.CLEAN_VAL_CSV)\n",
        "    test_df = pd.read_csv(cfg.CLEAN_TEST_CSV)\n",
        "    lex = TermsLexicon(cfg.TERMS_CSV)\n",
        "    fe = FeatureExtractor12(lex)\n",
        "\n",
        "    # --- Step 2: Extract features for all models ---\n",
        "    print(\"\\n--- Extracting features for all models... ---\")\n",
        "    feats_tr = fe.extract_df(train_df)\n",
        "    feats_v = fe.extract_df(val_df)\n",
        "    feats_te = fe.extract_df(test_df)\n",
        "\n",
        "    # --- Step 3: Train All Models ---\n",
        "    train_xgboost(cfg, train_df, val_df, feats_tr, feats_v)\n",
        "    train_xlmr_only(cfg, train_df, val_df, XLMRobertaTokenizerFast.from_pretrained(cfg.MODEL_NAME))\n",
        "    train_simple_fusion(cfg, train_df, val_df, feats_tr, feats_v, lex)\n",
        "    train_gated_fusion(cfg, train_df, val_df, feats_tr, feats_v, lex)\n",
        "\n",
        "    # --- Step 4: Final Evaluation ---\n",
        "    print(\"\\n--- Running final evaluation on clean test set for all models ---\")\n",
        "\n",
        "    # --- Load Models for Eval ---\n",
        "    clf_xgb = xgb.XGBClassifier(); clf_xgb.load_model(os.path.join(cfg.XGB_OUTPUTS, \"xgb_model.json\"))\n",
        "    scaler_xgb = joblib.load(os.path.join(cfg.XGB_OUTPUTS, \"scaler12.pkl\"))\n",
        "\n",
        "    model_xlmr = XLMRobertaForSequenceClassification.from_pretrained(cfg.XLM_R_OUTPUTS).to(cfg.DEVICE)\n",
        "    tokenizer_xlmr = XLMRobertaTokenizerFast.from_pretrained(cfg.XLM_R_OUTPUTS)\n",
        "\n",
        "    model_simple = SimpleFusion(cfg.MODEL_NAME, cfg.N_FEATURES).to(cfg.DEVICE)\n",
        "    model_simple.load_state_dict(torch.load(os.path.join(cfg.SIMPLE_OUTPUTS, \"fusion_simple.pt\")), strict=False)\n",
        "    scaler_simple = joblib.load(os.path.join(cfg.SIMPLE_OUTPUTS, \"scaler12.pkl\"))\n",
        "\n",
        "    model_gated = GatedFusion(cfg.MODEL_NAME, cfg.N_FEATURES).to(cfg.DEVICE)\n",
        "    model_gated.load_state_dict(torch.load(os.path.join(cfg.GATED_OUTPUTS, \"fusion_gated.pt\")), strict=False)\n",
        "    scaler_gated = joblib.load(os.path.join(cfg.GATED_OUTPUTS, \"scaler12.pkl\"))\n",
        "\n",
        "    # --- Prepare Test Data ---\n",
        "    X_test_xgb, y_true_xgb, _ = build_feature_matrix(test_df, cfg, lex)\n",
        "    X_test_scaled_xgb = scaler_xgb.transform(X_test_xgb)\n",
        "\n",
        "    X_test_simple, y_true_simple, _ = build_feature_matrix(test_df, cfg, lex)\n",
        "    X_test_scaled_simple = scaler_simple.transform(X_test_simple)\n",
        "\n",
        "    X_test_gated, y_true_gated, _ = build_feature_matrix(test_df, cfg, lex)\n",
        "    X_test_scaled_gated = scaler_gated.transform(X_test_gated)\n",
        "\n",
        "    test_ds_xlmr = TextFeatDataset(test_df, tokenizer_xlmr, feats=None)\n",
        "    test_loader_xlmr = DataLoader(test_ds_xlmr, batch_size=cfg.BATCH_SIZE, collate_fn=DataCollatorWithPadding(tokenizer_xlmr))\n",
        "\n",
        "    # --- Run Evaluations & Collect Results ---\n",
        "    results_dict = {}\n",
        "\n",
        "    # XGBoost\n",
        "    print(\"\\nEvaluating XGBoost...\")\n",
        "    y_prob_xgb = clf_xgb.predict_proba(X_test_scaled_xgb); y_pred_xgb = y_prob_xgb.argmax(axis=1)\n",
        "    results_dict['XGBoost + Features'] = {'y_true': y_true_xgb, 'y_pred': y_pred_xgb, 'y_prob': y_prob_xgb[:,1]}\n",
        "\n",
        "    # XLM-R\n",
        "    print(\"\\nEvaluating XLM-R Only...\")\n",
        "    y_true_xlmr, y_pred_xlmr, y_prob_xlmr = run_evaluation_loop(model_xlmr, test_loader_xlmr, cfg.DEVICE, 'xlmr')\n",
        "    results_dict['XLM-R Only'] = {'y_true': y_true_xlmr, 'y_pred': y_pred_xlmr, 'y_prob': y_prob_xlmr[:,1]}\n",
        "\n",
        "    # Simple Fusion\n",
        "    print(\"\\nEvaluating Simple Fusion...\")\n",
        "    test_ds_simple = TextFeatDataset(test_df, tokenizer_xlmr, feats=X_test_scaled_simple.astype(np.float32))\n",
        "    test_loader_simple = DataLoader(test_ds_simple, batch_size=cfg.BATCH_SIZE)\n",
        "    y_true_simple, y_pred_simple, y_prob_simple = run_evaluation_loop(model_simple, test_loader_simple, cfg.DEVICE, 'simple')\n",
        "    results_dict['Simple Fusion'] = {'y_true': y_true_simple, 'y_pred': y_pred_simple, 'y_prob': y_prob_simple[:,1]}\n",
        "\n",
        "    # Gated Fusion\n",
        "    print(\"\\nEvaluating Gated Fusion...\")\n",
        "    test_ds_gated = TextFeatDataset(test_df, tokenizer_xlmr, feats=X_test_scaled_gated.astype(np.float32))\n",
        "    test_loader_gated = DataLoader(test_ds_gated, batch_size=cfg.BATCH_SIZE)\n",
        "    y_true_gated, y_pred_gated, y_prob_gated = run_evaluation_loop(model_gated, test_loader_gated, cfg.DEVICE, 'gated')\n",
        "    results_dict['Gated Fusion'] = {'y_true': y_true_gated, 'y_pred': y_pred_gated, 'y_prob': y_prob_gated[:,1]}\n",
        "\n",
        "    # --- Print Final Table and Plots ---\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"Final Model Performance on Clean Test Set\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    table_data = []\n",
        "    for name, res in results_dict.items():\n",
        "        y_true, y_pred, y_prob = res['y_true'], res['y_pred'], res['y_prob']\n",
        "\n",
        "        metrics = compute_metrics(y_true, y_pred)\n",
        "        cis = bootstrap_ci(y_true, y_pred)\n",
        "\n",
        "        table_data.append({\n",
        "            \"Model\": name,\n",
        "            \"AUC-ROC\": roc_auc_score(y_true, y_prob),\n",
        "            \"Precision_Real\": precision_score(y_true, y_pred, pos_label=0, zero_division=0),\n",
        "            \"Recall_Real\": recall_score(y_true, y_pred, pos_label=0, zero_division=0),\n",
        "            \"F1_Real\": f1_score(y_true, y_pred, pos_label=0, zero_division=0),\n",
        "            \"CI_F1_Real_low\": cis['F1-score Real (0)'][0],\n",
        "            \"CI_F1_Real_high\": cis['F1-score Real (0)'][1],\n",
        "            \"Precision_Misinfo\": precision_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
        "            \"Recall_Misinfo\": recall_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
        "            \"F1_Misinfo\": f1_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
        "            \"CI_F1_Misinfo_low\": cis['F1-score Misinformation (1)'][0],\n",
        "            \"CI_F1_Misinfo_high\": cis['F1-score Misinformation (1)'][1],\n",
        "            \"Macro_F1\": metrics['macro_f1'],\n",
        "            \"CI_Macro_F1_low\": cis['Macro F1'][0],\n",
        "            \"CI_Macro_F1_high\": cis['Macro F1'][1],\n",
        "            \"Micro_F1\": metrics['micro_f1'],\n",
        "            \"CI_Micro_F1_low\": cis['Micro F1'][0],\n",
        "            \"CI_Micro_F1_high\": cis['Micro F1'][1],\n",
        "            \"Weighted_F1\": metrics['weighted_f1'],\n",
        "            \"CI_Weighted_F1_low\": cis['Weighted F1'][0],\n",
        "            \"CI_Weighted_F1_high\": cis['Weighted F1'][1],\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(table_data)\n",
        "    print(results_df)\n",
        "\n",
        "    # --- Combined AUC-ROC Plot ---\n",
        "    print(\"\\n--- Generating combined AUC-ROC plot... ---\")\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    for name, res in results_dict.items():\n",
        "        y_true, y_prob = res['y_true'], res['y_prob']\n",
        "        fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, lw=2, label=f'{name} (AUC = {roc_auc:.4f})')\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
        "    plt.title('Combined Model ROC Curves')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(cfg.COMBINED_AUC_ROC_PLOT_PATH, dpi=300)\n",
        "    print(f\"✅ Combined AUC-ROC plot saved to: {cfg.COMBINED_AUC_ROC_PLOT_PATH}\")\n",
        "\n",
        "    # --- Permutation Importance for XGBoost ---\n",
        "    print(\"\\n--- Generating Permutation Importance plot for XGBoost... ---\")\n",
        "    feat_names = [\"Chars\", \"Words\", \"Sents\", \"Flesch RE (en)\", \"Gunning Fog (en)\", \"% Eng Terms\", \"Punctuation\", \"Number Count\", \"Contains Standard\", \"Contains Safety\", \"Avg Number Mag\", \"Decimal Ratio\"]\n",
        "    result = permutation_importance(clf_xgb, X_test_scaled_xgb, y_true_xgb, n_repeats=10, random_state=42, n_jobs=-1)\n",
        "    importance_df = pd.DataFrame({'Feature': feat_names, 'Importance_Mean': result.importances_mean}).sort_values('Importance_Mean', ascending=True)\n",
        "    plt.figure(figsize=(10, 8)); plt.barh(importance_df['Feature'], importance_df['Importance_Mean'], color='darkblue'); plt.title('XGBoost Permutation Feature Importance'); plt.tight_layout(); plt.savefig(os.path.join(cfg.XGB_OUTPUTS, \"permutation_importance.png\"))\n",
        "    print(f\"✅ XGBoost Permutation Importance plot saved.\")\n",
        "\n",
        "    print(\"\\n✅ All training and evaluation complete.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pEEb9pVztrl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBOOST AND FEATURES"
      ],
      "metadata": {
        "id": "Oof6p6NfzyEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 0: imports, config, seed, helpers ---\n",
        "import os, re, json, random\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, Tuple, Optional, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    f1_score, accuracy_score, precision_score, recall_score,\n",
        "    roc_auc_score, roc_curve, auc\n",
        ")\n",
        "from sklearn.utils import resample\n",
        "import joblib\n",
        "\n",
        "import xgboost as xgb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    XLMRobertaForSequenceClassification,\n",
        "    XLMRobertaModel,\n",
        "    XLMRobertaTokenizerFast,\n",
        "    DataCollatorWithPadding,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "\n",
        "try:\n",
        "    import textstat\n",
        "    _HAS_TEXTSTAT = True\n",
        "except Exception:\n",
        "    _HAS_TEXTSTAT = False\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    BASE_DIR: str = \"/content/drive/MyDrive/emc\"\n",
        "    CLEAN_TRAIN_CSV: str = \"/content/drive/MyDrive/emc/train.csv\"\n",
        "    CLEAN_VAL_CSV:   str = \"/content/drive/MyDrive/emc/val.csv\"\n",
        "    CLEAN_TEST_CSV:  str = \"/content/drive/MyDrive/emc/test.csv\"\n",
        "    TERMS_CSV:       str = \"/content/drive/MyDrive/emc/engineering_terms.csv\"\n",
        "\n",
        "    XGB_OUTPUTS:     str = \"/content/drive/MyDrive/emc/xgb_outputs_clean\"\n",
        "\n",
        "    TEXT_COL:  str = \"content\"\n",
        "    LABEL_COL: str = \"label\"\n",
        "    LANG_COL:  str = \"lang\"\n",
        "\n",
        "    N_FEATURES: int = 12\n",
        "    N_CLASSES:  int = 2\n",
        "    MAX_LEN:    int = 256\n",
        "    BATCH_SIZE: int = 16\n",
        "\n",
        "    # XGB\n",
        "    XGB_ESTIMATORS: int   = 2000\n",
        "    XGB_LR:         float = 0.03\n",
        "    XGB_MAX_DEPTH:  int   = 6\n",
        "    XGB_EARLY_STOP: int   = 100\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# Version helper (no extra deps)\n",
        "def _xgb_is_v2() -> bool:\n",
        "    try:\n",
        "        major = int(xgb.__version__.split('.')[0])\n",
        "        return major >= 2\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "print(\"xgboost version:\", xgb.__version__, \"| uses v2 API:\", _xgb_is_v2())\n"
      ],
      "metadata": {
        "id": "IbvSdawlz3SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 1: feature extraction (safe casting) ---\n",
        "STD_TERMS = {\"iso\",\"asme\",\"ieee\",\"din\",\"ansi\",\"iec\",\"ul\",\"astm\",\"en\"}\n",
        "SAFETY_TERMS = {\"safety\",\"hazard\",\"warning\",\"risk\",\"caution\",\"danger\",\"emergency\"}\n",
        "_WORD_RE = re.compile(r\"\\w+\", re.UNICODE)\n",
        "_NUM_RE  = re.compile(r'[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?')\n",
        "\n",
        "def simple_words(t: str) -> List[str]:\n",
        "    return _WORD_RE.findall(t or \"\")\n",
        "\n",
        "def sent_count(t: str) -> int:\n",
        "    if not t: return 0\n",
        "    return max(1, len(re.split(r'[.!?]+[\\s\\n]+', t)))\n",
        "\n",
        "def punct_count(t: str) -> int:\n",
        "    return sum(1 for ch in (t or \"\") if ch in \".,;:!?\")\n",
        "\n",
        "def extract_numbers(text: str):\n",
        "    nums, dec = [], 0\n",
        "    for m in _NUM_RE.finditer(text or \"\"):\n",
        "        s = m.group(0)\n",
        "        try:\n",
        "            v = float(s)\n",
        "            if ('.' in s) or ('e' in s.lower()):\n",
        "                dec += 1\n",
        "            nums.append(abs(v))\n",
        "        except:\n",
        "            pass\n",
        "    return nums, dec\n",
        "\n",
        "def _finite_or_zero(x: float) -> float:\n",
        "    try:\n",
        "        xx = float(x)\n",
        "        return xx if np.isfinite(xx) else 0.0\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "class TermsLexicon:\n",
        "    def __init__(self, csv_path: str, term_col=\"terms\", lang_col=\"lang\"):\n",
        "        if not os.path.exists(csv_path): raise FileNotFoundError(csv_path)\n",
        "        df = pd.read_csv(csv_path)\n",
        "        if term_col not in df.columns: raise ValueError(f\"Missing '{term_col}'\")\n",
        "        if lang_col not in df.columns: df[lang_col] = 'en'\n",
        "        self.by_lang = {\n",
        "            str(l).lower(): set(str(x).strip().lower()\n",
        "                                for x in d[term_col].dropna().tolist() if str(x).strip())\n",
        "            for l, d in df.groupby(lang_col)\n",
        "        }\n",
        "\n",
        "    def pct_in_text(self, text: str, lang: str) -> float:\n",
        "        if not text: return 0.0\n",
        "        terms = self.by_lang.get((lang or \"en\").lower(), set())\n",
        "        if not terms: return 0.0\n",
        "        ws = [w.lower() for w in simple_words(text)]\n",
        "        if not ws: return 0.0\n",
        "        return sum(1 for w in ws if w in terms) / max(1, len(ws))\n",
        "\n",
        "class FeatureExtractor12:\n",
        "    def __init__(self, tlex: TermsLexicon):\n",
        "        self.tlex = tlex\n",
        "\n",
        "    def extract_one(self, text: str, lang: str) -> np.ndarray:\n",
        "        text = \"\" if text is None else str(text)\n",
        "        lang = (lang or \"en\").lower()\n",
        "\n",
        "        ws = simple_words(text); n_words = len(ws)\n",
        "        chars = len(text)\n",
        "        words = n_words\n",
        "        sents = sent_count(text)\n",
        "\n",
        "        if lang == \"en\" and _HAS_TEXTSTAT and text.strip():\n",
        "            fre = _finite_or_zero(textstat.flesch_reading_ease(text))\n",
        "            fog = _finite_or_zero(textstat.gunning_fog(text))\n",
        "        else:\n",
        "            fre, fog = 0.0, 0.0\n",
        "\n",
        "        eng_pct = self.tlex.pct_in_text(text, lang)\n",
        "        punc = punct_count(text)\n",
        "        nums, dec_cnt = extract_numbers(text)\n",
        "        nnums = len(nums)\n",
        "        avg_mag = float(np.mean(nums)) if nums else 0.0\n",
        "        dec_ratio = float(dec_cnt / max(1, len(nums)))  # safe\n",
        "\n",
        "        low = text.lower()\n",
        "        has_std = 1.0 if any(t in low for t in STD_TERMS) else 0.0\n",
        "        has_saf = 1.0 if any(t in low for t in SAFETY_TERMS) else 0.0\n",
        "\n",
        "        vals = [chars, words, sents, fre, fog, eng_pct, punc, nnums, has_std, has_saf, avg_mag, dec_ratio]\n",
        "        feats = np.asarray([_finite_or_zero(v) for v in vals], dtype=np.float64)\n",
        "        feats = np.nan_to_num(feats, nan=0.0, posinf=1e12, neginf=0.0)\n",
        "        feats = np.clip(feats, -1e12, 1e12).astype(np.float32)\n",
        "        return feats\n",
        "\n",
        "    def extract_df(self, df: pd.DataFrame) -> np.ndarray:\n",
        "        assert 'content' in df.columns\n",
        "        local = df if 'lang' in df.columns else df.assign(lang='en')\n",
        "        rows = [\n",
        "            self.extract_one(r.get(\"content\",\"\"), r.get(\"lang\",\"en\"))\n",
        "            for _, r in tqdm(local.iterrows(), total=len(local), desc=\"Extracting features\")\n",
        "        ]\n",
        "        return np.stack(rows, axis=0).astype(np.float32)\n",
        "\n",
        "def build_feature_matrix(df: pd.DataFrame, cfg: Config, lex: TermsLexicon) -> Tuple[np.ndarray, np.ndarray, List[str]]:\n",
        "    fe = FeatureExtractor12(lex)\n",
        "    X = fe.extract_df(df)\n",
        "    # robust mapping for labels that might be '0'/'1' or ints\n",
        "    y = np.array([0 if str(v).strip().lower().startswith('0') else (1 if str(v).strip().lower().startswith('1') else int(v))\n",
        "                  for v in df[cfg.LABEL_COL].tolist()], dtype=np.int32)\n",
        "    return X, y, df[cfg.TEXT_COL].astype(str).tolist()\n"
      ],
      "metadata": {
        "id": "zkTI0Imuz_Kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 2: load data & extract features ---\n",
        "train_df = pd.read_csv(cfg.CLEAN_TRAIN_CSV)\n",
        "val_df   = pd.read_csv(cfg.CLEAN_VAL_CSV)\n",
        "test_df  = pd.read_csv(cfg.CLEAN_TEST_CSV)\n",
        "\n",
        "lex = TermsLexicon(cfg.TERMS_CSV)\n",
        "fe  = FeatureExtractor12(lex)\n",
        "\n",
        "print(\"\\n--- Extracting features for all splits ---\")\n",
        "feats_tr = fe.extract_df(train_df)\n",
        "feats_v  = fe.extract_df(val_df)\n",
        "feats_te = fe.extract_df(test_df)\n",
        "\n",
        "print(\"Shapes | train/val/test:\", feats_tr.shape, feats_v.shape, feats_te.shape)\n"
      ],
      "metadata": {
        "id": "ctu5rTvM0EB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 3: train XGBoost only (version-agnostic early stopping) ---\n",
        "os.makedirs(cfg.XGB_OUTPUTS, exist_ok=True)\n",
        "\n",
        "y_train = train_df[cfg.LABEL_COL].astype(int).values\n",
        "y_val   = val_df[cfg.LABEL_COL].astype(int).values\n",
        "\n",
        "scaler_xgb = StandardScaler()\n",
        "X_train_scaled = scaler_xgb.fit_transform(feats_tr)\n",
        "X_val_scaled   = scaler_xgb.transform(feats_v)\n",
        "joblib.dump(scaler_xgb, os.path.join(cfg.XGB_OUTPUTS, \"scaler12.pkl\"))\n",
        "\n",
        "if _xgb_is_v2():\n",
        "    # xgboost 2.x → early_stopping_rounds in constructor\n",
        "    clf_xgb = xgb.XGBClassifier(\n",
        "        n_estimators=cfg.XGB_ESTIMATORS,\n",
        "        learning_rate=cfg.XGB_LR,\n",
        "        max_depth=cfg.XGB_MAX_DEPTH,\n",
        "        random_state=42,\n",
        "        eval_metric=\"logloss\",\n",
        "        early_stopping_rounds=cfg.XGB_EARLY_STOP,\n",
        "    )\n",
        "    clf_xgb.fit(X_train_scaled, y_train, eval_set=[(X_val_scaled, y_val)], verbose=True)\n",
        "else:\n",
        "    # xgboost 1.x → early_stopping_rounds goes to .fit()\n",
        "    clf_xgb = xgb.XGBClassifier(\n",
        "        n_estimators=cfg.XGB_ESTIMATORS,\n",
        "        learning_rate=cfg.XGB_LR,\n",
        "        max_depth=cfg.XGB_MAX_DEPTH,\n",
        "        random_state=42,\n",
        "        use_label_encoder=False,\n",
        "        eval_metric=\"logloss\",\n",
        "    )\n",
        "    clf_xgb.fit(\n",
        "        X_train_scaled, y_train,\n",
        "        eval_set=[(X_val_scaled, y_val)],\n",
        "        early_stopping_rounds=cfg.XGB_EARLY_STOP,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "clf_xgb.save_model(os.path.join(cfg.XGB_OUTPUTS, \"xgb_model.json\"))\n",
        "print(\"✅ XGB trained. Best iteration:\", getattr(clf_xgb, \"best_iteration\", None))\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rBitV-MH0TQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 4: evaluate XGB on test set ---\n",
        "X_test_scaled = scaler_xgb.transform(feats_te)\n",
        "y_test = test_df[cfg.LABEL_COL].astype(int).values\n",
        "\n",
        "proba = clf_xgb.predict_proba(X_test_scaled)[:,1]\n",
        "pred  = (proba >= 0.5).astype(int)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, pred))\n",
        "print(\"Macro F1:\", f1_score(y_test, pred, average='macro'))\n",
        "print(\"AUC:\", roc_auc_score(y_test, proba))\n"
      ],
      "metadata": {
        "id": "tE8byIu-0aQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 5: evaluation (table + ROC; no permutation importance on val) ---\n",
        "from sklearn.metrics import (\n",
        "    f1_score, precision_score, recall_score, roc_auc_score, roc_curve, auc\n",
        ")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    return {\n",
        "        \"macro_f1\": f1_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
        "        \"micro_f1\": f1_score(y_true, y_pred, average=\"micro\", zero_division=0),\n",
        "        \"weighted_f1\": f1_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
        "        \"accuracy\": (y_true == y_pred).mean(),\n",
        "    }\n",
        "\n",
        "def bootstrap_ci(y_true, y_pred, n_resamples=1000, alpha=0.95):\n",
        "    y_true, y_pred = np.asarray(y_true), np.asarray(y_pred)\n",
        "    N = len(y_true)\n",
        "    lo_q = (1 - alpha) / 2 * 100.0\n",
        "    hi_q = (1 - (1 - alpha) / 2) * 100.0\n",
        "\n",
        "    macro_vals, micro_vals, weighted_vals = [], [], []\n",
        "    f1_real_vals, f1_mis_vals = [], []\n",
        "\n",
        "    rng = np.random.default_rng(42)\n",
        "    for _ in range(n_resamples):\n",
        "        idx = rng.integers(0, N, size=N)\n",
        "        yt, yp = y_true[idx], y_pred[idx]\n",
        "        macro_vals.append(f1_score(yt, yp, average='macro', zero_division=0))\n",
        "        micro_vals.append(f1_score(yt, yp, average='micro', zero_division=0))\n",
        "        weighted_vals.append(f1_score(yt, yp, average='weighted', zero_division=0))\n",
        "        f1_real_vals.append(f1_score(yt, yp, pos_label=0, zero_division=0))\n",
        "        f1_mis_vals.append(f1_score(yt, yp, pos_label=1, zero_division=0))\n",
        "\n",
        "    return {\n",
        "        'Macro F1': np.percentile(macro_vals, [lo_q, hi_q]).tolist(),\n",
        "        'Micro F1': np.percentile(micro_vals, [lo_q, hi_q]).tolist(),\n",
        "        'Weighted F1': np.percentile(weighted_vals, [lo_q, hi_q]).tolist(),\n",
        "        'F1-score Real (0)': np.percentile(f1_real_vals, [lo_q, hi_q]).tolist(),\n",
        "        'F1-score Misinformation (1)': np.percentile(f1_mis_vals, [lo_q, hi_q]).tolist(),\n",
        "    }\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "# 1) Build/extend results_dict for whatever models you have available.\n",
        "#    Below: example for XGB only. Add other models similarly.\n",
        "# -----------------------------------------------------------------------\n",
        "results_dict = {}\n",
        "\n",
        "# If you trained XGB in Block 3 and have feats_te / scaler_xgb:\n",
        "X_test_scaled = scaler_xgb.transform(feats_te)\n",
        "y_test = test_df[cfg.LABEL_COL].astype(int).values\n",
        "proba_xgb = clf_xgb.predict_proba(X_test_scaled)[:, 1]\n",
        "pred_xgb  = (proba_xgb >= 0.5).astype(int)\n",
        "results_dict['XGBoost + Features'] = {\n",
        "    'y_true': y_test,\n",
        "    'y_pred': pred_xgb,\n",
        "    'y_prob': proba_xgb\n",
        "}\n",
        "\n",
        "# If/when you have other models, add entries like:\n",
        "# results_dict['XLM-R Only'] = {'y_true': y_true_xlmr, 'y_pred': y_pred_xlmr, 'y_prob': y_prob_xlmr[:,1]}\n",
        "# results_dict['Simple Fusion'] = {'y_true': y_true_simple, 'y_pred': y_pred_simple, 'y_prob': y_prob_simple[:,1]}\n",
        "# results_dict['Gated Fusion']  = {'y_true': y_true_gated,  'y_pred': y_pred_gated,  'y_prob': y_prob_gated[:,1]}\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "# 2) Make the summary table with the exact fields you want\n",
        "# -----------------------------------------------------------------------\n",
        "table_data = []\n",
        "for name, res in results_dict.items():\n",
        "    y_true = res['y_true']\n",
        "    y_pred = res['y_pred']\n",
        "    y_prob = res['y_prob']\n",
        "\n",
        "    metrics = compute_metrics(y_true, y_pred)\n",
        "    cis = bootstrap_ci(y_true, y_pred, n_resamples=1000, alpha=0.95)\n",
        "\n",
        "    row = {\n",
        "        \"Model\": name,\n",
        "        \"AUC-ROC\": roc_auc_score(y_true, y_prob),\n",
        "        \"Precision_Real\": precision_score(y_true, y_pred, pos_label=0, zero_division=0),\n",
        "        \"Recall_Real\": recall_score(y_true, y_pred, pos_label=0, zero_division=0),\n",
        "        \"F1_Real\": f1_score(y_true, y_pred, pos_label=0, zero_division=0),\n",
        "        \"CI_F1_Real_low\":  cis['F1-score Real (0)'][0],\n",
        "        \"CI_F1_Real_high\": cis['F1-score Real (0)'][1],\n",
        "        \"Precision_Misinfo\": precision_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
        "        \"Recall_Misinfo\":    recall_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
        "        \"F1_Misinfo\":        f1_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
        "        \"CI_F1_Misinfo_low\":  cis['F1-score Misinformation (1)'][0],\n",
        "        \"CI_F1_Misinfo_high\": cis['F1-score Misinformation (1)'][1],\n",
        "        \"Macro_F1\": metrics['macro_f1'],\n",
        "        \"CI_Macro_F1_low\":  cis['Macro F1'][0],\n",
        "        \"CI_Macro_F1_high\": cis['Macro F1'][1],\n",
        "        \"Micro_F1\": metrics['micro_f1'],\n",
        "        \"CI_Micro_F1_low\":  cis['Micro F1'][0],\n",
        "        \"CI_Micro_F1_high\": cis['Micro F1'][1],\n",
        "        \"Weighted_F1\": metrics['weighted_f1'],\n",
        "        \"CI_Weighted_F1_low\":  cis['Weighted F1'][0],\n",
        "        \"CI_Weighted_F1_high\": cis['Weighted F1'][1],\n",
        "    }\n",
        "    table_data.append(row)\n",
        "\n",
        "results_df = pd.DataFrame(table_data)\n",
        "print(\"\\n\" + \"=\"*90)\n",
        "print(\"Final Model Performance (Test Set)\")\n",
        "print(\"=\"*90)\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "# 3) Combined ROC plot (over the same TEST set)\n",
        "# -----------------------------------------------------------------------\n",
        "plt.figure(figsize=(9, 7))\n",
        "for name, res in results_dict.items():\n",
        "    y_true = res['y_true']\n",
        "    y_prob = res['y_prob']\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, lw=2, label=f\"{name} (AUC = {roc_auc:.4f})\")\n",
        "\n",
        "plt.plot([0,1],[0,1], linestyle='--')\n",
        "plt.xlim([0,1]); plt.ylim([0,1.05])\n",
        "plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
        "plt.title('XG ROC (Test Set)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# NOTE:\n",
        "# - We intentionally do NOT compute permutation importance on the validation set here.\n",
        "# - If you want permutation importance at all, run it on TEST (or skip entirely for clean reporting).\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qoJR1p1X1cri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XLM-R"
      ],
      "metadata": {
        "id": "_srsZGEV7eAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 6: dataset + evaluation loop for XLM-R only ---\n",
        "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizerFast, DataCollatorWithPadding, get_linear_schedule_with_warmup\n",
        "\n",
        "class TextDatasetXLMR(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, text_col: str, label_col: str, tokenizer, max_len: int):\n",
        "        self.texts = df[text_col].astype(str).tolist()\n",
        "        raw = df[label_col].tolist()\n",
        "        ids = []\n",
        "        for v in raw:\n",
        "            s = str(v).strip().lower()\n",
        "            if s in (\"0\",\"1\"):\n",
        "                ids.append(int(s))\n",
        "            else:\n",
        "                # fallback if labels are strings like \"Real\"/\"Misinformation\"\n",
        "                ids.append(1 if s.startswith(\"mis\") else 0)\n",
        "        self.labels = ids\n",
        "        self.tok = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self): return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tok(self.texts[idx], truncation=True, max_length=self.max_len, padding=False, return_tensors=\"pt\")\n",
        "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "@torch.no_grad()\n",
        "def xlmr_eval_loop(model, dataloader, device):\n",
        "    model.eval()\n",
        "    all_y, all_pred, all_prob = [], [], []\n",
        "    for batch in tqdm(dataloader, desc=\"Evaluating XLM-R\", leave=False):\n",
        "        inputs = {k: v.to(device) for k, v in batch.items() if k in (\"input_ids\",\"attention_mask\",\"labels\")}\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        probs = torch.softmax(logits, dim=-1)\n",
        "        pred = probs.argmax(dim=-1)\n",
        "        all_y.extend(inputs[\"labels\"].cpu().tolist())\n",
        "        all_pred.extend(pred.cpu().tolist())\n",
        "        all_prob.extend(probs[:,1].cpu().tolist())\n",
        "    return np.array(all_y), np.array(all_pred), np.array(all_prob)\n"
      ],
      "metadata": {
        "id": "DiSdn4KO2KHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 7: train XLM-R only ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if not hasattr(cfg, \"XLM_R_OUTPUTS\"):\n",
        "    cfg.XLM_R_OUTPUTS = \"/content/drive/MyDrive/emc/xlmr_only_outputs_clean\"\n",
        "\n",
        "os.makedirs(os.path.join(cfg.BASE_DIR, \"xlmr_only_outputs_clean\"), exist_ok=True)\n",
        "\n",
        "tokenizer_xlmr = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-base\")\n",
        "train_ds = TextDatasetXLMR(train_df, cfg.TEXT_COL, cfg.LABEL_COL, tokenizer_xlmr, cfg.MAX_LEN)\n",
        "val_ds   = TextDatasetXLMR(val_df,   cfg.TEXT_COL, cfg.LABEL_COL, tokenizer_xlmr, cfg.MAX_LEN)\n",
        "\n",
        "collator = DataCollatorWithPadding(tokenizer_xlmr)\n",
        "train_loader = DataLoader(train_ds, batch_size=cfg.BATCH_SIZE, shuffle=True, collate_fn=collator)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
        "\n",
        "model_xlmr = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=2).to(device)\n",
        "optimizer = torch.optim.AdamW(model_xlmr.parameters(), lr=2e-5)\n",
        "total_steps = len(train_loader) * 5\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "best_val_macro = -1.0\n",
        "patience = 3\n",
        "\n",
        "for epoch in range(5):\n",
        "    model_xlmr.train()\n",
        "    epoch_loss = 0.0\n",
        "    for batch in tqdm(train_loader, desc=f\"XLM-R Epoch {epoch+1}\"):\n",
        "        optimizer.zero_grad()\n",
        "        inputs = {k: v.to(device) for k, v in batch.items()}\n",
        "        out = model_xlmr(**inputs)\n",
        "        out.loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        epoch_loss += out.loss.item()\n",
        "    # validate\n",
        "    yv, pv, _ = xlmr_eval_loop(model_xlmr, val_loader, device)\n",
        "    val_macro = f1_score(yv, pv, average=\"macro\", zero_division=0)\n",
        "    print(f\"Epoch {epoch+1} | train_loss={epoch_loss/len(train_loader):.4f} | val_macro={val_macro:.4f}\")\n",
        "    if val_macro > best_val_macro:\n",
        "        best_val_macro = val_macro\n",
        "        patience = 3\n",
        "        model_xlmr.save_pretrained(cfg.XLM_R_OUTPUTS)\n",
        "        tokenizer_xlmr.save_pretrained(cfg.XLM_R_OUTPUTS)\n",
        "        print(\"✅ Saved new best XLM-R checkpoint.\")\n",
        "    else:\n",
        "        patience -= 1\n",
        "        if patience <= 0:\n",
        "            print(\"⏹️ Early stopping.\")\n",
        "            break\n",
        "\n",
        "# load best\n",
        "model_xlmr = XLMRobertaForSequenceClassification.from_pretrained(cfg.XLM_R_OUTPUTS).to(device)\n",
        "tokenizer_xlmr = XLMRobertaTokenizerFast.from_pretrained(cfg.XLM_R_OUTPUTS)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-wcEZIKV2NRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 8: evaluate XLM-R only on TEST (table + ROC) ---\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, roc_curve, auc\n",
        "\n",
        "# helpers (same schema you requested)\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    return {\n",
        "        \"macro_f1\": f1_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
        "        \"micro_f1\": f1_score(y_true, y_pred, average=\"micro\", zero_division=0),\n",
        "        \"weighted_f1\": f1_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
        "        \"accuracy\": (y_true == y_pred).mean(),\n",
        "    }\n",
        "\n",
        "def bootstrap_ci(y_true, y_pred, n_resamples=1000, alpha=0.95):\n",
        "    y_true, y_pred = np.asarray(y_true), np.asarray(y_pred)\n",
        "    N = len(y_true)\n",
        "    lo_q = (1 - alpha) / 2 * 100.0\n",
        "    hi_q = (1 - (1 - alpha) / 2) * 100.0\n",
        "    rng = np.random.default_rng(42)\n",
        "\n",
        "    macro_vals, micro_vals, weighted_vals = [], [], []\n",
        "    f1_real_vals, f1_mis_vals = [], []\n",
        "    for _ in range(n_resamples):\n",
        "        idx = rng.integers(0, N, size=N)\n",
        "        yt, yp = y_true[idx], y_pred[idx]\n",
        "        macro_vals.append(f1_score(yt, yp, average=\"macro\", zero_division=0))\n",
        "        micro_vals.append(f1_score(yt, yp, average=\"micro\", zero_division=0))\n",
        "        weighted_vals.append(f1_score(yt, yp, average=\"weighted\", zero_division=0))\n",
        "        f1_real_vals.append(f1_score(yt, yp, pos_label=0, zero_division=0))\n",
        "        f1_mis_vals.append(f1_score(yt, yp, pos_label=1, zero_division=0))\n",
        "    return {\n",
        "        \"Macro F1\": np.percentile(macro_vals, [lo_q, hi_q]).tolist(),\n",
        "        \"Micro F1\": np.percentile(micro_vals, [lo_q, hi_q]).tolist(),\n",
        "        \"Weighted F1\": np.percentile(weighted_vals, [lo_q, hi_q]).tolist(),\n",
        "        \"F1-score Real (0)\": np.percentile(f1_real_vals, [lo_q, hi_q]).tolist(),\n",
        "        \"F1-score Misinformation (1)\": np.percentile(f1_mis_vals, [lo_q, hi_q]).tolist(),\n",
        "    }\n",
        "\n",
        "# test loader\n",
        "test_ds_xlmr = TextDatasetXLMR(test_df, cfg.TEXT_COL, cfg.LABEL_COL, tokenizer_xlmr, cfg.MAX_LEN)\n",
        "test_loader_xlmr = DataLoader(test_ds_xlmr, batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=DataCollatorWithPadding(tokenizer_xlmr))\n",
        "\n",
        "# evaluate\n",
        "y_true, y_pred, y_prob = xlmr_eval_loop(model_xlmr, test_loader_xlmr, device)\n",
        "\n",
        "# build table row (exact fields)\n",
        "metrics = compute_metrics(y_true, y_pred)\n",
        "cis = bootstrap_ci(y_true, y_pred, n_resamples=1000, alpha=0.95)\n",
        "row = {\n",
        "    \"Model\": \"XLM-R Only\",\n",
        "    \"AUC-ROC\": roc_auc_score(y_true, y_prob),\n",
        "    \"Precision_Real\": precision_score(y_true, y_pred, pos_label=0, zero_division=0),\n",
        "    \"Recall_Real\": recall_score(y_true, y_pred, pos_label=0, zero_division=0),\n",
        "    \"F1_Real\": f1_score(y_true, y_pred, pos_label=0, zero_division=0),\n",
        "    \"CI_F1_Real_low\":  cis['F1-score Real (0)'][0],\n",
        "    \"CI_F1_Real_high\": cis['F1-score Real (0)'][1],\n",
        "    \"Precision_Misinfo\": precision_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
        "    \"Recall_Misinfo\":    recall_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
        "    \"F1_Misinfo\":        f1_score(y_true, y_pred, pos_label=1, zero_division=0),\n",
        "    \"CI_F1_Misinfo_low\":  cis['F1-score Misinformation (1)'][0],\n",
        "    \"CI_F1_Misinfo_high\": cis['F1-score Misinformation (1)'][1],\n",
        "    \"Macro_F1\": metrics['macro_f1'],\n",
        "    \"CI_Macro_F1_low\":  cis['Macro F1'][0],\n",
        "    \"CI_Macro_F1_high\": cis['Macro F1'][1],\n",
        "    \"Micro_F1\": metrics['micro_f1'],\n",
        "    \"CI_Micro_F1_low\":  cis['Micro F1'][0],\n",
        "    \"CI_Micro_F1_high\": cis['Micro F1'][1],\n",
        "    \"Weighted_F1\": metrics['weighted_f1'],\n",
        "    \"CI_Weighted_F1_low\":  cis['Weighted F1'][0],\n",
        "    \"CI_Weighted_F1_high\": cis['Weighted F1'][1],\n",
        "}\n",
        "results_df = pd.DataFrame([row])\n",
        "\n",
        "print(\"\\n\" + \"=\"*90)\n",
        "print(\"XLM-R Only — Performance on TEST\")\n",
        "print(\"=\"*90)\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "# ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(fpr, tpr, lw=2, label=f\"XLM-R Only (AUC = {roc_auc:.4f})\")\n",
        "plt.plot([0,1],[0,1],'--')\n",
        "plt.xlim([0,1]); plt.ylim([0,1.05])\n",
        "plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC — XLM-R Only (TEST)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "N5ZrMFpM69pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SIMPLE FUSION"
      ],
      "metadata": {
        "id": "qVtwKeNn7ysK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 9: train Simple Fusion ---\n",
        "import os, numpy as np, torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import XLMRobertaModel, XLMRobertaTokenizerFast, get_linear_schedule_with_warmup\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ensure output dir exists on cfg\n",
        "if not hasattr(cfg, \"SIMPLE_OUTPUTS\"):\n",
        "    cfg.SIMPLE_OUTPUTS = \"/content/drive/MyDrive/emc/simple_fusion_outputs_clean\"\n",
        "os.makedirs(cfg.SIMPLE_OUTPUTS, exist_ok=True)\n",
        "\n",
        "# tokenizer\n",
        "tok_sf = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-base\")\n",
        "\n",
        "# ---- dataset\n",
        "class TextFeatDatasetSF(Dataset):\n",
        "    def __init__(self, df, tokenizer, feats, max_len=256, text_col=\"content\", label_col=\"label\"):\n",
        "        self.texts = df[text_col].astype(str).tolist()\n",
        "        raw = df[label_col].tolist()\n",
        "        ids = []\n",
        "        for v in raw:\n",
        "            s = str(v).strip().lower()\n",
        "            if s in (\"0\",\"1\"): ids.append(int(s))\n",
        "            else: ids.append(1 if s.startswith(\"mis\") else 0)\n",
        "        self.labels = ids\n",
        "        self.tok = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.feats = feats.astype(np.float32)\n",
        "\n",
        "    def __len__(self): return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tok(self.texts[idx],\n",
        "                       truncation=True, padding=\"max_length\",\n",
        "                       max_length=self.max_len, return_tensors=\"pt\")\n",
        "        item = {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n",
        "            \"feats\": torch.tensor(self.feats[idx], dtype=torch.float32),\n",
        "        }\n",
        "        return item\n",
        "\n",
        "# ---- model\n",
        "class SimpleFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + n_feats, n_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        # mean pool with attention mask\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (out.last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "        fused = torch.cat([pooled, feats], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "\n",
        "@torch.no_grad()\n",
        "def simple_eval_loop(model, loader, device):\n",
        "    model.eval()\n",
        "    y_all, p_all, prob_all = [], [], []\n",
        "    for batch in loader:\n",
        "        ids = batch[\"input_ids\"].to(device)\n",
        "        am  = batch[\"attention_mask\"].to(device)\n",
        "        ft  = batch[\"feats\"].to(device)\n",
        "        log = model(ids, am, ft)\n",
        "        prob = torch.softmax(log, dim=-1)\n",
        "        pred = prob.argmax(dim=-1)\n",
        "        y_all.extend(batch[\"labels\"].cpu().tolist())\n",
        "        p_all.extend(pred.cpu().tolist())\n",
        "        prob_all.extend(prob[:,1].cpu().tolist())\n",
        "    return np.array(y_all), np.array(p_all), np.array(prob_all)\n",
        "\n",
        "# ---- scale features (fit on train, transform val), persist scaler\n",
        "scaler_simple = StandardScaler()\n",
        "feats_tr_sc = scaler_simple.fit_transform(feats_tr).astype(np.float32)\n",
        "feats_v_sc  = scaler_simple.transform(feats_v).astype(np.float32)\n",
        "joblib.dump(scaler_simple, os.path.join(cfg.SIMPLE_OUTPUTS, \"scaler12.pkl\"))\n",
        "\n",
        "# ---- loaders\n",
        "train_ds_sf = TextFeatDatasetSF(train_df, tok_sf, feats_tr_sc, max_len=cfg.MAX_LEN,\n",
        "                                text_col=cfg.TEXT_COL, label_col=cfg.LABEL_COL)\n",
        "val_ds_sf   = TextFeatDatasetSF(val_df,   tok_sf, feats_v_sc,  max_len=cfg.MAX_LEN,\n",
        "                                text_col=cfg.TEXT_COL, label_col=cfg.LABEL_COL)\n",
        "\n",
        "train_loader_sf = DataLoader(train_ds_sf, batch_size=cfg.BATCH_SIZE, shuffle=True)\n",
        "val_loader_sf   = DataLoader(val_ds_sf,   batch_size=cfg.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# ---- train loop with early stop on Val Macro-F1\n",
        "model_sf = SimpleFusion(\"xlm-roberta-base\", n_feats=cfg.N_FEATURES, n_labels=2).to(device)\n",
        "opt  = torch.optim.AdamW(model_sf.parameters(), lr=2e-5)\n",
        "sched = get_linear_schedule_with_warmup(opt, num_warmup_steps=0,\n",
        "                                        num_training_steps=len(train_loader_sf)*5)\n",
        "crit = nn.CrossEntropyLoss()\n",
        "\n",
        "best_val_macro = -1.0\n",
        "patience = 3\n",
        "for epoch in range(5):\n",
        "    model_sf.train()\n",
        "    epoch_loss = 0.0\n",
        "    for batch in tqdm(train_loader_sf, desc=f\"Simple Fusion Epoch {epoch+1}\"):\n",
        "        opt.zero_grad()\n",
        "        ids = batch[\"input_ids\"].to(device)\n",
        "        am  = batch[\"attention_mask\"].to(device)\n",
        "        ft  = batch[\"feats\"].to(device)\n",
        "        y   = batch[\"labels\"].to(device)\n",
        "        logits = model_sf(ids, am, ft)\n",
        "        loss = crit(logits, y)\n",
        "        loss.backward()\n",
        "        opt.step(); sched.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    # validate\n",
        "    from sklearn.metrics import f1_score\n",
        "    yv, pv, _ = simple_eval_loop(model_sf, val_loader_sf, device)\n",
        "    val_macro = f1_score(yv, pv, average=\"macro\", zero_division=0)\n",
        "    print(f\"Epoch {epoch+1} | train_loss={epoch_loss/len(train_loader_sf):.4f} | val_macro={val_macro:.4f}\")\n",
        "\n",
        "    if val_macro > best_val_macro:\n",
        "        best_val_macro = val_macro\n",
        "        patience = 3\n",
        "        torch.save(model_sf.state_dict(), os.path.join(cfg.SIMPLE_OUTPUTS, \"fusion_simple.pt\"))\n",
        "        print(\"✅ Saved new best Simple Fusion checkpoint.\")\n",
        "    else:\n",
        "        patience -= 1\n",
        "        if patience <= 0:\n",
        "            print(\"⏹️ Early stopping.\")\n",
        "            break\n",
        "\n",
        "# load best\n",
        "model_sf.load_state_dict(torch.load(os.path.join(cfg.SIMPLE_OUTPUTS, \"fusion_simple.pt\"), map_location=device))\n",
        "model_sf.to(device)\n",
        "print(\"✅ Simple Fusion ready.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "v12-VmJZ74rU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 10: evaluate Simple Fusion on TEST (table + ROC) ---\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "from sklearn.metrics import (\n",
        "    f1_score, precision_score, recall_score, roc_auc_score, roc_curve, auc\n",
        ")\n",
        "import joblib\n",
        "\n",
        "# reload scaler + scale test feats\n",
        "scaler_simple = joblib.load(os.path.join(cfg.SIMPLE_OUTPUTS, \"scaler12.pkl\"))\n",
        "feats_te_sc = scaler_simple.transform(feats_te).astype(np.float32)\n",
        "\n",
        "# dataset/loader for test\n",
        "test_ds_sf = TextFeatDatasetSF(test_df, tok_sf, feats_te_sc, max_len=cfg.MAX_LEN,\n",
        "                               text_col=cfg.TEXT_COL, label_col=cfg.LABEL_COL)\n",
        "test_loader_sf = DataLoader(test_ds_sf, batch_size=cfg.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# eval\n",
        "y_true_sf, y_pred_sf, y_prob_sf = simple_eval_loop(model_sf, test_loader_sf, device)\n",
        "\n",
        "# helpers: metrics + bootstrap CIs (same schema you wanted)\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    return {\n",
        "        \"macro_f1\": f1_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
        "        \"micro_f1\": f1_score(y_true, y_pred, average=\"micro\", zero_division=0),\n",
        "        \"weighted_f1\": f1_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
        "        \"accuracy\": (y_true == y_pred).mean(),\n",
        "    }\n",
        "\n",
        "def bootstrap_ci(y_true, y_pred, n_resamples=1000, alpha=0.95):\n",
        "    y_true, y_pred = np.asarray(y_true), np.asarray(y_pred)\n",
        "    N = len(y_true)\n",
        "    lo_q = (1 - alpha) / 2 * 100.0\n",
        "    hi_q = (1 - (1 - alpha) / 2) * 100.0\n",
        "    rng = np.random.default_rng(42)\n",
        "    macro_vals, micro_vals, weighted_vals = [], [], []\n",
        "    f1_real_vals, f1_mis_vals = [], []\n",
        "    for _ in range(n_resamples):\n",
        "        idx = rng.integers(0, N, size=N)\n",
        "        yt, yp = y_true[idx], y_pred[idx]\n",
        "        macro_vals.append(f1_score(yt, yp, average=\"macro\", zero_division=0))\n",
        "        micro_vals.append(f1_score(yt, yp, average=\"micro\", zero_division=0))\n",
        "        weighted_vals.append(f1_score(yt, yp, average=\"weighted\", zero_division=0))\n",
        "        f1_real_vals.append(f1_score(yt, yp, pos_label=0, zero_division=0))\n",
        "        f1_mis_vals.append(f1_score(yt, yp, pos_label=1, zero_division=0))\n",
        "    return {\n",
        "        \"Macro F1\": np.percentile(macro_vals, [lo_q, hi_q]).tolist(),\n",
        "        \"Micro F1\": np.percentile(micro_vals, [lo_q, hi_q]).tolist(),\n",
        "        \"Weighted F1\": np.percentile(weighted_vals, [lo_q, hi_q]).tolist(),\n",
        "        \"F1-score Real (0)\": np.percentile(f1_real_vals, [lo_q, hi_q]).tolist(),\n",
        "        \"F1-score Misinformation (1)\": np.percentile(f1_mis_vals, [lo_q, hi_q]).tolist(),\n",
        "    }\n",
        "\n",
        "metrics = compute_metrics(y_true_sf, y_pred_sf)\n",
        "cis = bootstrap_ci(y_true_sf, y_pred_sf, n_resamples=1000, alpha=0.95)\n",
        "\n",
        "row = {\n",
        "    \"Model\": \"Simple Fusion\",\n",
        "    \"AUC-ROC\": roc_auc_score(y_true_sf, y_prob_sf),\n",
        "    \"Precision_Real\": precision_score(y_true_sf, y_pred_sf, pos_label=0, zero_division=0),\n",
        "    \"Recall_Real\": recall_score(y_true_sf, y_pred_sf, pos_label=0, zero_division=0),\n",
        "    \"F1_Real\": f1_score(y_true_sf, y_pred_sf, pos_label=0, zero_division=0),\n",
        "    \"CI_F1_Real_low\":  cis['F1-score Real (0)'][0],\n",
        "    \"CI_F1_Real_high\": cis['F1-score Real (0)'][1],\n",
        "    \"Precision_Misinfo\": precision_score(y_true_sf, y_pred_sf, pos_label=1, zero_division=0),\n",
        "    \"Recall_Misinfo\":    recall_score(y_true_sf, y_pred_sf, pos_label=1, zero_division=0),\n",
        "    \"F1_Misinfo\":        f1_score(y_true_sf, y_pred_sf, pos_label=1, zero_division=0),\n",
        "    \"CI_F1_Misinfo_low\":  cis['F1-score Misinformation (1)'][0],\n",
        "    \"CI_F1_Misinfo_high\": cis['F1-score Misinformation (1)'][1],\n",
        "    \"Macro_F1\": metrics['macro_f1'],\n",
        "    \"CI_Macro_F1_low\":  cis['Macro F1'][0],\n",
        "    \"CI_Macro_F1_high\": cis['Macro F1'][1],\n",
        "    \"Micro_F1\": metrics['micro_f1'],\n",
        "    \"CI_Micro_F1_low\":  cis['Micro F1'][0],\n",
        "    \"CI_Micro_F1_high\": cis['Micro F1'][1],\n",
        "    \"Weighted_F1\": metrics['weighted_f1'],\n",
        "    \"CI_Weighted_F1_low\":  cis['Weighted F1'][0],\n",
        "    \"CI_Weighted_F1_high\": cis['Weighted F1'][1],\n",
        "}\n",
        "results_df_sf = pd.DataFrame([row])\n",
        "\n",
        "print(\"\\n\" + \"=\"*90)\n",
        "print(\"Simple Fusion — Performance on TEST\")\n",
        "print(\"=\"*90)\n",
        "print(results_df_sf.to_string(index=False))\n",
        "\n",
        "# ROC\n",
        "fpr, tpr, _ = roc_curve(y_true_sf, y_prob_sf)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(fpr, tpr, lw=2, label=f\"Simple Fusion (AUC = {roc_auc:.4f})\")\n",
        "plt.plot([0,1],[0,1],'--')\n",
        "plt.xlim([0,1]); plt.ylim([0,1.05])\n",
        "plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC — Simple Fusion (TEST)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NjZmCjn__VXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GATED FUSION"
      ],
      "metadata": {
        "id": "68vzVVQqAQNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 11: train Gated Fusion ---\n",
        "import os, numpy as np, torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import XLMRobertaModel, XLMRobertaTokenizerFast, get_linear_schedule_with_warmup\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ensure output dir exists on cfg\n",
        "if not hasattr(cfg, \"GATED_OUTPUTS\"):\n",
        "    cfg.GATED_OUTPUTS = \"/content/drive/MyDrive/emc/gated_fusion_outputs_clean\"\n",
        "os.makedirs(cfg.GATED_OUTPUTS, exist_ok=True)\n",
        "\n",
        "# tokenizer\n",
        "tok_gf = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-base\")\n",
        "\n",
        "# ---- dataset\n",
        "class TextFeatDatasetGF(Dataset):\n",
        "    def __init__(self, df, tokenizer, feats, max_len=256, text_col=\"content\", label_col=\"label\"):\n",
        "        self.texts = df[text_col].astype(str).tolist()\n",
        "        raw = df[label_col].tolist()\n",
        "        ids = []\n",
        "        for v in raw:\n",
        "            s = str(v).strip().lower()\n",
        "            if s in (\"0\",\"1\"): ids.append(int(s))\n",
        "            else: ids.append(1 if s.startswith(\"mis\") else 0)\n",
        "        self.labels = ids\n",
        "        self.tok = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.feats = feats.astype(np.float32)\n",
        "\n",
        "    def __len__(self): return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tok(self.texts[idx],\n",
        "                       truncation=True, padding=\"max_length\",\n",
        "                       max_length=self.max_len, return_tensors=\"pt\")\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n",
        "            \"feats\": torch.tensor(self.feats[idx], dtype=torch.float32),\n",
        "        }\n",
        "\n",
        "# ---- model\n",
        "class GatedFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2, feat_proj: int = 64):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.fe_proj = nn.Sequential(nn.Linear(n_feats, feat_proj), nn.ReLU())\n",
        "        self.gate    = nn.Sequential(nn.Linear(H + n_feats, 64), nn.ReLU(), nn.Linear(64, 1), nn.Sigmoid())\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + feat_proj, n_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        # mean pool with attention mask\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (out.last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "        alpha = self.gate(torch.cat([pooled, feats], dim=1))      # (B,1)\n",
        "        ef    = self.fe_proj(feats)                               # (B,feat_proj)\n",
        "        fused = torch.cat([pooled, alpha * ef], dim=1)            # gate-modulated features\n",
        "        return self.classifier(self.dropout(fused))\n",
        "\n",
        "@torch.no_grad()\n",
        "def gated_eval_loop(model, loader, device):\n",
        "    model.eval()\n",
        "    y_all, p_all, prob_all = [], [], []\n",
        "    for batch in loader:\n",
        "        ids = batch[\"input_ids\"].to(device)\n",
        "        am  = batch[\"attention_mask\"].to(device)\n",
        "        ft  = batch[\"feats\"].to(device)\n",
        "        log = model(ids, am, ft)\n",
        "        prob = torch.softmax(log, dim=-1)\n",
        "        pred = prob.argmax(dim=-1)\n",
        "        y_all.extend(batch[\"labels\"].cpu().tolist())\n",
        "        p_all.extend(pred.cpu().tolist())\n",
        "        prob_all.extend(prob[:,1].cpu().tolist())\n",
        "    return np.array(y_all), np.array(p_all), np.array(prob_all)\n",
        "\n",
        "# ---- scale features (fit on train, transform val), persist scaler\n",
        "scaler_gated = StandardScaler()\n",
        "feats_tr_sc = scaler_gated.fit_transform(feats_tr).astype(np.float32)\n",
        "feats_v_sc  = scaler_gated.transform(feats_v).astype(np.float32)\n",
        "joblib.dump(scaler_gated, os.path.join(cfg.GATED_OUTPUTS, \"scaler12.pkl\"))\n",
        "\n",
        "# ---- loaders\n",
        "train_ds_gf = TextFeatDatasetGF(train_df, tok_gf, feats_tr_sc, max_len=cfg.MAX_LEN,\n",
        "                                text_col=cfg.TEXT_COL, label_col=cfg.LABEL_COL)\n",
        "val_ds_gf   = TextFeatDatasetGF(val_df,   tok_gf, feats_v_sc,  max_len=cfg.MAX_LEN,\n",
        "                                text_col=cfg.TEXT_COL, label_col=cfg.LABEL_COL)\n",
        "\n",
        "train_loader_gf = DataLoader(train_ds_gf, batch_size=cfg.BATCH_SIZE, shuffle=True)\n",
        "val_loader_gf   = DataLoader(val_ds_gf,   batch_size=cfg.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# ---- train loop with early stop on Val Macro-F1\n",
        "model_gf = GatedFusion(\"xlm-roberta-base\", n_feats=cfg.N_FEATURES, n_labels=2, feat_proj=64).to(device)\n",
        "opt  = torch.optim.AdamW(model_gf.parameters(), lr=2e-5)\n",
        "sched = get_linear_schedule_with_warmup(opt, num_warmup_steps=0,\n",
        "                                        num_training_steps=len(train_loader_gf)*5)\n",
        "crit = nn.CrossEntropyLoss()\n",
        "\n",
        "best_val_macro = -1.0\n",
        "patience = 3\n",
        "for epoch in range(5):\n",
        "    model_gf.train()\n",
        "    epoch_loss = 0.0\n",
        "    for batch in tqdm(train_loader_gf, desc=f\"Gated Fusion Epoch {epoch+1}\"):\n",
        "        opt.zero_grad()\n",
        "        ids = batch[\"input_ids\"].to(device)\n",
        "        am  = batch[\"attention_mask\"].to(device)\n",
        "        ft  = batch[\"feats\"].to(device)\n",
        "        y   = batch[\"labels\"].to(device)\n",
        "        logits = model_gf(ids, am, ft)\n",
        "        loss = crit(logits, y)\n",
        "        loss.backward()\n",
        "        opt.step(); sched.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    # validate\n",
        "    yv, pv, _ = gated_eval_loop(model_gf, val_loader_gf, device)\n",
        "    val_macro = f1_score(yv, pv, average=\"macro\", zero_division=0)\n",
        "    print(f\"Epoch {epoch+1} | train_loss={epoch_loss/len(train_loader_gf):.4f} | val_macro={val_macro:.4f}\")\n",
        "\n",
        "    if val_macro > best_val_macro:\n",
        "        best_val_macro = val_macro\n",
        "        patience = 3\n",
        "        torch.save(model_gf.state_dict(), os.path.join(cfg.GATED_OUTPUTS, \"fusion_gated.pt\"))\n",
        "        print(\"✅ Saved new best Gated Fusion checkpoint.\")\n",
        "    else:\n",
        "        patience -= 1\n",
        "        if patience <= 0:\n",
        "            print(\"⏹️ Early stopping.\")\n",
        "            break\n",
        "\n",
        "# load best\n",
        "model_gf.load_state_dict(torch.load(os.path.join(cfg.GATED_OUTPUTS, \"fusion_gated.pt\"), map_location=device))\n",
        "model_gf.to(device)\n",
        "print(\"✅ Gated Fusion ready.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IgQvqfEsAT8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 12: evaluate Gated Fusion on TEST (table + ROC) ---\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "from sklearn.metrics import (\n",
        "    f1_score, precision_score, recall_score, roc_auc_score, roc_curve, auc\n",
        ")\n",
        "import joblib\n",
        "\n",
        "# reload scaler + scale test feats\n",
        "scaler_gated = joblib.load(os.path.join(cfg.GATED_OUTPUTS, \"scaler12.pkl\"))\n",
        "feats_te_sc = scaler_gated.transform(feats_te).astype(np.float32)\n",
        "\n",
        "# dataset/loader for test\n",
        "test_ds_gf = TextFeatDatasetGF(test_df, tok_gf, feats_te_sc, max_len=cfg.MAX_LEN,\n",
        "                               text_col=cfg.TEXT_COL, label_col=cfg.LABEL_COL)\n",
        "test_loader_gf = DataLoader(test_ds_gf, batch_size=cfg.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# eval\n",
        "y_true_gf, y_pred_gf, y_prob_gf = gated_eval_loop(model_gf, test_loader_gf, device)\n",
        "\n",
        "# helpers: metrics + bootstrap CIs (your schema)\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    return {\n",
        "        \"macro_f1\": f1_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
        "        \"micro_f1\": f1_score(y_true, y_pred, average=\"micro\", zero_division=0),\n",
        "        \"weighted_f1\": f1_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
        "        \"accuracy\": (y_true == y_pred).mean(),\n",
        "    }\n",
        "\n",
        "def bootstrap_ci(y_true, y_pred, n_resamples=1000, alpha=0.95):\n",
        "    y_true, y_pred = np.asarray(y_true), np.asarray(y_pred)\n",
        "    N = len(y_true)\n",
        "    lo_q = (1 - alpha) / 2 * 100.0\n",
        "    hi_q = (1 - (1 - alpha) / 2) * 100.0\n",
        "    rng = np.random.default_rng(42)\n",
        "    macro_vals, micro_vals, weighted_vals = [], [], []\n",
        "    f1_real_vals, f1_mis_vals = [], []\n",
        "    for _ in range(n_resamples):\n",
        "        idx = rng.integers(0, N, size=N)\n",
        "        yt, yp = y_true[idx], y_pred[idx]\n",
        "        macro_vals.append(f1_score(yt, yp, average=\"macro\", zero_division=0))\n",
        "        micro_vals.append(f1_score(yt, yp, average=\"micro\", zero_division=0))\n",
        "        weighted_vals.append(f1_score(yt, yp, average=\"weighted\", zero_division=0))\n",
        "        f1_real_vals.append(f1_score(yt, yp, pos_label=0, zero_division=0))\n",
        "        f1_mis_vals.append(f1_score(yt, yp, pos_label=1, zero_division=0))\n",
        "    return {\n",
        "        \"Macro F1\": np.percentile(macro_vals, [lo_q, hi_q]).tolist(),\n",
        "        \"Micro F1\": np.percentile(micro_vals, [lo_q, hi_q]).tolist(),\n",
        "        \"Weighted F1\": np.percentile(weighted_vals, [lo_q, hi_q]).tolist(),\n",
        "        \"F1-score Real (0)\": np.percentile(f1_real_vals, [lo_q, hi_q]).tolist(),\n",
        "        \"F1-score Misinformation (1)\": np.percentile(f1_mis_vals, [lo_q, hi_q]).tolist(),\n",
        "    }\n",
        "\n",
        "metrics = compute_metrics(y_true_gf, y_pred_gf)\n",
        "cis = bootstrap_ci(y_true_gf, y_pred_gf, n_resamples=1000, alpha=0.95)\n",
        "\n",
        "row = {\n",
        "    \"Model\": \"Gated Fusion\",\n",
        "    \"AUC-ROC\": roc_auc_score(y_true_gf, y_prob_gf),\n",
        "    \"Precision_Real\": precision_score(y_true_gf, y_pred_gf, pos_label=0, zero_division=0),\n",
        "    \"Recall_Real\": recall_score(y_true_gf, y_pred_gf, pos_label=0, zero_division=0),\n",
        "    \"F1_Real\": f1_score(y_true_gf, y_pred_gf, pos_label=0, zero_division=0),\n",
        "    \"CI_F1_Real_low\":  cis['F1-score Real (0)'][0],\n",
        "    \"CI_F1_Real_high\": cis['F1-score Real (0)'][1],\n",
        "    \"Precision_Misinfo\": precision_score(y_true_gf, y_pred_gf, pos_label=1, zero_division=0),\n",
        "    \"Recall_Misinfo\":    recall_score(y_true_gf, y_pred_gf, pos_label=1, zero_division=0),\n",
        "    \"F1_Misinfo\":        f1_score(y_true_gf, y_pred_gf, pos_label=1, zero_division=0),\n",
        "    \"CI_F1_Misinfo_low\":  cis['F1-score Misinformation (1)'][0],\n",
        "    \"CI_F1_Misinfo_high\": cis['F1-score Misinformation (1)'][1],\n",
        "    \"Macro_F1\": metrics['macro_f1'],\n",
        "    \"CI_Macro_F1_low\":  cis['Macro F1'][0],\n",
        "    \"CI_Macro_F1_high\": cis['Macro F1'][1],\n",
        "    \"Micro_F1\": metrics['micro_f1'],\n",
        "    \"CI_Micro_F1_low\":  cis['Micro F1'][0],\n",
        "    \"CI_Micro_F1_high\": cis['Micro F1'][1],\n",
        "    \"Weighted_F1\": metrics['weighted_f1'],\n",
        "    \"CI_Weighted_F1_low\":  cis['Weighted F1'][0],\n",
        "    \"CI_Weighted_F1_high\": cis['Weighted F1'][1],\n",
        "}\n",
        "results_df_gf = pd.DataFrame([row])\n",
        "\n",
        "print(\"\\n\" + \"=\"*90)\n",
        "print(\"Gated Fusion — Performance on TEST\")\n",
        "print(\"=\"*90)\n",
        "print(results_df_gf.to_string(index=False))\n",
        "\n",
        "# ROC\n",
        "fpr, tpr, _ = roc_curve(y_true_gf, y_prob_gf)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(fpr, tpr, lw=2, label=f\"Gated Fusion (AUC = {roc_auc:.4f})\")\n",
        "plt.plot([0,1],[0,1],'--')\n",
        "plt.xlim([0,1]); plt.ylim([0,1.05])\n",
        "plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC — Gated Fusion (TEST)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "o4ZR3qhhDVWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ADVERSARIAL ATTACK"
      ],
      "metadata": {
        "id": "kqU6WRsHE-6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 13: adversarial attack functions ---\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "# seeded RNG for reproducibility\n",
        "ATTACK_SEED = 12345\n",
        "rng_attack = np.random.default_rng(ATTACK_SEED)\n",
        "\n",
        "# 1) Char swap within words (keeps first/last char)\n",
        "def attack_char_swap(text: str, p=0.07) -> str:\n",
        "    def swap_word(w):\n",
        "        if len(w) < 4: return w\n",
        "        chars = list(w)\n",
        "        for i in range(1, len(chars)-2):\n",
        "            if rng_attack.random() < p and chars[i].isalpha() and chars[i+1].isalpha():\n",
        "                chars[i], chars[i+1] = chars[i+1], chars[i]\n",
        "        return ''.join(chars)\n",
        "    return re.sub(r\"\\w+\", lambda m: swap_word(m.group(0)), text or \"\")\n",
        "\n",
        "# 2) Drop vowels in long words\n",
        "def attack_drop_vowels(text: str, p=0.15) -> str:\n",
        "    vowels = set(\"aeiouAEIOU\")\n",
        "    def dv(w):\n",
        "        if len(w) < 6: return w\n",
        "        if rng_attack.random() >= p: return w\n",
        "        return ''.join(ch for ch in w if ch not in vowels) or w\n",
        "    return re.sub(r\"\\w+\", lambda m: dv(m.group(0)), text or \"\")\n",
        "\n",
        "# 3) Insert random punctuation\n",
        "def attack_punct_insert(text: str, p=0.05) -> str:\n",
        "    punct = ['.', ',', ';', ':', '!', '?']\n",
        "    out = []\n",
        "    for ch in text or \"\":\n",
        "        out.append(ch)\n",
        "        if ch.isalnum() and rng_attack.random() < p:\n",
        "            out.append(rng_attack.choice(punct))\n",
        "    return ''.join(out)\n",
        "\n",
        "# 4) Whitespace noise (extra spaces/newlines)\n",
        "def attack_whitespace_noise(text: str, p=0.06) -> str:\n",
        "    out = []\n",
        "    for ch in text or \"\":\n",
        "        out.append(ch)\n",
        "        if ch.isspace() and rng_attack.random() < p:\n",
        "            out.append(' ' * rng_attack.integers(1, 4))\n",
        "        elif ch.isalnum() and rng_attack.random() < (p/4):\n",
        "            out.append('\\n')\n",
        "    return ''.join(out)\n",
        "\n",
        "# 5) Case toggle (random casing)\n",
        "def attack_case_toggle(text: str, p=0.25) -> str:\n",
        "    out = []\n",
        "    for ch in text or \"\":\n",
        "        if ch.isalpha() and rng_attack.random() < p:\n",
        "            out.append(ch.upper() if ch.islower() else ch.lower())\n",
        "        else:\n",
        "            out.append(ch)\n",
        "    return ''.join(out)\n",
        "\n",
        "# 6) Number perturbation ±5% (keep decimals & scientific format)\n",
        "_num_re = re.compile(r'(?P<sign>[-+]?)(?P<int>\\d+)(?P<frac>\\.\\d+)?(?P<exp>[eE][-+]?\\d+)?')\n",
        "def _format_like(orig, val):\n",
        "    sign, intval, frac, exp = orig.group('sign'), orig.group('int'), orig.group('frac'), orig.group('exp')\n",
        "    if exp:  # scientific\n",
        "        try:\n",
        "            d = \"{:e}\".format(val)\n",
        "            # keep exponent letter case\n",
        "            if 'E' in exp: d = d.replace('e', 'E')\n",
        "            return (sign or '') + d\n",
        "        except:\n",
        "            return orig.group(0)\n",
        "    if frac:\n",
        "        nd = len(frac) - 1\n",
        "        fmt = \"{:.\" + str(nd) + \"f}\"\n",
        "        return (sign or '') + fmt.format(val)\n",
        "    # integer\n",
        "    try:\n",
        "        return (sign or '') + str(int(round(val)))\n",
        "    except:\n",
        "        return orig.group(0)\n",
        "\n",
        "def attack_number_perturb(text: str, max_pct=0.05) -> str:\n",
        "    def repl(m):\n",
        "        s = m.group(0)\n",
        "        try:\n",
        "            v = float(s)\n",
        "            eps = rng_attack.uniform(-max_pct, max_pct)\n",
        "            nv = v * (1.0 + eps)\n",
        "            return _format_like(m, nv)\n",
        "        except:\n",
        "            return s\n",
        "    return _num_re.sub(repl, text or \"\")\n",
        "\n",
        "# 7) Unicode confusables (lightweight map)\n",
        "CONFUSE = {\n",
        "    'a':'ɑ', 'A':'Α',  # Greek Alpha for A (looks similar)\n",
        "    'e':'е', 'E':'Ε',\n",
        "    'i':'і', 'I':'І',\n",
        "    'o':'ο', 'O':'Ο',\n",
        "    'c':'ϲ', 'C':'Ϲ',\n",
        "    'p':'ρ', 'P':'Ρ',\n",
        "    'x':'х', 'X':'Χ',\n",
        "    'y':'у', 'Y':'Υ',\n",
        "    'k':'κ', 'K':'Κ',\n",
        "    'm':'ｍ', 'n':'ｎ', 'h':'һ', 's':'ѕ', 't':'τ', 'r':'г'\n",
        "}\n",
        "def attack_unicode_confuse(text: str, p=0.08) -> str:\n",
        "    out = []\n",
        "    for ch in text or \"\":\n",
        "        if ch in CONFUSE and rng_attack.random() < p:\n",
        "            out.append(CONFUSE[ch])\n",
        "        else:\n",
        "            out.append(ch)\n",
        "    return ''.join(out)\n",
        "\n",
        "# 8) Truncate to first N words (simulates clipping)\n",
        "def attack_truncate(text: str, max_words=80) -> str:\n",
        "    words = re.findall(r'\\S+', text or \"\")\n",
        "    return ' '.join(words[:max_words])\n",
        "\n",
        "# Registry so we can loop attacks\n",
        "ATTACKS = {\n",
        "    \"CharSwap\": attack_char_swap,\n",
        "    \"DropVowels\": attack_drop_vowels,\n",
        "    \"PunctInsert\": attack_punct_insert,\n",
        "    \"WhitespaceNoise\": attack_whitespace_noise,\n",
        "    \"CaseToggle\": attack_case_toggle,\n",
        "    \"NumberPerturb\": attack_number_perturb,\n",
        "    \"UnicodeConfuse\": attack_unicode_confuse,\n",
        "    \"Truncate80w\": attack_truncate,\n",
        "}\n",
        "\n",
        "def apply_attack_to_df(df: pd.DataFrame, attack_name: str, text_col: str = \"content\") -> pd.DataFrame:\n",
        "    if attack_name not in ATTACKS:\n",
        "        raise ValueError(f\"Unknown attack: {attack_name}\")\n",
        "    f = ATTACKS[attack_name]\n",
        "    attacked = df.copy()\n",
        "    attacked[text_col] = [f(str(t)) for t in df[text_col].tolist()]\n",
        "    return attacked\n"
      ],
      "metadata": {
        "id": "ylOmAyGpFCbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 14: loaders for trained models + datasets ---\n",
        "import os, joblib, torch, numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import XLMRobertaTokenizerFast, XLMRobertaForSequenceClassification, DataCollatorWithPadding\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Ensure output roots exist fields on cfg (for safety)\n",
        "if not hasattr(cfg, \"XGB_OUTPUTS\"):    cfg.XGB_OUTPUTS    = \"/content/drive/MyDrive/emc/xgb_outputs_clean\"\n",
        "if not hasattr(cfg, \"XLM_R_OUTPUTS\"):  cfg.XLM_R_OUTPUTS  = \"/content/drive/MyDrive/emc/xlmr_only_outputs_clean\"\n",
        "if not hasattr(cfg, \"SIMPLE_OUTPUTS\"): cfg.SIMPLE_OUTPUTS = \"/content/drive/MyDrive/emc/simple_fusion_outputs_clean\"\n",
        "if not hasattr(cfg, \"GATED_OUTPUTS\"):  cfg.GATED_OUTPUTS  = \"/content/drive/MyDrive/emc/gated_fusion_outputs_clean\"\n",
        "\n",
        "# ---- dataset classes\n",
        "class XLMRTestDS(Dataset):\n",
        "    def __init__(self, df, tokenizer, text_col=\"content\", label_col=\"label\", max_len=256):\n",
        "        self.texts = df[text_col].astype(str).tolist()\n",
        "        raw = df[label_col].tolist()\n",
        "        ids = []\n",
        "        for v in raw:\n",
        "            s = str(v).strip().lower()\n",
        "            if s in (\"0\",\"1\"): ids.append(int(s))\n",
        "            else: ids.append(1 if s.startswith(\"mis\") else 0)\n",
        "        self.labels = ids\n",
        "        self.tok = tokenizer\n",
        "        self.max_len = max_len\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tok(self.texts[idx], truncation=True, padding=False, max_length=self.max_len, return_tensors=\"pt\")\n",
        "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "class TextFeatDS(Dataset):\n",
        "    def __init__(self, df, tokenizer, feats, text_col=\"content\", label_col=\"label\", max_len=256):\n",
        "        self.texts = df[text_col].astype(str).tolist()\n",
        "        raw = df[label_col].tolist()\n",
        "        ids = []\n",
        "        for v in raw:\n",
        "            s = str(v).strip().lower()\n",
        "            if s in (\"0\",\"1\"): ids.append(int(s))\n",
        "            else: ids.append(1 if s.startswith(\"mis\") else 0)\n",
        "        self.labels = ids\n",
        "        self.tok = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.feats = feats.astype(np.float32)\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tok(self.texts[idx], truncation=True, padding=\"max_length\", max_length=self.max_len, return_tensors=\"pt\")\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n",
        "            \"feats\": torch.tensor(self.feats[idx], dtype=torch.float32),\n",
        "        }\n",
        "\n",
        "# ---- fusion models\n",
        "import torch.nn as nn\n",
        "from transformers import XLMRobertaModel, get_linear_schedule_with_warmup\n",
        "\n",
        "class SimpleFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + n_feats, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (out.last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "        fused = torch.cat([pooled, feats], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "\n",
        "class GatedFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2, feat_proj: int = 64):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.fe_proj = nn.Sequential(nn.Linear(n_feats, feat_proj), nn.ReLU())\n",
        "        self.gate    = nn.Sequential(nn.Linear(H + n_feats, 64), nn.ReLU(), nn.Linear(64, 1), nn.Sigmoid())\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + feat_proj, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (out.last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "        alpha = self.gate(torch.cat([pooled, feats], dim=1))\n",
        "        ef    = self.fe_proj(feats)\n",
        "        fused = torch.cat([pooled, alpha * ef], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "\n",
        "# ---- load whatever models are available\n",
        "available = {}\n",
        "\n",
        "# XGB\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    if os.path.exists(os.path.join(cfg.XGB_OUTPUTS, \"xgb_model.json\")):\n",
        "        xgb_model = xgb.XGBClassifier()\n",
        "        xgb_model.load_model(os.path.join(cfg.XGB_OUTPUTS, \"xgb_model.json\"))\n",
        "        xgb_scaler = joblib.load(os.path.join(cfg.XGB_OUTPUTS, \"scaler12.pkl\"))\n",
        "        available[\"XGBoost + Features\"] = (\"xgb\", xgb_model, xgb_scaler)\n",
        "        print(\"Loaded: XGB\")\n",
        "except Exception as e:\n",
        "    print(\"XGB load skipped:\", e)\n",
        "\n",
        "# XLM-R\n",
        "try:\n",
        "    if os.path.exists(cfg.XLM_R_OUTPUTS):\n",
        "        xlmr_tok = XLMRobertaTokenizerFast.from_pretrained(cfg.XLM_R_OUTPUTS)\n",
        "        xlmr_model = XLMRobertaForSequenceClassification.from_pretrained(cfg.XLM_R_OUTPUTS).to(device)\n",
        "        available[\"XLM-R Only\"] = (\"xlmr\", xlmr_model, xlmr_tok)\n",
        "        print(\"Loaded: XLM-R\")\n",
        "except Exception as e:\n",
        "    print(\"XLM-R load skipped:\", e)\n",
        "\n",
        "# Simple Fusion\n",
        "try:\n",
        "    if os.path.exists(os.path.join(cfg.SIMPLE_OUTPUTS, \"fusion_simple.pt\")):\n",
        "        sf_tok = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-base\")\n",
        "        sf_model = SimpleFusion(\"xlm-roberta-base\", n_feats=cfg.N_FEATURES, n_labels=2).to(device)\n",
        "        sf_model.load_state_dict(torch.load(os.path.join(cfg.SIMPLE_OUTPUTS, \"fusion_simple.pt\"), map_location=device))\n",
        "        sf_scaler = joblib.load(os.path.join(cfg.SIMPLE_OUTPUTS, \"scaler12.pkl\"))\n",
        "        available[\"Simple Fusion\"] = (\"simple\", sf_model, (sf_tok, sf_scaler))\n",
        "        print(\"Loaded: Simple Fusion\")\n",
        "except Exception as e:\n",
        "    print(\"Simple Fusion load skipped:\", e)\n",
        "\n",
        "# Gated Fusion\n",
        "try:\n",
        "    if os.path.exists(os.path.join(cfg.GATED_OUTPUTS, \"fusion_gated.pt\")):\n",
        "        gf_tok = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-base\")\n",
        "        gf_model = GatedFusion(\"xlm-roberta-base\", n_feats=cfg.N_FEATURES, n_labels=2, feat_proj=64).to(device)\n",
        "        gf_model.load_state_dict(torch.load(os.path.join(cfg.GATED_OUTPUTS, \"fusion_gated.pt\"), map_location=device))\n",
        "        gf_scaler = joblib.load(os.path.join(cfg.GATED_OUTPUTS, \"scaler12.pkl\"))\n",
        "        available[\"Gated Fusion\"] = (\"gated\", gf_model, (gf_tok, gf_scaler))\n",
        "        print(\"Loaded: Gated Fusion\")\n",
        "except Exception as e:\n",
        "    print(\"Gated Fusion load skipped:\", e)\n",
        "\n",
        "if not available:\n",
        "    raise RuntimeError(\"No models found. Train/load at least one model before running adversarial eval.\")\n"
      ],
      "metadata": {
        "id": "C1QTwq5oFJNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 15: evaluation helpers ---\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "# ensure we have extractor (from earlier blocks) for XGB features\n",
        "try:\n",
        "    fe  # existing instance\n",
        "except NameError:\n",
        "    # create minimal extractor from cfg paths\n",
        "    lex = TermsLexicon(cfg.TERMS_CSV)\n",
        "    fe = FeatureExtractor12(lex)\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_xlmr(df):\n",
        "    model = available[\"XLM-R Only\"][1]\n",
        "    tok   = available[\"XLM-R Only\"][2]\n",
        "    ds = XLMRTestDS(df, tok, text_col=cfg.TEXT_COL, label_col=cfg.LABEL_COL, max_len=cfg.MAX_LEN)\n",
        "    dl = DataLoader(ds, batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=DataCollatorWithPadding(tok))\n",
        "    model.eval()\n",
        "    y_all, p_all = [], []\n",
        "    for batch in dl:\n",
        "        ins = {k: v.to(device) for k, v in batch.items() if k in (\"input_ids\",\"attention_mask\",\"labels\")}\n",
        "        logits = model(**ins).logits\n",
        "        pred = logits.argmax(dim=-1)\n",
        "        y_all.extend(ins[\"labels\"].cpu().tolist())\n",
        "        p_all.extend(pred.cpu().tolist())\n",
        "    y_all = np.array(y_all); p_all = np.array(p_all)\n",
        "    return {\n",
        "        \"macro_f1\": f1_score(y_all, p_all, average=\"macro\", zero_division=0),\n",
        "        \"accuracy\": accuracy_score(y_all, p_all),\n",
        "    }\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_simple(df):\n",
        "    model = available[\"Simple Fusion\"][1]\n",
        "    tok, scaler = available[\"Simple Fusion\"][2]\n",
        "    X = fe.extract_df(df)\n",
        "    Xs = scaler.transform(X).astype(np.float32)\n",
        "    ds = TextFeatDS(df, tok, Xs, text_col=cfg.TEXT_COL, label_col=cfg.LABEL_COL, max_len=cfg.MAX_LEN)\n",
        "    dl = DataLoader(ds, batch_size=cfg.BATCH_SIZE, shuffle=False)\n",
        "    model.eval()\n",
        "    y_all, p_all = [], []\n",
        "    for b in dl:\n",
        "        ids = b[\"input_ids\"].to(device); am = b[\"attention_mask\"].to(device); ft = b[\"feats\"].to(device)\n",
        "        logits = model(ids, am, ft)\n",
        "        pred = logits.argmax(dim=-1)\n",
        "        y_all.extend(b[\"labels\"].cpu().tolist()); p_all.extend(pred.cpu().tolist())\n",
        "    y_all = np.array(y_all); p_all = np.array(p_all)\n",
        "    return {\n",
        "        \"macro_f1\": f1_score(y_all, p_all, average=\"macro\", zero_division=0),\n",
        "        \"accuracy\": accuracy_score(y_all, p_all),\n",
        "    }\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_gated(df):\n",
        "    model = available[\"Gated Fusion\"][1]\n",
        "    tok, scaler = available[\"Gated Fusion\"][2]\n",
        "    X = fe.extract_df(df)\n",
        "    Xs = scaler.transform(X).astype(np.float32)\n",
        "    ds = TextFeatDS(df, tok, Xs, text_col=cfg.TEXT_COL, label_col=cfg.LABEL_COL, max_len=cfg.MAX_LEN)\n",
        "    dl = DataLoader(ds, batch_size=cfg.BATCH_SIZE, shuffle=False)\n",
        "    model.eval()\n",
        "    y_all, p_all = [], []\n",
        "    for b in dl:\n",
        "        ids = b[\"input_ids\"].to(device); am = b[\"attention_mask\"].to(device); ft = b[\"feats\"].to(device)\n",
        "        logits = model(ids, am, ft)\n",
        "        pred = logits.argmax(dim=-1)\n",
        "        y_all.extend(b[\"labels\"].cpu().tolist()); p_all.extend(pred.cpu().tolist())\n",
        "    y_all = np.array(y_all); p_all = np.array(p_all)\n",
        "    return {\n",
        "        \"macro_f1\": f1_score(y_all, p_all, average=\"macro\", zero_division=0),\n",
        "        \"accuracy\": accuracy_score(y_all, p_all),\n",
        "    }\n",
        "\n",
        "def eval_xgb(df):\n",
        "    import xgboost as xgb\n",
        "    model = available[\"XGBoost + Features\"][1]\n",
        "    scaler = available[\"XGBoost + Features\"][2]\n",
        "    X = fe.extract_df(df)\n",
        "    Xs = scaler.transform(X)\n",
        "    y = df[cfg.LABEL_COL].astype(int).values\n",
        "    pred = model.predict(Xs)\n",
        "    return {\n",
        "        \"macro_f1\": f1_score(y, pred, average=\"macro\", zero_division=0),\n",
        "        \"accuracy\": accuracy_score(y, pred),\n",
        "    }\n",
        "\n",
        "def evaluate_models_on_df(df, attack_name: str):\n",
        "    rows = []\n",
        "    for name, (kind, *_rest) in available.items():\n",
        "        if kind == \"xlmr\":\n",
        "            m = eval_xlmr(df)\n",
        "        elif kind == \"simple\":\n",
        "            m = eval_simple(df)\n",
        "        elif kind == \"gated\":\n",
        "            m = eval_gated(df)\n",
        "        elif kind == \"xgb\":\n",
        "            m = eval_xgb(df)\n",
        "        else:\n",
        "            continue\n",
        "        rows.append({\"Model\": name, \"Attack\": attack_name, \"macro_f1\": m[\"macro_f1\"], \"accuracy\": m[\"accuracy\"]})\n",
        "    return rows\n"
      ],
      "metadata": {
        "id": "UqVqOMHpFStQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 16: CLEAN evaluation -> clean_eval.csv ---\n",
        "import os, pandas as pd\n",
        "\n",
        "adv_out_dir = \"/content/drive/MyDrive/emc/adv_eval_outputs\"\n",
        "os.makedirs(adv_out_dir, exist_ok=True)\n",
        "\n",
        "clean_rows = evaluate_models_on_df(test_df, attack_name=\"Clean\")\n",
        "clean_df = pd.DataFrame(clean_rows)\n",
        "clean_path = os.path.join(adv_out_dir, \"clean_eval.csv\")\n",
        "clean_df.to_csv(clean_path, index=False)\n",
        "print(\"Wrote:\", clean_path)\n",
        "print(clean_df)\n"
      ],
      "metadata": {
        "id": "j0bMICr6FYvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 17: adversarial evaluation for all attacks -> adversarial_eval.csv ---\n",
        "import pandas as pd\n",
        "all_rows = []\n",
        "\n",
        "# run each registered attack on test_df\n",
        "for attack_name in ATTACKS.keys():\n",
        "    print(f\"Running attack: {attack_name}\")\n",
        "    adv_df = apply_attack_to_df(test_df, attack_name, text_col=cfg.TEXT_COL)\n",
        "    rows = evaluate_models_on_df(adv_df, attack_name=attack_name)\n",
        "    all_rows.extend(rows)\n",
        "\n",
        "adv_df_out = pd.DataFrame(all_rows)\n",
        "adv_path = os.path.join(adv_out_dir, \"adversarial_eval.csv\")\n",
        "adv_df_out.to_csv(adv_path, index=False)\n",
        "print(\"Wrote:\", adv_path)\n",
        "print(adv_df_out.head())\n"
      ],
      "metadata": {
        "id": "fnMbWEjEF0uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 18: (optional) print combined results using your function ---\n",
        "import os, pandas as pd\n",
        "\n",
        "def print_combined_results(output_dir):\n",
        "    clean_file = os.path.join(output_dir, 'clean_eval.csv')\n",
        "    adv_file   = os.path.join(output_dir, 'adversarial_eval.csv')\n",
        "    try:\n",
        "        clean_df = pd.read_csv(clean_file)\n",
        "        adv_df   = pd.read_csv(adv_file)\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}.\")\n",
        "        raise\n",
        "\n",
        "    clean_scores = clean_df.pivot(index='Model', columns='Attack', values='macro_f1').rename(columns={'Clean': 'Clean Macro F1'})\n",
        "    adv_scores   = adv_df.pivot(index='Model', columns='Attack', values='macro_f1')\n",
        "    combined = pd.concat([clean_scores, adv_scores], axis=1)\n",
        "\n",
        "    for attack in adv_scores.columns:\n",
        "        combined[f'Drop from {attack}'] = combined['Clean Macro F1'] - combined[attack]\n",
        "\n",
        "    sorted_cols = (\n",
        "        ['Clean Macro F1'] +\n",
        "        [c for c in combined.columns if isinstance(c, str) and c.startswith('Drop')] +\n",
        "        [c for c in combined.columns if c not in ['Clean Macro F1'] and not (isinstance(c, str) and c.startswith('Drop'))]\n",
        "    )\n",
        "    combined = combined[sorted_cols]\n",
        "    print(\"\\n--- Combined Model Performance and Robustness (Macro F1) ---\")\n",
        "    print(combined.round(4).to_string())\n",
        "\n",
        "print_combined_results(\"/content/drive/MyDrive/emc/adv_eval_outputs\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LX9288faI8Zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 19: domain-cue attack helpers + functions ---\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "rng_dom = np.random.default_rng(424242)\n",
        "\n",
        "# Expand domain lexicons (kept small & transparent; tune as needed)\n",
        "STD_PREFIXES = r\"(?:ISO|IEC|EN|ASTM|ANSI|IEEE|ASME|DIN|UL|EASA|FAA|NIST|OSHA|EPA|DOE|NASA)\"\n",
        "STD_WORDS = [\n",
        "    \"standard\", \"standards\", \"specification\", \"specifications\", \"compliance\",\n",
        "    \"regulation\", \"regulations\", \"requirement\", \"requirements\", \"certification\",\n",
        "    \"qualification\", \"directive\", \"guideline\", \"guidelines\"\n",
        "]\n",
        "SAFETY_WORDS = [\n",
        "    \"safety\", \"hazard\", \"hazards\", \"warning\", \"warnings\", \"risk\", \"risks\",\n",
        "    \"caution\", \"danger\", \"emergency\", \"fail-safe\", \"failsafe\", \"fault tolerance\",\n",
        "    \"redundancy\", \"interlock\", \"lockout\", \"tagout\"\n",
        "]\n",
        "\n",
        "# Units (common engineering units)\n",
        "UNIT_LIST = [\n",
        "    \"kg\",\"g\",\"mg\",\"lb\",\"N\",\"kN\",\"MN\",\"Pa\",\"kPa\",\"MPa\",\"GPa\",\"psi\",\"bar\",\n",
        "    \"m\",\"mm\",\"cm\",\"km\",\"in\",\"ft\",\n",
        "    \"°C\",\"°F\",\"K\",\"J\",\"kJ\",\"MJ\",\"W\",\"kW\",\"MW\",\"V\",\"kV\",\"A\",\"mA\",\n",
        "    \"Hz\",\"kHz\",\"MHz\",\"GHz\",\"s\",\"ms\",\"μs\",\"ns\",\"ohm\",\"Ω\",\"rpm\"\n",
        "]\n",
        "# Regexes\n",
        "RE_STD_NUMBER = re.compile(rf\"\\b{STD_PREFIXES}\\s*[\\d]{{2,5}}(?:[-:]\\d+)*\\b\", re.I)    # e.g., ISO 26262-6:2018\n",
        "RE_ACRONYM    = re.compile(rf\"\\b(?:{STD_PREFIXES})\\b\", re.I)                            # e.g., FAA, NIST, ISO\n",
        "RE_UNIT       = re.compile(r\"\\b(\" + \"|\".join(map(re.escape, UNIT_LIST)) + r\")\\b\", re.I)\n",
        "RE_CIT_BRACK  = re.compile(r\"\\[\\s*\\d+\\s*\\]\")                                            # [12]\n",
        "RE_CIT_YEAR   = re.compile(r\"\\((?:[A-Z][A-Za-z\\.\\-]+(?:\\s+[A-Z][A-Za-z\\.\\-]+)*)\\s+((19|20)\\d{2})\\)\")  # (Hartzell 2021)\n",
        "RE_WORD       = re.compile(r\"\\b\\w+\\b\")\n",
        "\n",
        "def _preserve_case(src: str, repl: str) -> str:\n",
        "    return repl.upper() if src.isupper() else (repl.capitalize() if src[0].isupper() else repl.lower())\n",
        "\n",
        "# Keyword sets for quick matching\n",
        "STD_WORDS_SET    = set(w.lower() for w in STD_WORDS)\n",
        "SAFETY_WORDS_SET = set(w.lower() for w in SAFETY_WORDS)\n",
        "\n",
        "# 1) Mask domain terms (standards/safety/common domain nouns)\n",
        "def attack_mask_domain_terms(text: str, mask_token=\"[TERM]\") -> str:\n",
        "    if not text: return text\n",
        "    def repl_word(m):\n",
        "        w = m.group(0)\n",
        "        wl = w.lower()\n",
        "        if wl in STD_WORDS_SET or wl in SAFETY_WORDS_SET:\n",
        "            return mask_token\n",
        "        return w\n",
        "    # mask standalone words\n",
        "    t = RE_WORD.sub(repl_word, text)\n",
        "    # mask complete \"ISO 26262-6:2018\" style mentions\n",
        "    t = RE_STD_NUMBER.sub(mask_token, t)\n",
        "    return t\n",
        "\n",
        "# 2) Drop domain terms entirely\n",
        "def attack_drop_domain_terms(text: str) -> str:\n",
        "    if not text: return text\n",
        "    t = RE_STD_NUMBER.sub(\"\", text)\n",
        "    def repl_word(m):\n",
        "        w = m.group(0)\n",
        "        if w.lower() in STD_WORDS_SET or w.lower() in SAFETY_WORDS_SET:\n",
        "            return \"\"\n",
        "        return w\n",
        "    t = RE_WORD.sub(repl_word, t)\n",
        "    # collapse multiple spaces\n",
        "    t = re.sub(r\"\\s{2,}\", \" \", t).strip()\n",
        "    return t\n",
        "\n",
        "# 3) Swap domain terms with generic synonyms (reduce salience)\n",
        "DOMAIN_SYNONYMS = {\n",
        "    # safety-ish\n",
        "    \"safety\": \"protection\",\n",
        "    \"hazard\": \"threat\",\n",
        "    \"hazards\": \"threats\",\n",
        "    \"warning\": \"notice\",\n",
        "    \"warnings\": \"notices\",\n",
        "    \"risk\": \"chance\",\n",
        "    \"risks\": \"chances\",\n",
        "    \"caution\": \"care\",\n",
        "    \"danger\": \"peril\",\n",
        "    \"emergency\": \"crisis\",\n",
        "    \"fail-safe\": \"fallback\",\n",
        "    \"failsafe\": \"fallback\",\n",
        "    \"redundancy\": \"backup\",\n",
        "    \"interlock\": \"block\",\n",
        "    # standards-ish\n",
        "    \"standard\": \"document\",\n",
        "    \"standards\": \"documents\",\n",
        "    \"specification\": \"description\",\n",
        "    \"specifications\": \"descriptions\",\n",
        "    \"compliance\": \"conformance\",\n",
        "    \"regulation\": \"rule\",\n",
        "    \"regulations\": \"rules\",\n",
        "    \"requirement\": \"condition\",\n",
        "    \"requirements\": \"conditions\",\n",
        "    \"certification\": \"approval\",\n",
        "    \"qualification\": \"approval\",\n",
        "    \"directive\": \"instruction\",\n",
        "    \"guideline\": \"recommendation\",\n",
        "    \"guidelines\": \"recommendations\",\n",
        "}\n",
        "def attack_synonym_swap_domain(text: str, p=1.0) -> str:\n",
        "    if not text: return text\n",
        "    def repl_word(m):\n",
        "        w = m.group(0)\n",
        "        wl = w.lower()\n",
        "        if wl in DOMAIN_SYNONYMS and rng_dom.random() < p:\n",
        "            return _preserve_case(w, DOMAIN_SYNONYMS[wl])\n",
        "        return w\n",
        "    t = RE_WORD.sub(repl_word, text)\n",
        "    # Also neuter full standard refs to generic \"doc\"\n",
        "    t = RE_STD_NUMBER.sub(\"doc\", t)\n",
        "    return t\n",
        "\n",
        "# 4) Corrupt standard numbers slightly (keep prefix, tweak digits)\n",
        "def _tweak_digits(s: str) -> str:\n",
        "    def tweak_digit(d):\n",
        "        nd = (int(d) + rng_dom.integers(1, 9)) % 10\n",
        "        return str(nd)\n",
        "    return re.sub(r\"\\d\", lambda m: tweak_digit(m.group(0)), s, count=rng_dom.integers(1, 3))  # tweak 1–2 digits\n",
        "\n",
        "def attack_standard_number_corrupt(text: str) -> str:\n",
        "    if not text: return text\n",
        "    def repl(m):\n",
        "        s = m.group(0)\n",
        "        # split prefix and the rest so we keep \"ISO\" etc.\n",
        "        parts = re.split(r\"(\\s+)\", s, maxsplit=1)\n",
        "        if len(parts) >= 3:\n",
        "            prefix, sp, rest = parts[0], parts[1], parts[2]\n",
        "            return prefix + sp + _tweak_digits(rest)\n",
        "        return _tweak_digits(s)\n",
        "    return RE_STD_NUMBER.sub(repl, text)\n",
        "\n",
        "# 5) Neutralize units to generic token or corrupt them\n",
        "def attack_unit_neutralize(text: str, mode=\"mask\"):  # mode: mask|drop|generic\n",
        "    if not text: return text\n",
        "    if mode == \"drop\":\n",
        "        return RE_UNIT.sub(\"\", text)\n",
        "    elif mode == \"generic\":\n",
        "        return RE_UNIT.sub(\" unit \", text)\n",
        "    else:  # mask\n",
        "        return RE_UNIT.sub(\"[u]\", text)\n",
        "\n",
        "# 6) Acronym split/perturb (FAA -> F.A.A. or F A A or faA)\n",
        "def attack_acronym_perturb(text: str) -> str:\n",
        "    if not text: return text\n",
        "    def repl(m):\n",
        "        s = m.group(0)\n",
        "        forms = [ \".\".join(list(s)) + \".\", \" \".join(list(s)), s.lower(), s.capitalize() ]\n",
        "        return rng_dom.choice(forms)\n",
        "    return RE_ACRONYM.sub(repl, text)\n",
        "\n",
        "# 7) Strip citations ( [12] and (Surname 2021) patterns )\n",
        "def attack_citation_strip(text: str) -> str:\n",
        "    if not text: return text\n",
        "    t = RE_CIT_BRACK.sub(\"\", text)\n",
        "    t = RE_CIT_YEAR.sub(\"\", t)\n",
        "    # collapse extra spaces\n",
        "    t = re.sub(r\"\\s{2,}\", \" \", t).strip()\n",
        "    return t\n",
        "\n",
        "# 8) Engineering symbol normalization (remove or ascii-fy)\n",
        "SYMBOL_MAP = {\n",
        "    \"°\": \" deg \", \"±\": \"+/-\", \"μ\": \"u\", \"Ω\": \"ohm\", \"×\": \"x\", \"·\": \".\", \"≈\": \"~\",\n",
        "    \"≤\": \"<=\", \"≥\": \">=\", \"∑\": \"sum\", \"∏\": \"prod\", \"∂\": \"d\", \"∞\": \"inf\"\n",
        "}\n",
        "def attack_symbol_ascii(text: str) -> str:\n",
        "    if not text: return text\n",
        "    return \"\".join(SYMBOL_MAP.get(ch, ch) for ch in text)\n",
        "\n",
        "# Utility: row-level coverage (did anything change?)\n",
        "def coverage_rate(df_before, df_after, text_col=\"content\") -> float:\n",
        "    before = df_before[text_col].astype(str).tolist()\n",
        "    after  = df_after[text_col].astype(str).tolist()\n",
        "    changed = sum(1 for b,a in zip(before, after) if b != a)\n",
        "    return changed / max(1, len(before))\n"
      ],
      "metadata": {
        "id": "yGW-p6OxKJeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 20: extend ATTACKS registry + define pipelines ---\n",
        "try:\n",
        "    ATTACKS\n",
        "except NameError:\n",
        "    ATTACKS = {}\n",
        "\n",
        "ATTACKS.update({\n",
        "    \"MaskDomainTerms\":      attack_mask_domain_terms,\n",
        "    \"DropDomainTerms\":      attack_drop_domain_terms,\n",
        "    \"SynonymSwapDomain\":    attack_synonym_swap_domain,\n",
        "    \"StandardNumCorrupt\":   attack_standard_number_corrupt,\n",
        "    \"UnitNeutralizeMask\":   lambda t: attack_unit_neutralize(t, mode=\"mask\"),\n",
        "    \"UnitNeutralizeDrop\":   lambda t: attack_unit_neutralize(t, mode=\"drop\"),\n",
        "    \"UnitNeutralizeGeneric\":lambda t: attack_unit_neutralize(t, mode=\"generic\"),\n",
        "    \"AcronymPerturb\":       attack_acronym_perturb,\n",
        "    \"CitationStrip\":        attack_citation_strip,\n",
        "    \"SymbolAscii\":          attack_symbol_ascii,\n",
        "})\n",
        "\n",
        "DOMAIN_ATTACKS = [\n",
        "    \"MaskDomainTerms\", \"DropDomainTerms\", \"SynonymSwapDomain\",\n",
        "    \"StandardNumCorrupt\", \"UnitNeutralizeMask\", \"UnitNeutralizeDrop\",\n",
        "    \"UnitNeutralizeGeneric\", \"AcronymPerturb\", \"CitationStrip\", \"SymbolAscii\"\n",
        "]\n",
        "\n",
        "# Composed pipelines for stronger stress\n",
        "PIPELINES = {\n",
        "    \"DomainCombo1\": [\"MaskDomainTerms\", \"StandardNumCorrupt\", \"UnitNeutralizeMask\"],\n",
        "    \"DomainCombo2\": [\"SynonymSwapDomain\", \"AcronymPerturb\", \"CitationStrip\"],\n",
        "    \"DomainCombo3\": [\"DropDomainTerms\", \"SymbolAscii\", \"UnitNeutralizeGeneric\"],\n",
        "    \"DomainMax\":    [\"DropDomainTerms\", \"StandardNumCorrupt\", \"UnitNeutralizeDrop\", \"AcronymPerturb\", \"CitationStrip\", \"SymbolAscii\"],\n",
        "}\n",
        "\n",
        "def apply_attack_to_df(df, attack_name: str, text_col=\"content\"):\n",
        "    if attack_name not in ATTACKS:\n",
        "        raise ValueError(f\"Unknown attack: {attack_name}\")\n",
        "    f = ATTACKS[attack_name]\n",
        "    out = df.copy()\n",
        "    out[text_col] = [f(str(t)) for t in df[text_col].tolist()]\n",
        "    return out\n",
        "\n",
        "def apply_pipeline_to_df(df, pipeline_name: str, text_col=\"content\"):\n",
        "    if pipeline_name not in PIPELINES:\n",
        "        raise ValueError(f\"Unknown pipeline: {pipeline_name}\")\n",
        "    out = df.copy()\n",
        "    for step in PIPELINES[pipeline_name]:\n",
        "        out[text_col] = [ATTACKS[step](t) for t in out[text_col].tolist()]\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "kQo4zjLsKQHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 21: run individual domain attacks with coverage, save results ---\n",
        "import os, pandas as pd\n",
        "\n",
        "adv_out_dir = \"/content/drive/MyDrive/emc/adv_eval_outputs\"\n",
        "os.makedirs(adv_out_dir, exist_ok=True)\n",
        "\n",
        "domain_rows = []\n",
        "coverage_rows = []\n",
        "\n",
        "for attack_name in DOMAIN_ATTACKS:\n",
        "    print(f\"[Domain Attack] {attack_name}\")\n",
        "    adv_df = apply_attack_to_df(test_df, attack_name, text_col=cfg.TEXT_COL)\n",
        "    cov = coverage_rate(test_df, adv_df, text_col=cfg.TEXT_COL)\n",
        "    coverage_rows.append({\"Attack\": attack_name, \"Coverage\": cov})\n",
        "    # evaluate on adversarial df\n",
        "    rows = evaluate_models_on_df(adv_df, attack_name=attack_name)\n",
        "    domain_rows.extend(rows)\n",
        "\n",
        "# Save per-attack results\n",
        "adv_domain_df = pd.DataFrame(domain_rows)\n",
        "adv_domain_path = os.path.join(adv_out_dir, \"adversarial_eval_domain.csv\")\n",
        "adv_domain_df.to_csv(adv_domain_path, index=False)\n",
        "print(\"Wrote:\", adv_domain_path)\n",
        "\n",
        "# Save coverage stats\n",
        "coverage_df = pd.DataFrame(coverage_rows).sort_values(\"Attack\")\n",
        "coverage_path = os.path.join(adv_out_dir, \"adversarial_attack_coverage_domain.csv\")\n",
        "coverage_df.to_csv(coverage_path, index=False)\n",
        "print(\"Wrote:\", coverage_path)\n",
        "\n",
        "print(\"\\nCoverage preview:\")\n",
        "print(coverage_df.round(4).to_string(index=False))\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fstEnHfmKVSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 22: run composed pipelines (stronger stress), save results ---\n",
        "import os, pandas as pd\n",
        "\n",
        "adv_out_dir = \"/content/drive/MyDrive/emc/adv_eval_outputs\"\n",
        "combo_rows = []\n",
        "combo_cov_rows = []\n",
        "\n",
        "for pname in PIPELINES.keys():\n",
        "    print(f\"[Domain Pipeline] {pname}\")\n",
        "    adv_df = apply_pipeline_to_df(test_df, pname, text_col=cfg.TEXT_COL)\n",
        "    cov = coverage_rate(test_df, adv_df, text_col=cfg.TEXT_COL)\n",
        "    combo_cov_rows.append({\"Attack\": pname, \"Coverage\": cov})\n",
        "    rows = evaluate_models_on_df(adv_df, attack_name=pname)\n",
        "    combo_rows.extend(rows)\n",
        "\n",
        "adv_combo_df = pd.DataFrame(combo_rows)\n",
        "adv_combo_path = os.path.join(adv_out_dir, \"adversarial_eval_domain_combos.csv\")\n",
        "adv_combo_df.to_csv(adv_combo_path, index=False)\n",
        "print(\"Wrote:\", adv_combo_path)\n",
        "\n",
        "combo_cov_df = pd.DataFrame(combo_cov_rows).sort_values(\"Attack\")\n",
        "combo_cov_path = os.path.join(adv_out_dir, \"adversarial_attack_coverage_domain_combos.csv\")\n",
        "combo_cov_df.to_csv(combo_cov_path, index=False)\n",
        "print(\"Wrote:\", combo_cov_path)\n",
        "\n",
        "print(\"\\nPipeline coverage preview:\")\n",
        "print(combo_cov_df.round(4).to_string(index=False))\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-CsxO5tcODIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 23: combine Clean vs ALL attacks and compute drops ---\n",
        "import os, glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "ADV_OUT_DIR = \"/content/drive/MyDrive/emc/adv_eval_outputs\"\n",
        "\n",
        "def _safe_read_csv(path):\n",
        "    try:\n",
        "        return pd.read_csv(path)\n",
        "    except Exception as e:\n",
        "        print(f\"Skip {os.path.basename(path)}: {e}\")\n",
        "        return None\n",
        "\n",
        "def _prep_clean_df(df):\n",
        "    # Expect columns: Model, Attack='Clean', macro_f1, accuracy\n",
        "    need = {\"Model\", \"Attack\", \"macro_f1\", \"accuracy\"}\n",
        "    missing = need - set(df.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"clean_eval.csv missing columns: {missing}\")\n",
        "    clean_only = df[df[\"Attack\"].astype(str).str.lower() == \"clean\"].copy()\n",
        "    return clean_only\n",
        "\n",
        "def _gather_all_attacks(dirpath: str) -> pd.DataFrame:\n",
        "    # auto-discover all adversarial_eval*.csv except clean_eval.csv\n",
        "    paths = sorted(glob.glob(os.path.join(dirpath, \"adversarial_eval*.csv\")))\n",
        "    paths = [p for p in paths if not p.endswith(\"clean_eval.csv\")]\n",
        "    frames = []\n",
        "    for p in paths:\n",
        "        df = _safe_read_csv(p)\n",
        "        if df is None:\n",
        "            continue\n",
        "        need = {\"Model\", \"Attack\", \"macro_f1\", \"accuracy\"}\n",
        "        if not need.issubset(df.columns):\n",
        "            print(f\"Skip {os.path.basename(p)} (missing columns).\")\n",
        "            continue\n",
        "        # filter out accidental 'Clean' rows (shouldn't be here, but safe)\n",
        "        df = df[df[\"Attack\"].astype(str).str.lower() != \"clean\"].copy()\n",
        "        if len(df):\n",
        "            frames.append(df)\n",
        "    if not frames:\n",
        "        raise RuntimeError(\"No adversarial_eval*.csv files found.\")\n",
        "    return pd.concat(frames, ignore_index=True)\n",
        "\n",
        "def _make_drop_tables(clean_df: pd.DataFrame, adv_df: pd.DataFrame):\n",
        "    # Baselines per model\n",
        "    clean_macro = clean_df.pivot(index=\"Model\", columns=\"Attack\", values=\"macro_f1\")\n",
        "    if \"Clean\" not in clean_macro.columns:\n",
        "        # normalize name\n",
        "        clean_macro.columns = [\"Clean\" if str(c).lower()==\"clean\" else c for c in clean_macro.columns]\n",
        "    clean_macro = clean_macro.rename(columns={\"Clean\":\"Clean Macro F1\"})[[\"Clean Macro F1\"]]\n",
        "\n",
        "    clean_acc = clean_df.pivot(index=\"Model\", columns=\"Attack\", values=\"accuracy\")\n",
        "    if \"Clean\" not in clean_acc.columns:\n",
        "        clean_acc.columns = [\"Clean\" if str(c).lower()==\"clean\" else c for c in clean_acc.columns]\n",
        "    clean_acc = clean_acc.rename(columns={\"Clean\":\"Clean Accuracy\"})[[\"Clean Accuracy\"]]\n",
        "\n",
        "    # Adversarial (all attacks gathered)\n",
        "    adv_macro = adv_df.pivot_table(index=\"Model\", columns=\"Attack\", values=\"macro_f1\", aggfunc=\"mean\")\n",
        "    adv_acc   = adv_df.pivot_table(index=\"Model\", columns=\"Attack\", values=\"accuracy\", aggfunc=\"mean\")\n",
        "\n",
        "    # Combine baseline + adv, compute drops\n",
        "    macro_tbl = clean_macro.join(adv_macro, how=\"outer\")\n",
        "    acc_tbl   = clean_acc.join(adv_acc,   how=\"outer\")\n",
        "\n",
        "    # Compute drops = Clean - Attack\n",
        "    macro_drop_cols = []\n",
        "    for atk in adv_macro.columns:\n",
        "        col = f\"Drop: {atk}\"\n",
        "        macro_tbl[col] = macro_tbl[\"Clean Macro F1\"] - macro_tbl[atk]\n",
        "        macro_drop_cols.append(col)\n",
        "\n",
        "    acc_drop_cols = []\n",
        "    for atk in adv_acc.columns:\n",
        "        col = f\"DropAcc: {atk}\"\n",
        "        acc_tbl[col] = acc_tbl[\"Clean Accuracy\"] - acc_tbl[atk]\n",
        "        acc_drop_cols.append(col)\n",
        "\n",
        "    # Order: baseline, all drop cols (alpha), then attack scores\n",
        "    macro_cols = [\"Clean Macro F1\"] + sorted(macro_drop_cols) + list(adv_macro.columns)\n",
        "    acc_cols   = [\"Clean Accuracy\"] + sorted(acc_drop_cols) + list(adv_acc.columns)\n",
        "\n",
        "    macro_tbl = macro_tbl.reindex(columns=macro_cols)\n",
        "    acc_tbl   = acc_tbl.reindex(columns=acc_cols)\n",
        "\n",
        "    return macro_tbl.sort_index(), acc_tbl.sort_index()\n",
        "\n",
        "def build_and_save_drop_tables(out_dir=ADV_OUT_DIR):\n",
        "    clean_path = os.path.join(out_dir, \"clean_eval.csv\")\n",
        "    if not os.path.exists(clean_path):\n",
        "        raise FileNotFoundError(f\"Missing clean_eval.csv in {out_dir}\")\n",
        "    clean_df = _prep_clean_df(pd.read_csv(clean_path))\n",
        "    adv_df   = _gather_all_attacks(out_dir)\n",
        "\n",
        "    macro_tbl, acc_tbl = _make_drop_tables(clean_df, adv_df)\n",
        "\n",
        "    # Save\n",
        "    macro_out = os.path.join(out_dir, \"combined_drops_macro_f1.csv\")\n",
        "    acc_out   = os.path.join(out_dir, \"combined_drops_accuracy.csv\")\n",
        "    macro_tbl.to_csv(macro_out)\n",
        "    acc_tbl.to_csv(acc_out)\n",
        "\n",
        "    # Long format for ad-hoc plotting\n",
        "    macro_long = adv_df.merge(\n",
        "        clean_df[[\"Model\",\"macro_f1\"]].rename(columns={\"macro_f1\":\"clean_macro_f1\"}),\n",
        "        on=\"Model\", how=\"left\"\n",
        "    )\n",
        "    macro_long[\"drop_macro_f1\"] = macro_long[\"clean_macro_f1\"] - macro_long[\"macro_f1\"]\n",
        "    macro_long_out = os.path.join(out_dir, \"long_drops_macro_f1.csv\")\n",
        "    macro_long.to_csv(macro_long_out, index=False)\n",
        "\n",
        "    print(\"Wrote:\")\n",
        "    print(\" \", macro_out)\n",
        "    print(\" \", acc_out)\n",
        "    print(\" \", macro_long_out)\n",
        "    print(\"\\n--- Combined Drops (Macro F1) preview ---\")\n",
        "    print(macro_tbl.round(4).to_string())\n",
        "    return macro_tbl, acc_tbl, macro_long\n",
        "\n",
        "macro_tbl, acc_tbl, macro_long = build_and_save_drop_tables(ADV_OUT_DIR)\n"
      ],
      "metadata": {
        "id": "QJDKuJokQNla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 24: summarize worst-case & average drops per model ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "ADV_OUT_DIR = \"/content/drive/MyDrive/emc/adv_eval_outputs\"\n",
        "macro_tbl = pd.read_csv(os.path.join(ADV_OUT_DIR, \"combined_drops_macro_f1.csv\"), index_col=0)\n",
        "\n",
        "# Extract drop columns (they start with \"Drop: \")\n",
        "drop_cols = [c for c in macro_tbl.columns if c.startswith(\"Drop: \")]\n",
        "if not drop_cols:\n",
        "    raise RuntimeError(\"No drop columns found in combined_drops_macro_f1.csv\")\n",
        "\n",
        "# Worst (max) drop and the attack causing it\n",
        "worst_attack = macro_tbl[drop_cols].idxmax(axis=1).rename(\"Worst Attack\")\n",
        "worst_drop   = macro_tbl[drop_cols].max(axis=1).rename(\"Worst Drop (Macro F1)\")\n",
        "\n",
        "# Average drop across attacks\n",
        "avg_drop = macro_tbl[drop_cols].mean(axis=1).rename(\"Avg Drop (Macro F1)\")\n",
        "\n",
        "summary = pd.concat([worst_attack, worst_drop, avg_drop], axis=1).sort_values(\"Worst Drop (Macro F1)\", ascending=False)\n",
        "print(\"\\n--- Per-Model Drop Summary (Macro F1) ---\")\n",
        "print(summary.round(4).to_string())\n",
        "\n",
        "# Save summary\n",
        "summary_out = os.path.join(ADV_OUT_DIR, \"summary_drops_macro_f1.csv\")\n",
        "summary.to_csv(summary_out)\n",
        "print(\"\\nWrote:\", summary_out)\n"
      ],
      "metadata": {
        "id": "IQQ0IXsbQhty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 25: optional matplotlib visuals ---\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ADV_OUT_DIR = \"/content/drive/MyDrive/emc/adv_eval_outputs\"\n",
        "macro_tbl = pd.read_csv(os.path.join(ADV_OUT_DIR, \"combined_drops_macro_f1.csv\"), index_col=0)\n",
        "drop_cols = [c for c in macro_tbl.columns if c.startswith(\"Drop: \")]\n",
        "\n",
        "# Heatmap-style plot (matplotlib only)\n",
        "plt.figure(figsize=(max(8, len(drop_cols)*0.5), 0.6*len(macro_tbl)))\n",
        "im = plt.imshow(macro_tbl[drop_cols].values, aspect=\"auto\")\n",
        "plt.colorbar(im, fraction=0.022, pad=0.02)\n",
        "plt.xticks(ticks=np.arange(len(drop_cols)), labels=[c.replace(\"Drop: \",\"\") for c in drop_cols], rotation=90)\n",
        "plt.yticks(ticks=np.arange(len(macro_tbl.index)), labels=macro_tbl.index)\n",
        "plt.title(\"Drop (Clean Macro F1 - Attack Macro F1)\")\n",
        "plt.tight_layout()\n",
        "heatmap_path = os.path.join(ADV_OUT_DIR, \"drops_heatmap_macro_f1.png\")\n",
        "plt.savefig(heatmap_path, dpi=200)\n",
        "plt.show()\n",
        "print(\"Saved:\", heatmap_path)\n",
        "\n",
        "# Per-model top-5 worst attacks bar chart(s)\n",
        "for model, row in macro_tbl.iterrows():\n",
        "    drops = row[drop_cols].sort_values(ascending=False).head(5)\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.bar(drops.index.str.replace(\"Drop: \",\"\", regex=False), drops.values)\n",
        "    plt.ylabel(\"Drop (Macro F1)\")\n",
        "    plt.title(f\"Worst 5 Attacks — {model}\")\n",
        "    plt.xticks(rotation=30, ha=\"right\")\n",
        "    plt.tight_layout()\n",
        "    outp = os.path.join(ADV_OUT_DIR, f\"{model.replace(' ','_')}_worst5_drops.png\")\n",
        "    plt.savefig(outp, dpi=200)\n",
        "    plt.show()\n",
        "    print(\"Saved:\", outp)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fA6_3tH1Qp3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 26: Build clean long table (Macro-F1) for manuscript ---\n",
        "import os, glob, re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "ADV_OUT_DIR = \"/content/drive/MyDrive/emc/adv_eval_outputs\"\n",
        "OUT_DIR     = os.path.join(ADV_OUT_DIR, \"manuscript_tables\")\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "def _safe_read_csv(path):\n",
        "    try:\n",
        "        return pd.read_csv(path)\n",
        "    except Exception as e:\n",
        "        print(f\"Skip {os.path.basename(path)}: {e}\")\n",
        "        return None\n",
        "\n",
        "def _prettify_attack(name: str) -> str:\n",
        "    mapping = {\n",
        "        \"CharSwap\":\"Character Swap\",\n",
        "        \"DropVowels\":\"Drop Vowels\",\n",
        "        \"PunctInsert\":\"Punctuation Insert\",\n",
        "        \"WhitespaceNoise\":\"Whitespace Noise\",\n",
        "        \"CaseToggle\":\"Case Toggle\",\n",
        "        \"NumberPerturb\":\"Number Perturbation\",\n",
        "        \"UnicodeConfuse\":\"Unicode Confusables\",\n",
        "        \"Truncate80w\":\"Truncate (80 words)\",\n",
        "        \"MaskDomainTerms\":\"Mask Domain Terms\",\n",
        "        \"DropDomainTerms\":\"Drop Domain Terms\",\n",
        "        \"SynonymSwapDomain\":\"Synonym Swap (Domain)\",\n",
        "        \"StandardNumCorrupt\":\"Corrupt Standard Number\",\n",
        "        \"UnitNeutralizeMask\":\"Unit Neutralize (Mask)\",\n",
        "        \"UnitNeutralizeDrop\":\"Unit Neutralize (Drop)\",\n",
        "        \"UnitNeutralizeGeneric\":\"Unit Neutralize (Generic)\",\n",
        "        \"AcronymPerturb\":\"Acronym Perturbation\",\n",
        "        \"CitationStrip\":\"Strip Citations\",\n",
        "        \"SymbolAscii\":\"Normalize Symbols\",\n",
        "        \"DomainCombo1\":\"Domain Combo 1\",\n",
        "        \"DomainCombo2\":\"Domain Combo 2\",\n",
        "        \"DomainCombo3\":\"Domain Combo 3\",\n",
        "        \"DomainMax\":\"Domain Combo (Max)\",\n",
        "        \"Clean\":\"Clean\"\n",
        "    }\n",
        "    if name in mapping:\n",
        "        return mapping[name]\n",
        "    # fallback: split CamelCase → words\n",
        "    pretty = re.sub(r'(?<!^)(?=[A-Z])', ' ', str(name)).strip()\n",
        "    pretty = pretty.replace(\"_\", \" \")\n",
        "    return pretty\n",
        "\n",
        "def _collect_clean_df(dirpath: str) -> pd.DataFrame:\n",
        "    p = os.path.join(dirpath, \"clean_eval.csv\")\n",
        "    if not os.path.exists(p):\n",
        "        raise FileNotFoundError(f\"Missing clean_eval.csv in {dirpath}\")\n",
        "    df = pd.read_csv(p)\n",
        "    need = {\"Model\",\"Attack\",\"macro_f1\",\"accuracy\"}\n",
        "    if not need.issubset(df.columns):\n",
        "        raise ValueError(f\"clean_eval.csv missing columns {need - set(df.columns)}\")\n",
        "    # keep only the 'Clean' rows (robust to case)\n",
        "    df = df[df[\"Attack\"].astype(str).str.lower()==\"clean\"].copy()\n",
        "    df = df.rename(columns={\"macro_f1\":\"clean_macro_f1\", \"accuracy\":\"clean_accuracy\"})\n",
        "    df[\"Attack\"] = \"Clean\"\n",
        "    return df[[\"Model\",\"Attack\",\"clean_macro_f1\",\"clean_accuracy\"]]\n",
        "\n",
        "def _collect_adv_long(dirpath: str) -> pd.DataFrame:\n",
        "    paths = sorted(glob.glob(os.path.join(dirpath, \"adversarial_eval*.csv\")))\n",
        "    paths = [p for p in paths if not p.endswith(\"clean_eval.csv\")]\n",
        "    frames = []\n",
        "    for p in paths:\n",
        "        df = _safe_read_csv(p)\n",
        "        if df is None:\n",
        "            continue\n",
        "        need = {\"Model\",\"Attack\",\"macro_f1\",\"accuracy\"}\n",
        "        if not need.issubset(df.columns):\n",
        "            continue\n",
        "        df = df[df[\"Attack\"].astype(str).str.lower()!=\"clean\"].copy()\n",
        "        if len(df):\n",
        "            frames.append(df[[\"Model\",\"Attack\",\"macro_f1\",\"accuracy\"]])\n",
        "    if not frames:\n",
        "        raise RuntimeError(\"No adversarial_eval*.csv files found.\")\n",
        "    adv = pd.concat(frames, ignore_index=True)\n",
        "    return adv\n",
        "\n",
        "def _collect_coverage(dirpath: str) -> pd.DataFrame:\n",
        "    # optional\n",
        "    cov_paths = [\n",
        "        os.path.join(dirpath, \"adversarial_attack_coverage_domain.csv\"),\n",
        "        os.path.join(dirpath, \"adversarial_attack_coverage_domain_combos.csv\")\n",
        "    ]\n",
        "    frames = []\n",
        "    for p in cov_paths:\n",
        "        if os.path.exists(p):\n",
        "            df = _safe_read_csv(p)\n",
        "            if df is not None and {\"Attack\",\"Coverage\"}.issubset(df.columns):\n",
        "                frames.append(df[[\"Attack\",\"Coverage\"]])\n",
        "    if frames:\n",
        "        cov = pd.concat(frames, ignore_index=True)\n",
        "        # if duplicates (same name from multiple files), average\n",
        "        cov = cov.groupby(\"Attack\", as_index=False)[\"Coverage\"].mean()\n",
        "        return cov\n",
        "    return pd.DataFrame(columns=[\"Attack\",\"Coverage\"])\n",
        "\n",
        "def build_long_macro_table(dirpath=ADV_OUT_DIR, round_digits=3, order=\"by_drop_mean\"):\n",
        "    clean = _collect_clean_df(dirpath)\n",
        "    adv   = _collect_adv_long(dirpath)\n",
        "    cov   = _collect_coverage(dirpath)  # optional\n",
        "\n",
        "    # merge clean baseline onto adv to compute drops\n",
        "    merged = adv.merge(clean[[\"Model\",\"clean_macro_f1\"]], on=\"Model\", how=\"left\")\n",
        "    merged[\"Delta\"]  = merged[\"clean_macro_f1\"] - merged[\"macro_f1\"]\n",
        "    merged[\"Delta%\"] = 100.0 * merged[\"Delta\"] / merged[\"clean_macro_f1\"].replace(0.0, np.nan)\n",
        "\n",
        "    # pretty names\n",
        "    merged[\"Attack Pretty\"] = merged[\"Attack\"].map(_prettify_attack)\n",
        "\n",
        "    # optional coverage\n",
        "    if len(cov):\n",
        "        merged = merged.merge(cov, left_on=\"Attack\", right_on=\"Attack\", how=\"left\")\n",
        "    else:\n",
        "        merged[\"Coverage\"] = np.nan\n",
        "\n",
        "    # column order\n",
        "    cols = [\"Model\", \"Attack Pretty\", \"clean_macro_f1\", \"macro_f1\", \"Delta\", \"Delta%\", \"Coverage\"]\n",
        "    out  = merged[cols].rename(columns={\n",
        "        \"Attack Pretty\":\"Attack\",\n",
        "        \"clean_macro_f1\":\"Clean Macro F1\",\n",
        "        \"macro_f1\":\"Attack Macro F1\",\n",
        "    })\n",
        "\n",
        "    # ordering\n",
        "    if order == \"by_drop_mean\":\n",
        "        # sort attacks by mean drop across models (descending), and within each model by drop\n",
        "        attack_order = out.groupby(\"Attack\")[\"Delta\"].mean().sort_values(ascending=False).index.tolist()\n",
        "        out[\"Attack\"] = pd.Categorical(out[\"Attack\"], categories=attack_order, ordered=True)\n",
        "        out = out.sort_values([\"Model\",\"Attack\",\"Delta\"], ascending=[True, True, False])\n",
        "    elif order == \"alphabetical\":\n",
        "        out = out.sort_values([\"Model\",\"Attack\"])\n",
        "    else:\n",
        "        # as-is\n",
        "        pass\n",
        "\n",
        "    # rounding\n",
        "    out[\"Clean Macro F1\"]   = out[\"Clean Macro F1\"].round(round_digits)\n",
        "    out[\"Attack Macro F1\"]  = out[\"Attack Macro F1\"].round(round_digits)\n",
        "    out[\"Delta\"]            = out[\"Delta\"].round(round_digits)\n",
        "    out[\"Delta%\"]           = out[\"Delta%\"].round(1)\n",
        "    if out[\"Coverage\"].notna().any():\n",
        "        out[\"Coverage\"] = (100.0 * out[\"Coverage\"]).round(1)\n",
        "\n",
        "    return out\n",
        "\n",
        "manu_long = build_long_macro_table(ADV_OUT_DIR, round_digits=3, order=\"by_drop_mean\")\n",
        "print(\"Preview (first 10 rows):\")\n",
        "print(manu_long.head(10).to_string(index=False))\n"
      ],
      "metadata": {
        "id": "cFurxbwzR8hP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 27: Export CSV, Markdown, LaTeX (booktabs) ---\n",
        "import os\n",
        "\n",
        "csv_path = os.path.join(OUT_DIR, \"manuscript_table_macro_f1.csv\")\n",
        "md_path  = os.path.join(OUT_DIR, \"manuscript_table_macro_f1.md\")\n",
        "tex_path = os.path.join(OUT_DIR, \"manuscript_table_macro_f1.tex\")\n",
        "\n",
        "manu_long.to_csv(csv_path, index=False)\n",
        "\n",
        "# Markdown (simple, readable)\n",
        "with open(md_path, \"w\") as f:\n",
        "    f.write(manu_long.to_markdown(index=False))\n",
        "\n",
        "# LaTeX table with booktabs; keep ASCII for Δ (%) symbols via column names\n",
        "# (You can add \\% in the LaTeX header for percent symbol.)\n",
        "latex_tbl = manu_long.rename(columns={\n",
        "    \"Clean Macro F1\": \"Clean~F1\",\n",
        "    \"Attack Macro F1\": \"Attack~F1\",\n",
        "    \"Delta\": r\"$\\Delta$~F1\",\n",
        "    \"Delta%\": r\"$\\Delta$~(\\%)\",\n",
        "    \"Coverage\": \"Cov.~(\\%)\"\n",
        "}).to_latex(\n",
        "    index=False,\n",
        "    escape=True,\n",
        "    longtable=False,\n",
        "    bold_rows=False,\n",
        "    column_format=\"llrrrrr\",\n",
        "    na_rep=\"--\",\n",
        "    float_format=\"%.3f\".__mod__,\n",
        "    caption=\"Clean vs. Adversarial Macro-F1 per model and attack.\",\n",
        "    label=\"tab:robustness_macroF1\",\n",
        "    buf=None,\n",
        "    multicolumn=False,\n",
        "    multicolumn_format=\"c\",\n",
        "    header=True\n",
        ")\n",
        "\n",
        "with open(tex_path, \"w\") as f:\n",
        "    f.write(\"% Requires \\\\usepackage{booktabs}\\n\")\n",
        "    f.write(latex_tbl)\n",
        "\n",
        "print(\"Wrote:\")\n",
        "print(\" \", csv_path)\n",
        "print(\" \", md_path)\n",
        "print(\" \", tex_path)\n"
      ],
      "metadata": {
        "id": "LchKIsAHSVAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 28: Per-model Top-K compact tables (Markdown + LaTeX) ---\n",
        "TOPK = 8  # attacks per model to keep\n",
        "per_model_dir = os.path.join(OUT_DIR, \"per_model\")\n",
        "os.makedirs(per_model_dir, exist_ok=True)\n",
        "\n",
        "for model, dfm in manu_long.groupby(\"Model\", as_index=False):\n",
        "    df_sorted = dfm.sort_values(\"Delta\", ascending=False).head(TOPK)\n",
        "    csv_p = os.path.join(per_model_dir, f\"{model.replace(' ','_')}_top{TOPK}_macro_f1.csv\")\n",
        "    md_p  = os.path.join(per_model_dir, f\"{model.replace(' ','_')}_top{TOPK}_macro_f1.md\")\n",
        "    tex_p = os.path.join(per_model_dir, f\"{model.replace(' ','_')}_top{TOPK}_macro_f1.tex\")\n",
        "\n",
        "    df_sorted.to_csv(csv_p, index=False)\n",
        "    with open(md_p, \"w\") as f:\n",
        "        f.write(df_sorted.to_markdown(index=False))\n",
        "\n",
        "    latex_tbl = df_sorted.rename(columns={\n",
        "        \"Clean Macro F1\": \"Clean~F1\",\n",
        "        \"Attack Macro F1\": \"Attack~F1\",\n",
        "        \"Delta\": r\"$\\Delta$~F1\",\n",
        "        \"Delta%\": r\"$\\Delta$~(\\%)\",\n",
        "        \"Coverage\": \"Cov.~(\\%)\"\n",
        "    }).to_latex(\n",
        "        index=False, escape=True, longtable=False, column_format=\"llrrrrr\",\n",
        "        na_rep=\"--\", float_format=\"%.3f\".__mod__,\n",
        "        caption=f\"Top-{TOPK} robustness drops for {model}.\",\n",
        "        label=f\"tab:robustness_{model.replace(' ','_').lower()}\",\n",
        "        multicolumn=False, multicolumn_format=\"c\", header=True\n",
        "    )\n",
        "    with open(tex_p, \"w\") as f:\n",
        "        f.write(\"% Requires \\\\usepackage{booktabs}\\n\")\n",
        "        f.write(latex_tbl)\n",
        "\n",
        "print(\"Per-model tables written to:\", per_model_dir)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7JrapNZaSZvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 29: Define attack groups (5–10 buckets) ---\n",
        "\n",
        "# Tweak names or grouping as you like. Only attacks found in your CSVs will be used.\n",
        "ATTACK_GROUPS = {\n",
        "    # Generic noise / typos\n",
        "    \"CharSwap\":              \"Typos & Casing\",\n",
        "    \"DropVowels\":            \"Typos & Casing\",\n",
        "    \"CaseToggle\":            \"Typos & Casing\",\n",
        "\n",
        "    \"PunctInsert\":           \"Punct/Whitespace Noise\",\n",
        "    \"WhitespaceNoise\":       \"Punct/Whitespace Noise\",\n",
        "\n",
        "    \"UnicodeConfuse\":        \"Unicode & Symbols\",\n",
        "    \"SymbolAscii\":           \"Unicode & Symbols\",\n",
        "\n",
        "    \"NumberPerturb\":         \"Numbers\",\n",
        "    \"Truncate80w\":           \"Truncation\",\n",
        "\n",
        "    # Domain-targeted\n",
        "    \"MaskDomainTerms\":       \"Domain Terms\",\n",
        "    \"DropDomainTerms\":       \"Domain Terms\",\n",
        "    \"SynonymSwapDomain\":     \"Domain Terms\",\n",
        "\n",
        "    \"StandardNumCorrupt\":    \"Standards Corruption\",\n",
        "\n",
        "    \"UnitNeutralizeMask\":    \"Units Neutralization\",\n",
        "    \"UnitNeutralizeDrop\":    \"Units Neutralization\",\n",
        "    \"UnitNeutralizeGeneric\": \"Units Neutralization\",\n",
        "\n",
        "    \"AcronymPerturb\":        \"Acronyms & Citations\",\n",
        "    \"CitationStrip\":         \"Acronyms & Citations\",\n",
        "\n",
        "    # Combo pipelines (optional — keep or drop)\n",
        "    \"DomainCombo1\":          \"Domain Combos\",\n",
        "    \"DomainCombo2\":          \"Domain Combos\",\n",
        "    \"DomainCombo3\":          \"Domain Combos\",\n",
        "    \"DomainMax\":             \"Domain Combos\",\n",
        "}\n",
        "\n",
        "# If you want to reduce to <= 8 groups, keep only these:\n",
        "KEEP_GROUPS = [\n",
        "    \"Typos & Casing\",\n",
        "    \"Punct/Whitespace Noise\",\n",
        "    \"Unicode & Symbols\",\n",
        "    \"Numbers\",\n",
        "    \"Truncation\",\n",
        "    \"Domain Terms\",\n",
        "    \"Standards Corruption\",\n",
        "    \"Units Neutralization\",\n",
        "    # \"Acronyms & Citations\",  # uncomment to include\n",
        "    # \"Domain Combos\",         # uncomment to include\n",
        "]\n"
      ],
      "metadata": {
        "id": "yn7cP1YiTLgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 30: Build grouped Clean vs Attack Macro-F1 table ---\n",
        "import os, glob, pandas as pd, numpy as np\n",
        "\n",
        "ADV_OUT_DIR = \"/content/drive/MyDrive/emc/adv_eval_outputs\"\n",
        "OUT_DIR     = os.path.join(ADV_OUT_DIR, \"manuscript_tables\")\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "AGGREGATOR = \"mean\"   # choose: \"mean\", \"median\", or \"worst\" (worst = lowest F1)\n",
        "\n",
        "def _safe_read_csv(p):\n",
        "    try:\n",
        "        return pd.read_csv(p)\n",
        "    except Exception as e:\n",
        "        print(f\"Skip {os.path.basename(p)}: {e}\")\n",
        "        return None\n",
        "\n",
        "def _load_clean(dirpath):\n",
        "    p = os.path.join(dirpath, \"clean_eval.csv\")\n",
        "    df = pd.read_csv(p)\n",
        "    df = df[df[\"Attack\"].astype(str).str.lower()==\"clean\"].copy()\n",
        "    df = df.rename(columns={\"macro_f1\":\"Clean Macro F1\"})\n",
        "    return df[[\"Model\",\"Clean Macro F1\"]]\n",
        "\n",
        "def _load_all_attacks(dirpath):\n",
        "    paths = sorted(glob.glob(os.path.join(dirpath, \"adversarial_eval*.csv\")))\n",
        "    paths = [p for p in paths if not p.endswith(\"clean_eval.csv\")]\n",
        "    frames = []\n",
        "    for p in paths:\n",
        "        df = _safe_read_csv(p)\n",
        "        if df is None: continue\n",
        "        need = {\"Model\",\"Attack\",\"macro_f1\"}\n",
        "        if not need.issubset(df.columns):\n",
        "            print(f\"Missing columns in {os.path.basename(p)}; skipping.\")\n",
        "            continue\n",
        "        frames.append(df[[\"Model\",\"Attack\",\"macro_f1\"]])\n",
        "    if not frames:\n",
        "        raise RuntimeError(\"No adversarial_eval*.csv found.\")\n",
        "    adv = pd.concat(frames, ignore_index=True)\n",
        "    # keep only attacks we know how to group\n",
        "    adv = adv[adv[\"Attack\"].isin(ATTACK_GROUPS.keys())].copy()\n",
        "    # map to group\n",
        "    adv[\"Group\"] = adv[\"Attack\"].map(ATTACK_GROUPS)\n",
        "    if 'KEEP_GROUPS' in globals() and KEEP_GROUPS:\n",
        "        adv = adv[adv[\"Group\"].isin(KEEP_GROUPS)].copy()\n",
        "    return adv\n",
        "\n",
        "def _aggregate_group(adv_long, how=\"mean\"):\n",
        "    # adv_long: Model, Attack, macro_f1, Group\n",
        "    if how == \"mean\":\n",
        "        agg = adv_long.groupby([\"Model\",\"Group\"], as_index=False)[\"macro_f1\"].mean()\n",
        "    elif how == \"median\":\n",
        "        agg = adv_long.groupby([\"Model\",\"Group\"], as_index=False)[\"macro_f1\"].median()\n",
        "    elif how == \"worst\":\n",
        "        # worst-case = minimum F1 within the group\n",
        "        agg = adv_long.groupby([\"Model\",\"Group\"], as_index=False)[\"macro_f1\"].min()\n",
        "    else:\n",
        "        raise ValueError(\"AGGREGATOR must be one of {'mean','median','worst'}\")\n",
        "    agg = agg.rename(columns={\"macro_f1\":\"Attack Macro F1\"})\n",
        "    return agg\n",
        "\n",
        "def build_grouped_table(dirpath=ADV_OUT_DIR, how=AGGREGATOR, round_digits=3):\n",
        "    clean = _load_clean(dirpath)\n",
        "    adv   = _load_all_attacks(dirpath)\n",
        "    if adv.empty:\n",
        "        raise RuntimeError(\"No adversarial rows remain after filtering to known attacks.\")\n",
        "    agg = _aggregate_group(adv, how=how)\n",
        "\n",
        "    # merge clean baseline, compute deltas\n",
        "    out = agg.merge(clean, on=\"Model\", how=\"left\")\n",
        "    out[\"Δ\"]   = out[\"Clean Macro F1\"] - out[\"Attack Macro F1\"]\n",
        "    out[\"Δ%\"]  = 100.0 * out[\"Δ\"] / out[\"Clean Macro F1\"].replace(0.0, np.nan)\n",
        "\n",
        "    # pretty order: sort groups by avg drop across models desc\n",
        "    grp_order = out.groupby(\"Group\")[\"Δ\"].mean().sort_values(ascending=False).index.tolist()\n",
        "    out[\"Group\"] = pd.Categorical(out[\"Group\"], categories=grp_order, ordered=True)\n",
        "    out = out.sort_values([\"Group\",\"Model\"]).reset_index(drop=True)\n",
        "\n",
        "    # rounding\n",
        "    out[\"Clean Macro F1\"]  = out[\"Clean Macro F1\"].round(round_digits)\n",
        "    out[\"Attack Macro F1\"] = out[\"Attack Macro F1\"].round(round_digits)\n",
        "    out[\"Δ\"]               = out[\"Δ\"].round(round_digits)\n",
        "    out[\"Δ%\"]              = out[\"Δ%\"].round(1)\n",
        "\n",
        "    return out, adv\n",
        "\n",
        "grouped_tbl, adv_long_used = build_grouped_table(ADV_OUT_DIR, how=AGGREGATOR, round_digits=3)\n",
        "print(\"Grouped table preview:\")\n",
        "print(grouped_tbl.head(10).to_string(index=False))\n",
        "print(\"\\nGroups included:\", sorted(grouped_tbl['Group'].unique().tolist()))\n"
      ],
      "metadata": {
        "id": "-os0Qm13TPsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 31: Export grouped table in CSV/Markdown/LaTeX ---\n",
        "import os\n",
        "\n",
        "# filenames reflect the aggregator used\n",
        "suffix = {\"mean\":\"avg\", \"median\":\"median\", \"worst\":\"worst\"}[AGGREGATOR]\n",
        "base = f\"manuscript_grouped_macro_f1_{suffix}\"\n",
        "\n",
        "csv_path = os.path.join(OUT_DIR, base + \".csv\")\n",
        "md_path  = os.path.join(OUT_DIR, base + \".md\")\n",
        "tex_path = os.path.join(OUT_DIR, base + \".tex\")\n",
        "\n",
        "grouped_tbl.to_csv(csv_path, index=False)\n",
        "\n",
        "# Markdown\n",
        "with open(md_path, \"w\") as f:\n",
        "    f.write(grouped_tbl.rename(columns={\"Group\":\"Attack Group\", \"Δ\":\"Delta\", \"Δ%\":\"Delta%\"}).to_markdown(index=False))\n",
        "\n",
        "# LaTeX (booktabs)\n",
        "latex_tbl = grouped_tbl.rename(columns={\n",
        "    \"Group\": \"Attack Group\",\n",
        "    \"Clean Macro F1\": \"Clean~F1\",\n",
        "    \"Attack Macro F1\": \"Group~F1\",\n",
        "    \"Δ\": r\"$\\Delta$~F1\",\n",
        "    \"Δ%\": r\"$\\Delta$~(\\%)\",\n",
        "}).to_latex(\n",
        "    index=False, escape=True, longtable=False, column_format=\"l l r r r r\",\n",
        "    na_rep=\"--\", float_format=\"%.3f\".__mod__,\n",
        "    caption=f\"Clean vs. grouped adversarial Macro-F1 (aggregator = {AGGREGATOR}).\",\n",
        "    label=f\"tab:grouped_macroF1_{suffix}\",\n",
        "    multicolumn=False, multicolumn_format=\"c\", header=True\n",
        ")\n",
        "\n",
        "with open(tex_path, \"w\") as f:\n",
        "    f.write(\"% Requires \\\\usepackage{booktabs}\\n\")\n",
        "    f.write(latex_tbl)\n",
        "\n",
        "print(\"Wrote:\")\n",
        "print(\" \", csv_path)\n",
        "print(\" \", md_path)\n",
        "print(\" \", tex_path)\n"
      ],
      "metadata": {
        "id": "t9-kEFjaUIaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 32: UMAP for XGBoost features (blue=label 0, red=label 1), 600 dpi ---\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "\n",
        "# 1) Ensure umap-learn is available\n",
        "try:\n",
        "    import umap\n",
        "except ModuleNotFoundError:\n",
        "    import sys, subprocess\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"umap-learn\"])\n",
        "    import umap\n",
        "\n",
        "# 2) Make sure we have cfg + test_df + feature extractor and scaler\n",
        "try:\n",
        "    cfg\n",
        "except NameError:\n",
        "    from dataclasses import dataclass\n",
        "    @dataclass\n",
        "    class _TmpCfg:\n",
        "        BASE_DIR: str = \"/content/drive/MyDrive/emc\"\n",
        "        CLEAN_TEST_CSV: str = \"/content/drive/MyDrive/emc/test.csv\"\n",
        "        TERMS_CSV: str = \"/content/drive/MyDrive/emc/engineering_terms.csv\"\n",
        "        XGB_OUTPUTS: str = \"/content/drive/MyDrive/emc/xgb_outputs_clean\"\n",
        "        TEXT_COL: str = \"content\"\n",
        "        LABEL_COL: str = \"label\"\n",
        "        LANG_COL: str = \"lang\"\n",
        "    cfg = _TmpCfg()\n",
        "\n",
        "# Attempt to reuse existing test_df, else load it\n",
        "try:\n",
        "    test_df\n",
        "except NameError:\n",
        "    test_df = pd.read_csv(cfg.CLEAN_TEST_CSV)\n",
        "\n",
        "# Ensure feature extractor exists (from earlier blocks) or re-create\n",
        "try:\n",
        "    fe\n",
        "    lex\n",
        "except NameError:\n",
        "    # Minimal redefinitions to rebuild features\n",
        "    import re\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    _WORD_RE = re.compile(r\"\\w+\", re.UNICODE)\n",
        "    _NUM_RE  = re.compile(r'[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?')\n",
        "\n",
        "    def simple_words(t: str): return _WORD_RE.findall(t or \"\")\n",
        "    def sent_count(t: str) -> int:\n",
        "        if not t: return 0\n",
        "        import re as _re\n",
        "        return max(1, len(_re.split(r'[.!?]+[\\s\\n]+', t)))\n",
        "    def punct_count(t: str) -> int: return sum(1 for ch in (t or \"\") if ch in \".,;:!?\")\n",
        "    def extract_numbers(text: str):\n",
        "        nums, dec = [], 0\n",
        "        for m in _NUM_RE.finditer(text or \"\"):\n",
        "            s = m.group(0)\n",
        "            try:\n",
        "                v = float(s)\n",
        "                if ('.' in s) or ('e' in s.lower()): dec += 1\n",
        "                nums.append(abs(v))\n",
        "            except: pass\n",
        "        return nums, dec\n",
        "    def _finite_or_zero(x: float) -> float:\n",
        "        try:\n",
        "            xx = float(x)\n",
        "            return xx if np.isfinite(xx) else 0.0\n",
        "        except:\n",
        "            return 0.0\n",
        "\n",
        "    class TermsLexicon:\n",
        "        def __init__(self, csv_path: str, term_col=\"terms\", lang_col=\"lang\"):\n",
        "            if not os.path.exists(csv_path): raise FileNotFoundError(csv_path)\n",
        "            df = pd.read_csv(csv_path)\n",
        "            if term_col not in df.columns: raise ValueError(f\"Missing '{term_col}'\")\n",
        "            if lang_col not in df.columns: df[lang_col] = 'en'\n",
        "            self.by_lang = {\n",
        "                str(l).lower(): set(str(x).strip().lower()\n",
        "                                    for x in d[term_col].dropna().tolist() if str(x).strip())\n",
        "                for l, d in df.groupby(lang_col)\n",
        "            }\n",
        "        def pct_in_text(self, text: str, lang: str) -> float:\n",
        "            if not text: return 0.0\n",
        "            terms = self.by_lang.get((lang or \"en\").lower(), set())\n",
        "            if not terms: return 0.0\n",
        "            ws = [w.lower() for w in simple_words(text)]\n",
        "            if not ws: return 0.0\n",
        "            return sum(1 for w in ws if w in terms) / max(1, len(ws))\n",
        "\n",
        "    STD_TERMS = {\"iso\",\"asme\",\"ieee\",\"din\",\"ansi\",\"iec\",\"ul\",\"astm\",\"en\"}\n",
        "    SAFETY_TERMS = {\"safety\",\"hazard\",\"warning\",\"risk\",\"caution\",\"danger\",\"emergency\"}\n",
        "\n",
        "    class FeatureExtractor12:\n",
        "        def __init__(self, tlex: TermsLexicon): self.tlex = tlex\n",
        "        def extract_one(self, text: str, lang: str):\n",
        "            text = \"\" if text is None else str(text); lang = (lang or \"en\").lower()\n",
        "            ws = simple_words(text); n_words = len(ws)\n",
        "            chars = len(text); words = n_words; sents = sent_count(text)\n",
        "            # no textstat for brevity here\n",
        "            fre, fog = 0.0, 0.0\n",
        "            eng_pct = self.tlex.pct_in_text(text, lang)\n",
        "            punc = punct_count(text)\n",
        "            nums, dec_cnt = extract_numbers(text); nnums = len(nums)\n",
        "            avg_mag = float(np.mean(nums)) if nums else 0.0\n",
        "            dec_ratio = float(dec_cnt / max(1, len(nums)))\n",
        "            low = text.lower()\n",
        "            has_std = 1.0 if any(t in low for t in STD_TERMS) else 0.0\n",
        "            has_saf = 1.0 if any(t in low for t in SAFETY_TERMS) else 0.0\n",
        "            vals = [chars, words, sents, fre, fog, eng_pct, punc, nnums, has_std, has_saf, avg_mag, dec_ratio]\n",
        "            feats = np.asarray([_finite_or_zero(v) for v in vals], dtype=np.float64)\n",
        "            feats = np.nan_to_num(feats, nan=0.0, posinf=1e12, neginf=0.0)\n",
        "            return np.clip(feats, -1e12, 1e12).astype(np.float32)\n",
        "        def extract_df(self, df):\n",
        "            local = df if 'lang' in df.columns else df.assign(lang='en')\n",
        "            rows = [self.extract_one(r.get(\"content\",\"\"), r.get(\"lang\",\"en\")) for _, r in local.iterrows()]\n",
        "            return np.stack(rows, axis=0).astype(np.float32)\n",
        "\n",
        "    lex = TermsLexicon(cfg.TERMS_CSV)\n",
        "    fe  = FeatureExtractor12(lex)\n",
        "\n",
        "# 3) Build or reuse scaled features for TEST\n",
        "try:\n",
        "    # reuse precomputed feats_te + scaler_xgb if they exist\n",
        "    X_test_scaled = scaler_xgb.transform(feats_te)\n",
        "    y_test = test_df[cfg.LABEL_COL].astype(int).values\n",
        "except Exception:\n",
        "    # compute features and load scaler\n",
        "    X_test = fe.extract_df(test_df)\n",
        "    scaler_xgb = joblib.load(os.path.join(cfg.XGB_OUTPUTS, \"scaler12.pkl\"))\n",
        "    X_test_scaled = scaler_xgb.transform(X_test)\n",
        "    y_test = test_df[cfg.LABEL_COL].astype(int).values\n",
        "\n",
        "# 4) UMAP embedding (2D)\n",
        "umap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, metric=\"euclidean\", random_state=42)\n",
        "emb2d = umap_model.fit_transform(X_test_scaled)  # shape: (N, 2)\n",
        "\n",
        "# 5) Plot (blue=label 0, red=label 1), save 600 dpi\n",
        "out_dir = getattr(cfg, \"XGB_OUTPUTS\", \"/content\")\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "png_path = os.path.join(out_dir, \"umap_xgb_test_2d.png\")\n",
        "csv_path = os.path.join(out_dir, \"umap_xgb_test_2d.csv\")\n",
        "\n",
        "plt.figure(figsize=(7.0, 6.0))\n",
        "# build masks\n",
        "mask0 = (y_test == 0)\n",
        "mask1 = (y_test == 1)\n",
        "plt.scatter(emb2d[mask0, 0], emb2d[mask0, 1], s=10, c=\"blue\", alpha=0.8, label=\"Real 0\")\n",
        "plt.scatter(emb2d[mask1, 0], emb2d[mask1, 1], s=10, c=\"red\",  alpha=0.8, label=\"MisInformation 1\")\n",
        "\n",
        "plt.title(\"UMAP Visualization of XGBoost Engineered Features\")\n",
        "plt.xlabel(\"UMAP-1\"); plt.ylabel(\"UMAP-2\")\n",
        "plt.legend(loc=\"best\", frameon=True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(png_path, dpi=600)\n",
        "plt.show()\n",
        "\n",
        "# 6) Save coordinates to CSV (optional)\n",
        "out_df = pd.DataFrame({\n",
        "    \"umap_x\": emb2d[:, 0],\n",
        "    \"umap_y\": emb2d[:, 1],\n",
        "    \"label\": y_test\n",
        "})\n",
        "out_df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(\"Saved UMAP figure (600 dpi):\", png_path)\n",
        "print(\"Saved UMAP coordinates:\", csv_path)\n"
      ],
      "metadata": {
        "id": "JbrELIuCUZzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- UMAP for XLM-R (text-only) — blue=Real, red=Misinformation, 600 dpi ---\n",
        "\n",
        "# 0) Imports\n",
        "import os, sys, subprocess\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# tqdm fallback\n",
        "try:\n",
        "    from tqdm import tqdm\n",
        "except Exception:\n",
        "    def tqdm(x, **kwargs): return x\n",
        "\n",
        "# Ensure umap-learn is available\n",
        "try:\n",
        "    import umap\n",
        "except ModuleNotFoundError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"umap-learn\"])\n",
        "    import umap\n",
        "\n",
        "from transformers import (\n",
        "    XLMRobertaTokenizerFast,\n",
        "    XLMRobertaModel,\n",
        "    XLMRobertaForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 1) Ensure cfg exists and has required attributes (use sane defaults if missing)\n",
        "try:\n",
        "    cfg\n",
        "except NameError:\n",
        "    from dataclasses import dataclass\n",
        "    @dataclass\n",
        "    class _TmpCfg:\n",
        "        BASE_DIR: str = \"/content/drive/MyDrive/emc\"\n",
        "        CLEAN_TEST_CSV: str = \"/content/drive/MyDrive/emc/test.csv\"\n",
        "        XLM_R_OUTPUTS: str = \"/content/drive/MyDrive/emc/xlmr_only_outputs_clean\"\n",
        "        TEXT_COL: str = \"content\"\n",
        "        LABEL_COL: str = \"label\"\n",
        "        MAX_LEN: int = 256\n",
        "        BATCH_SIZE: int = 16\n",
        "        ID2LABEL: dict = {0: \"Real\", 1: \"Misinformation\"}\n",
        "    cfg = _TmpCfg()\n",
        "\n",
        "def ensure_attr(o, name, value):\n",
        "    if not hasattr(o, name) or getattr(o, name) in (None, \"\", 0):\n",
        "        setattr(o, name, value)\n",
        "\n",
        "ensure_attr(cfg, \"XLM_R_OUTPUTS\", \"/content/drive/MyDrive/emc/xlmr_only_outputs_clean\")\n",
        "ensure_attr(cfg, \"CLEAN_TEST_CSV\", \"/content/drive/MyDrive/emc/test.csv\")\n",
        "ensure_attr(cfg, \"TEXT_COL\", \"content\")\n",
        "ensure_attr(cfg, \"LABEL_COL\", \"label\")\n",
        "ensure_attr(cfg, \"MAX_LEN\", 256)\n",
        "ensure_attr(cfg, \"BATCH_SIZE\", 16)\n",
        "ensure_attr(cfg, \"ID2LABEL\", {0: \"Real\", 1: \"Misinformation\"})\n",
        "\n",
        "# 2) Load test set\n",
        "try:\n",
        "    test_df\n",
        "except NameError:\n",
        "    test_df = pd.read_csv(cfg.CLEAN_TEST_CSV)\n",
        "\n",
        "# 3) Dataset for text-only embeddings\n",
        "class TextOnlyDS(Dataset):\n",
        "    def __init__(self, df, tokenizer, text_col=\"content\", label_col=\"label\", max_len=256):\n",
        "        self.texts = df[text_col].astype(str).tolist()\n",
        "        raw = df[label_col].tolist()\n",
        "        labels = []\n",
        "        for v in raw:\n",
        "            s = str(v).strip().lower()\n",
        "            if s in (\"0\",\"1\"):\n",
        "                labels.append(int(s))\n",
        "            else:\n",
        "                labels.append(1 if s.startswith(\"mis\") else 0)\n",
        "        self.labels = np.array(labels, dtype=np.int64)\n",
        "        self.tok = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self): return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tok(\n",
        "            self.texts[idx],\n",
        "            truncation=True, padding=False, max_length=self.max_len,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "# 4) Load tokenizer + encoder (prefer your finetuned checkpoint's encoder)\n",
        "xlmr_ckpt_dir = cfg.XLM_R_OUTPUTS\n",
        "use_finetuned = os.path.isdir(xlmr_ckpt_dir) and os.path.exists(os.path.join(xlmr_ckpt_dir, \"config.json\"))\n",
        "\n",
        "if use_finetuned:\n",
        "    tokenizer = XLMRobertaTokenizerFast.from_pretrained(xlmr_ckpt_dir)\n",
        "    # load classification checkpoint, then grab the underlying encoder to avoid pooler init warnings\n",
        "    clf = XLMRobertaForSequenceClassification.from_pretrained(xlmr_ckpt_dir).to(device)\n",
        "    encoder = clf.roberta  # base encoder with your fine-tuned weights\n",
        "else:\n",
        "    tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-base\")\n",
        "    encoder = XLMRobertaModel.from_pretrained(\"xlm-roberta-base\").to(device)\n",
        "\n",
        "# 5) DataLoader\n",
        "ds = TextOnlyDS(test_df, tokenizer, text_col=cfg.TEXT_COL, label_col=cfg.LABEL_COL, max_len=cfg.MAX_LEN)\n",
        "collator = DataCollatorWithPadding(tokenizer)\n",
        "loader = DataLoader(ds, batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
        "\n",
        "# 6) Mean-pool helper\n",
        "def masked_mean_pool(last_hidden_state: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
        "    mask = attention_mask.unsqueeze(-1).float()\n",
        "    return (last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "\n",
        "# 7) Encode embeddings\n",
        "encoder.eval()\n",
        "embs, labels = [], []\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(loader, desc=\"Encoding with XLM-R\"):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attn = batch[\"attention_mask\"].to(device)\n",
        "        out = encoder(input_ids=input_ids, attention_mask=attn, return_dict=True)\n",
        "        pooled = masked_mean_pool(out.last_hidden_state, attn)  # [B, H]\n",
        "        embs.append(pooled.cpu().numpy())\n",
        "        labels.append(batch[\"labels\"].numpy())\n",
        "embs = np.vstack(embs)\n",
        "y_test = np.concatenate(labels)\n",
        "\n",
        "# 8) UMAP (cosine) to 2D\n",
        "umap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, metric=\"cosine\", random_state=42)\n",
        "emb2d = umap_model.fit_transform(embs)\n",
        "\n",
        "# 9) Plot (blue=Real, red=Misinformation) and save 600 dpi\n",
        "out_dir = xlmr_ckpt_dir if use_finetuned else \"/content\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "png_path = os.path.join(out_dir, \"umap_xlmr_text_test_2d.png\")\n",
        "csv_path = os.path.join(out_dir, \"umap_xlmr_text_test_2d.csv\")\n",
        "\n",
        "name0 = cfg.ID2LABEL.get(0, \"Real\")\n",
        "name1 = cfg.ID2LABEL.get(1, \"Misinformation\")\n",
        "\n",
        "plt.figure(figsize=(7.0, 6.0))\n",
        "mask0 = (y_test == 0)\n",
        "mask1 = (y_test == 1)\n",
        "plt.scatter(emb2d[mask0, 0], emb2d[mask0, 1], s=10, c=\"blue\", alpha=0.8, label=name0)\n",
        "plt.scatter(emb2d[mask1, 0], emb2d[mask1, 1], s=10, c=\"red\",  alpha=0.8, label=name1)\n",
        "plt.title(\"UMAP (XLM-RoBERTa Mean-Pooled Encoder States)\")\n",
        "plt.xlabel(\"UMAP-1\"); plt.ylabel(\"UMAP-2\")\n",
        "plt.legend(loc=\"best\", frameon=True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(png_path, dpi=600)\n",
        "plt.show()\n",
        "\n",
        "# 10) Save coordinates CSV\n",
        "out_df = pd.DataFrame({\n",
        "    \"umap_x\": emb2d[:, 0],\n",
        "    \"umap_y\": emb2d[:, 1],\n",
        "    \"label_id\": y_test,\n",
        "    \"label_name\": np.where(y_test == 0, name0, name1),\n",
        "})\n",
        "out_df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(\"Saved UMAP figure (600 dpi):\", png_path)\n",
        "print(\"Saved UMAP coordinates:\", csv_path)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "CRwQKJ-FgLNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- UMAP for Simple Fusion & Gated Fusion (side-by-side), blue=Real red=Misinformation, 600 dpi ---\n",
        "\n",
        "# 0) Imports\n",
        "import os, sys, subprocess\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# tqdm fallback\n",
        "try:\n",
        "    from tqdm import tqdm\n",
        "except Exception:\n",
        "    def tqdm(x, **kwargs): return x\n",
        "\n",
        "# Ensure umap-learn is available\n",
        "try:\n",
        "    import umap\n",
        "except ModuleNotFoundError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"umap-learn\"])\n",
        "    import umap\n",
        "\n",
        "# Sklearn/joblib\n",
        "try:\n",
        "    import joblib\n",
        "except ModuleNotFoundError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"joblib\"])\n",
        "    import joblib\n",
        "\n",
        "from transformers import XLMRobertaTokenizerFast, XLMRobertaModel, DataCollatorWithPadding\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 1) Ensure cfg with required attributes (defaults if missing)\n",
        "try:\n",
        "    cfg\n",
        "except NameError:\n",
        "    from dataclasses import dataclass\n",
        "    @dataclass\n",
        "    class _TmpCfg:\n",
        "        BASE_DIR: str = \"/content/drive/MyDrive/emc\"\n",
        "        CLEAN_TEST_CSV: str = \"/content/drive/MyDrive/emc/test.csv\"\n",
        "        TERMS_CSV: str = \"/content/drive/MyDrive/emc/engineering_terms.csv\"\n",
        "        SIMPLE_OUTPUTS: str = \"/content/drive/MyDrive/emc/simple_fusion_outputs_clean\"\n",
        "        GATED_OUTPUTS: str = \"/content/drive/MyDrive/emc/gated_fusion_outputs_clean\"\n",
        "        TEXT_COL: str = \"content\"\n",
        "        LABEL_COL: str = \"label\"\n",
        "        LANG_COL: str = \"lang\"\n",
        "        MAX_LEN: int = 256\n",
        "        BATCH_SIZE: int = 16\n",
        "        ID2LABEL: dict = {0: \"Real\", 1: \"Misinformation\"}\n",
        "    cfg = _TmpCfg()\n",
        "\n",
        "def ensure_attr(o, name, value):\n",
        "    if not hasattr(o, name) or getattr(o, name) in (None, \"\", 0):\n",
        "        setattr(o, name, value)\n",
        "\n",
        "ensure_attr(cfg, \"SIMPLE_OUTPUTS\", \"/content/drive/MyDrive/emc/simple_fusion_outputs_clean\")\n",
        "ensure_attr(cfg, \"GATED_OUTPUTS\",  \"/content/drive/MyDrive/emc/gated_fusion_outputs_clean\")\n",
        "ensure_attr(cfg, \"TERMS_CSV\",      \"/content/drive/MyDrive/emc/engineering_terms.csv\")\n",
        "ensure_attr(cfg, \"CLEAN_TEST_CSV\", \"/content/drive/MyDrive/emc/test.csv\")\n",
        "ensure_attr(cfg, \"TEXT_COL\", \"content\")\n",
        "ensure_attr(cfg, \"LABEL_COL\", \"label\")\n",
        "ensure_attr(cfg, \"MAX_LEN\", 256)\n",
        "ensure_attr(cfg, \"BATCH_SIZE\", 16)\n",
        "ensure_attr(cfg, \"ID2LABEL\", {0: \"Real\", 1: \"Misinformation\"})\n",
        "\n",
        "# 2) Load test set\n",
        "try:\n",
        "    test_df\n",
        "except NameError:\n",
        "    test_df = pd.read_csv(cfg.CLEAN_TEST_CSV)\n",
        "\n",
        "# 3) Minimal feature extractor (12D) to rebuild raw features\n",
        "import re\n",
        "_WORD_RE = re.compile(r\"\\w+\", re.UNICODE)\n",
        "_NUM_RE  = re.compile(r'[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?')\n",
        "STD_TERMS = {\"iso\",\"asme\",\"ieee\",\"din\",\"ansi\",\"iec\",\"ul\",\"astm\",\"en\"}\n",
        "SAFETY_TERMS = {\"safety\",\"hazard\",\"warning\",\"risk\",\"caution\",\"danger\",\"emergency\"}\n",
        "\n",
        "def simple_words(t: str): return _WORD_RE.findall(t or \"\")\n",
        "def sent_count(t: str) -> int:\n",
        "    if not t: return 0\n",
        "    return max(1, len(re.split(r'[.!?]+[\\s\\n]+', t)))\n",
        "def punct_count(t: str) -> int: return sum(1 for ch in (t or \"\") if ch in \".,;:!?\")\n",
        "def extract_numbers(text: str):\n",
        "    nums, dec = [], 0\n",
        "    for m in _NUM_RE.finditer(text or \"\"):\n",
        "        s = m.group(0)\n",
        "        try:\n",
        "            v = float(s)\n",
        "            if ('.' in s) or ('e' in s.lower()): dec += 1\n",
        "            nums.append(abs(v))\n",
        "        except: pass\n",
        "    return nums, dec\n",
        "def _finite_or_zero(x: float):\n",
        "    try:\n",
        "        xx = float(x);\n",
        "        return xx if np.isfinite(xx) else 0.0\n",
        "    except: return 0.0\n",
        "\n",
        "class TermsLexicon:\n",
        "    def __init__(self, csv_path: str, term_col=\"terms\", lang_col=\"lang\"):\n",
        "        if not os.path.exists(csv_path): raise FileNotFoundError(csv_path)\n",
        "        df = pd.read_csv(csv_path)\n",
        "        if term_col not in df.columns: raise ValueError(f\"Missing '{term_col}'\")\n",
        "        if lang_col not in df.columns: df[lang_col] = 'en'\n",
        "        self.by_lang = {\n",
        "            str(l).lower(): set(str(x).strip().lower() for x in d[term_col].dropna().tolist() if str(x).strip())\n",
        "            for l, d in df.groupby(lang_col)\n",
        "        }\n",
        "    def pct_in_text(self, text: str, lang: str) -> float:\n",
        "        if not text: return 0.0\n",
        "        terms = self.by_lang.get((lang or \"en\").lower(), set())\n",
        "        if not terms: return 0.0\n",
        "        ws = [w.lower() for w in simple_words(text)]\n",
        "        if not ws: return 0.0\n",
        "        return sum(1 for w in ws if w in terms) / max(1, len(ws))\n",
        "\n",
        "class FeatureExtractor12:\n",
        "    def __init__(self, tlex: TermsLexicon): self.tlex = tlex\n",
        "    def extract_one(self, text: str, lang: str):\n",
        "        text = \"\" if text is None else str(text); lang = (lang or \"en\").lower()\n",
        "        ws = simple_words(text); n_words = len(ws)\n",
        "        chars = len(text); words = n_words; sents = sent_count(text)\n",
        "        fre, fog = 0.0, 0.0  # omit textstat for portability\n",
        "        eng_pct = self.tlex.pct_in_text(text, lang)\n",
        "        punc = punct_count(text)\n",
        "        nums, dec_cnt = extract_numbers(text); nnums = len(nums)\n",
        "        avg_mag = float(np.mean(nums)) if nums else 0.0\n",
        "        dec_ratio = float(dec_cnt / max(1, len(nums)))\n",
        "        low = text.lower()\n",
        "        has_std = 1.0 if any(t in low for t in STD_TERMS) else 0.0\n",
        "        has_saf = 1.0 if any(t in low for t in SAFETY_TERMS) else 0.0\n",
        "        vals = [chars, words, sents, fre, fog, eng_pct, punc, nnums, has_std, has_saf, avg_mag, dec_ratio]\n",
        "        feats = np.asarray([_finite_or_zero(v) for v in vals], dtype=np.float64)\n",
        "        feats = np.nan_to_num(feats, nan=0.0, posinf=1e12, neginf=0.0)\n",
        "        return np.clip(feats, -1e12, 1e12).astype(np.float32)\n",
        "    def extract_df(self, df):\n",
        "        local = df if 'lang' in df.columns else df.assign(lang='en')\n",
        "        rows = [self.extract_one(r.get(cfg.TEXT_COL,\"\"), r.get(\"lang\",\"en\")) for _, r in local.iterrows()]\n",
        "        return np.stack(rows, axis=0).astype(np.float32)\n",
        "\n",
        "lex = TermsLexicon(cfg.TERMS_CSV)\n",
        "fe  = FeatureExtractor12(lex)\n",
        "\n",
        "# 4) Tokenizer\n",
        "tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-base\")\n",
        "\n",
        "# 5) Dataset classes with scaler-applied feats\n",
        "class TextFeatDS(Dataset):\n",
        "    def __init__(self, df, tokenizer, feats_scaled, text_col=\"content\", label_col=\"label\", max_len=256):\n",
        "        self.texts = df[text_col].astype(str).tolist()\n",
        "        raw = df[label_col].tolist()\n",
        "        labels = []\n",
        "        for v in raw:\n",
        "            s = str(v).strip().lower()\n",
        "            if s in (\"0\",\"1\"): labels.append(int(s))\n",
        "            else: labels.append(1 if s.startswith(\"mis\") else 0)\n",
        "        self.labels = np.array(labels, dtype=np.int64)\n",
        "        self.tok = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.feats = feats_scaled.astype(np.float32)\n",
        "\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tok(self.texts[idx], truncation=True, padding=\"max_length\",\n",
        "                       max_length=self.max_len, return_tensors=\"pt\")\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n",
        "            \"feats\": torch.tensor(self.feats[idx], dtype=torch.float32),\n",
        "        }\n",
        "\n",
        "# 6) Model defs (same as training)\n",
        "class SimpleFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + n_feats, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (out.last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "        fused = torch.cat([pooled, feats], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "    # helper to get fused representation\n",
        "    def fused_repr(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (out.last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "        return torch.cat([pooled, feats], dim=1)\n",
        "\n",
        "class GatedFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2, feat_proj: int = 64):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.fe_proj = nn.Sequential(nn.Linear(n_feats, feat_proj), nn.ReLU())\n",
        "        self.gate    = nn.Sequential(nn.Linear(H + n_feats, 64), nn.ReLU(), nn.Linear(64, 1), nn.Sigmoid())\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + feat_proj, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (out.last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "        alpha = self.gate(torch.cat([pooled, feats], dim=1))\n",
        "        ef    = self.fe_proj(feats)\n",
        "        fused = torch.cat([pooled, alpha * ef], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "    # helper to get fused representation\n",
        "    def fused_repr(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (out.last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "        alpha = self.gate(torch.cat([pooled, feats], dim=1))\n",
        "        ef    = self.fe_proj(feats)\n",
        "        return torch.cat([pooled, alpha * ef], dim=1)\n",
        "\n",
        "# 7) Build raw features and scale with saved scalers for each model\n",
        "X_raw = fe.extract_df(test_df)\n",
        "# Simple scaler\n",
        "scaler_simple_path = os.path.join(cfg.SIMPLE_OUTPUTS, \"scaler12.pkl\")\n",
        "scaler_gated_path  = os.path.join(cfg.GATED_OUTPUTS,  \"scaler12.pkl\")\n",
        "if not os.path.exists(scaler_simple_path) or not os.path.exists(scaler_gated_path):\n",
        "    raise FileNotFoundError(\"Missing scaler12.pkl for Simple or Gated. Make sure training saved them.\")\n",
        "\n",
        "scaler_simple = joblib.load(scaler_simple_path)\n",
        "scaler_gated  = joblib.load(scaler_gated_path)\n",
        "X_simple = scaler_simple.transform(X_raw).astype(np.float32)\n",
        "X_gated  = scaler_gated.transform(X_raw).astype(np.float32)\n",
        "\n",
        "# 8) Datasets & loaders\n",
        "ds_simple = TextFeatDS(test_df, tokenizer, X_simple, text_col=cgf.TEXT_COL if 'cgf' in globals() else cfg.TEXT_COL,\n",
        "                       label_col=cfg.LABEL_COL, max_len=cfg.MAX_LEN)\n",
        "ds_gated  = TextFeatDS(test_df, tokenizer, X_gated,  text_col=cfg.TEXT_COL, label_col=cfg.LABEL_COL, max_len=cfg.MAX_LEN)\n",
        "collator  = DataCollatorWithPadding(tokenizer)\n",
        "dl_simple = DataLoader(ds_simple, batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
        "dl_gated  = DataLoader(ds_gated,  batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
        "\n",
        "# 9) Load models with fine-tuned weights\n",
        "simple_ckpt = os.path.join(cfg.SIMPLE_OUTPUTS, \"fusion_simple.pt\")\n",
        "gated_ckpt  = os.path.join(cfg.GATED_OUTPUTS,  \"fusion_gated.pt\")\n",
        "if not os.path.exists(simple_ckpt) or not os.path.exists(gated_ckpt):\n",
        "    raise FileNotFoundError(\"Missing fusion_simple.pt or fusion_gated.pt. Train the models first.\")\n",
        "\n",
        "model_simple = SimpleFusion(\"xlm-roberta-base\", n_feats=12, n_labels=2).to(device)\n",
        "model_simple.load_state_dict(torch.load(simple_ckpt, map_location=device), strict=False)\n",
        "model_simple.eval()\n",
        "\n",
        "model_gated  = GatedFusion(\"xlm-roberta-base\", n_feats=12, n_labels=2, feat_proj=64).to(device)\n",
        "model_gated.load_state_dict(torch.load(gated_ckpt, map_location=device), strict=False)\n",
        "model_gated.eval()\n",
        "\n",
        "# 10) Extract fused representations\n",
        "def collect_fused(model, loader):\n",
        "    emb, y = [], []\n",
        "    with torch.no_grad():\n",
        "        for b in tqdm(loader, desc=\"Fused repr\"):\n",
        "            ids = b[\"input_ids\"].to(device)\n",
        "            am  = b[\"attention_mask\"].to(device)\n",
        "            ft  = b[\"feats\"].to(device)\n",
        "            fused = model.fused_repr(ids, am, ft)\n",
        "            emb.append(fused.cpu().numpy())\n",
        "            y.append(b[\"labels\"].numpy())\n",
        "    return np.vstack(emb), np.concatenate(y)\n",
        "\n",
        "emb_simple, y_test = collect_fused(model_simple, dl_simple)\n",
        "emb_gated,  _      = collect_fused(model_gated,  dl_gated)\n",
        "\n",
        "# 11) UMAP (separate models)\n",
        "umap_simple = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, metric=\"cosine\", random_state=42)\n",
        "umap_gated  = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, metric=\"cosine\", random_state=42)\n",
        "um2d_simple = umap_simple.fit_transform(emb_simple)\n",
        "um2d_gated  = umap_gated.fit_transform(emb_gated)\n",
        "\n",
        "# 12) Plot side-by-side, save 600 dpi\n",
        "name0 = cfg.ID2LABEL.get(0, \"Real\")\n",
        "name1 = cfg.ID2LABEL.get(1, \"Misinformation\")\n",
        "mask0 = (y_test == 0)\n",
        "mask1 = (y_test == 1)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5), constrained_layout=True)\n",
        "axes[0].scatter(um2d_simple[mask0,0], um2d_simple[mask0,1], s=10, c=\"blue\", alpha=0.8, label=name0)\n",
        "axes[0].scatter(um2d_simple[mask1,0], um2d_simple[mask1,1], s=10, c=\"red\",  alpha=0.8, label=name1)\n",
        "axes[0].set_title(\"UMAP — Simple Fusion (fused space)\")\n",
        "axes[0].set_xlabel(\"UMAP-1\"); axes[0].set_ylabel(\"UMAP-2\")\n",
        "axes[0].legend(loc=\"best\", frameon=True)\n",
        "\n",
        "axes[1].scatter(um2d_gated[mask0,0], um2d_gated[mask0,1], s=10, c=\"blue\", alpha=0.8, label=name0)\n",
        "axes[1].scatter(um2d_gated[mask1,0], um2d_gated[mask1,1], s=10, c=\"red\",  alpha=0.8, label=name1)\n",
        "axes[1].set_title(\"UMAP — Gated Fusion (fused space)\")\n",
        "axes[1].set_xlabel(\"UMAP-1\"); axes[1].set_ylabel(\"UMAP-2\")\n",
        "axes[1].legend(loc=\"best\", frameon=True)\n",
        "\n",
        "out_dir = cfg.BASE_DIR\n",
        "png_path = os.path.join(out_dir, \"umap_simple_vs_gated_fused_2d.png\")\n",
        "plt.savefig(png_path, dpi=600)\n",
        "plt.show()\n",
        "print(\"Saved side-by-side UMAP (600 dpi):\", png_path)\n",
        "\n",
        "# 13) Save coordinates CSVs\n",
        "csv_simple = os.path.join(cfg.SIMPLE_OUTPUTS, \"umap_simple_fused_2d.csv\")\n",
        "csv_gated  = os.path.join(cfg.GATED_OUTPUTS,  \"umap_gated_fused_2d.csv\")\n",
        "pd.DataFrame({\"umap_x\": um2d_simple[:,0], \"umap_y\": um2d_simple[:,1], \"label_id\": y_test,\n",
        "              \"label_name\": np.where(y_test==0, name0, name1)}).to_csv(csv_simple, index=False)\n",
        "pd.DataFrame({\"umap_x\": um2d_gated[:,0],  \"umap_y\": um2d_gated[:,1],  \"label_id\": y_test,\n",
        "              \"label_name\": np.where(y_test==0, name0, name1)}).to_csv(csv_gated, index=False)\n",
        "print(\"Saved coords:\", csv_simple)\n",
        "print(\"Saved coords:\", csv_gated)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LI87oIrJivys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 34: Permutation Importance for Gated Fusion (TEST set), 12 engineered features ---\n",
        "\n",
        "# 0) Imports\n",
        "import os, sys, subprocess, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "# tqdm fallback\n",
        "try:\n",
        "    from tqdm import tqdm\n",
        "except Exception:\n",
        "    def tqdm(x, **kwargs): return x\n",
        "\n",
        "# joblib\n",
        "try:\n",
        "    import joblib\n",
        "except ModuleNotFoundError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"joblib\"])\n",
        "    import joblib\n",
        "\n",
        "# HF\n",
        "from transformers import XLMRobertaTokenizerFast, XLMRobertaModel, DataCollatorWithPadding\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 1) Ensure cfg and required attributes\n",
        "try:\n",
        "    cfg\n",
        "except NameError:\n",
        "    from dataclasses import dataclass\n",
        "    @dataclass\n",
        "    class _TmpCfg:\n",
        "        BASE_DIR: str = \"/content/drive/MyDrive/emc\"\n",
        "        CLEAN_TEST_CSV: str = \"/content/drive/MyDrive/emc/test.csv\"\n",
        "        TERMS_CSV: str = \"/content/drive/MyDrive/emc/engineering_terms.csv\"\n",
        "        GATED_OUTPUTS: str = \"/content/drive/MyDrive/emc/gated_fusion_outputs_clean\"\n",
        "        TEXT_COL: str = \"content\"\n",
        "        LABEL_COL: str = \"label\"\n",
        "        LANG_COL: str = \"lang\"\n",
        "        MAX_LEN: int = 256\n",
        "        BATCH_SIZE: int = 16\n",
        "        N_FEATURES: int = 12\n",
        "        ID2LABEL: dict = {0: \"Real\", 1: \"Misinformation\"}\n",
        "    cfg = _TmpCfg()\n",
        "\n",
        "def ensure_attr(o, name, value):\n",
        "    if not hasattr(o, name) or getattr(o, name) in (None, \"\", 0):\n",
        "        setattr(o, name, value)\n",
        "\n",
        "ensure_attr(cfg, \"GATED_OUTPUTS\",  \"/content/drive/MyDrive/emc/gated_fusion_outputs_clean\")\n",
        "ensure_attr(cfg, \"TERMS_CSV\",      \"/content/drive/MyDrive/emc/engineering_terms.csv\")\n",
        "ensure_attr(cfg, \"CLEAN_TEST_CSV\", \"/content/drive/MyDrive/emc/test.csv\")\n",
        "ensure_attr(cfg, \"TEXT_COL\", \"content\")\n",
        "ensure_attr(cfg, \"LABEL_COL\", \"label\")\n",
        "ensure_attr(cfg, \"LANG_COL\", \"lang\")\n",
        "ensure_attr(cfg, \"MAX_LEN\", 256)\n",
        "ensure_attr(cfg, \"BATCH_SIZE\", 16)\n",
        "ensure_attr(cfg, \"N_FEATURES\", 12)\n",
        "\n",
        "# 2) Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# 3) Load TEST set\n",
        "test_df = pd.read_csv(cfg.CLEAN_TEST_CSV)\n",
        "\n",
        "# 4) Minimal 12-D feature extractor (same design as training)\n",
        "import re\n",
        "_WORD_RE = re.compile(r\"\\w+\", re.UNICODE)\n",
        "_NUM_RE  = re.compile(r'[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?')\n",
        "STD_TERMS = {\"iso\",\"asme\",\"ieee\",\"din\",\"ansi\",\"iec\",\"ul\",\"astm\",\"en\"}\n",
        "SAFETY_TERMS = {\"safety\",\"hazard\",\"warning\",\"risk\",\"caution\",\"danger\",\"emergency\"}\n",
        "\n",
        "def simple_words(t: str): return _WORD_RE.findall(t or \"\")\n",
        "def sent_count(t: str) -> int:\n",
        "    if not t: return 0\n",
        "    return max(1, len(re.split(r'[.!?]+[\\s\\n]+', t)))\n",
        "def punct_count(t: str) -> int: return sum(1 for ch in (t or \"\") if ch in \".,;:!?\")\n",
        "def extract_numbers(text: str):\n",
        "    nums, dec = [], 0\n",
        "    for m in _NUM_RE.finditer(text or \"\"):\n",
        "        s = m.group(0)\n",
        "        try:\n",
        "            v = float(s)\n",
        "            if ('.' in s) or ('e' in s.lower()): dec += 1\n",
        "            nums.append(abs(v))\n",
        "        except: pass\n",
        "    return nums, dec\n",
        "def _finite_or_zero(x: float):\n",
        "    try:\n",
        "        xx = float(x);\n",
        "        return xx if np.isfinite(xx) else 0.0\n",
        "    except: return 0.0\n",
        "\n",
        "class TermsLexicon:\n",
        "    def __init__(self, csv_path: str, term_col=\"terms\", lang_col=\"lang\"):\n",
        "        if not os.path.exists(csv_path): raise FileNotFoundError(csv_path)\n",
        "        df = pd.read_csv(csv_path)\n",
        "        if term_col not in df.columns: raise ValueError(f\"Missing '{term_col}'\")\n",
        "        if lang_col not in df.columns: df[lang_col] = 'en'\n",
        "        self.by_lang = {\n",
        "            str(l).lower(): set(str(x).strip().lower() for x in d[term_col].dropna().tolist() if str(x).strip())\n",
        "            for l, d in df.groupby(lang_col)\n",
        "        }\n",
        "    def pct_in_text(self, text: str, lang: str) -> float:\n",
        "        if not text: return 0.0\n",
        "        terms = self.by_lang.get((lang or \"en\").lower(), set())\n",
        "        if not terms: return 0.0\n",
        "        ws = [w.lower() for w in simple_words(text)]\n",
        "        if not ws: return 0.0\n",
        "        return sum(1 for w in ws if w in terms) / max(1, len(ws))\n",
        "\n",
        "class FeatureExtractor12:\n",
        "    def __init__(self, tlex: TermsLexicon): self.tlex = tlex\n",
        "    def extract_one(self, text: str, lang: str):\n",
        "        text = \"\" if text is None else str(text); lang = (lang or \"en\").lower()\n",
        "        ws = simple_words(text); n_words = len(ws)\n",
        "        chars = len(text); words = n_words; sents = sent_count(text)\n",
        "        fre, fog = 0.0, 0.0  # textstat omitted for portability\n",
        "        eng_pct = self.tlex.pct_in_text(text, lang)\n",
        "        punc = punct_count(text)\n",
        "        nums, dec_cnt = extract_numbers(text); nnums = len(nums)\n",
        "        avg_mag = float(np.mean(nums)) if nums else 0.0\n",
        "        dec_ratio = float(dec_cnt / max(1, len(nums)))\n",
        "        low = text.lower()\n",
        "        has_std = 1.0 if any(t in low for t in STD_TERMS) else 0.0\n",
        "        has_saf = 1.0 if any(t in low for t in SAFETY_TERMS) else 0.0\n",
        "        vals = [chars, words, sents, fre, fog, eng_pct, punc, nnums, has_std, has_saf, avg_mag, dec_ratio]\n",
        "        feats = np.asarray([_finite_or_zero(v) for v in vals], dtype=np.float64)\n",
        "        feats = np.nan_to_num(feats, nan=0.0, posinf=1e12, neginf=0.0)\n",
        "        return np.clip(feats, -1e12, 1e12).astype(np.float32)\n",
        "    def extract_df(self, df):\n",
        "        local = df if cfg.LANG_COL in df.columns else df.assign(**{cfg.LANG_COL:'en'})\n",
        "        rows = [self.extract_one(r.get(cfg.TEXT_COL,\"\"), r.get(cfg.LANG_COL,\"en\")) for _, r in local.iterrows()]\n",
        "        return np.stack(rows, axis=0).astype(np.float32)\n",
        "\n",
        "lex = TermsLexicon(cfg.TERMS_CSV)\n",
        "fe  = FeatureExtractor12(lex)\n",
        "\n",
        "# 5) Tokenizer (same as training backbone)\n",
        "tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-base\")\n",
        "\n",
        "# 6) Dataset class that injects (scaled) feats\n",
        "class TextFeatDS(Dataset):\n",
        "    def __init__(self, df, tokenizer, feats_scaled, text_col=\"content\", label_col=\"label\", max_len=256):\n",
        "        self.texts = df[text_col].astype(str).tolist()\n",
        "        raw = df[label_col].tolist()\n",
        "        labels = []\n",
        "        for v in raw:\n",
        "            s = str(v).strip().lower()\n",
        "            if s in (\"0\",\"1\"): labels.append(int(s))\n",
        "            else: labels.append(1 if s.startswith(\"mis\") else 0)\n",
        "        self.labels = np.array(labels, dtype=np.int64)\n",
        "        self.tok = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.feats = feats_scaled.astype(np.float32)\n",
        "\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tok(self.texts[idx], truncation=True, padding=\"max_length\",\n",
        "                       max_length=self.max_len, return_tensors=\"pt\")\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n",
        "            \"feats\": torch.tensor(self.feats[idx], dtype=torch.float32),\n",
        "        }\n",
        "\n",
        "# 7) Gated Fusion model (same as training)\n",
        "class GatedFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2, feat_proj: int = 64):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.fe_proj = nn.Sequential(nn.Linear(n_feats, feat_proj), nn.ReLU())\n",
        "        self.gate    = nn.Sequential(nn.Linear(H + n_feats, 64), nn.ReLU(), nn.Linear(64, 1), nn.Sigmoid())\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + feat_proj, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (out.last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "        alpha = self.gate(torch.cat([pooled, feats], dim=1))\n",
        "        ef    = self.fe_proj(feats)\n",
        "        fused = torch.cat([pooled, alpha * ef], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "\n",
        "# 8) Load scaler + model weights\n",
        "scaler_path = os.path.join(cfg.GATED_OUTPUTS, \"scaler12.pkl\")\n",
        "model_path  = os.path.join(cfg.GATED_OUTPUTS, \"fusion_gated.pt\")\n",
        "if not os.path.exists(scaler_path) or not os.path.exists(model_path):\n",
        "    raise FileNotFoundError(\"Missing gated scaler/model. Expected scaler12.pkl and fusion_gated.pt in GATED_OUTPUTS.\")\n",
        "\n",
        "scaler = joblib.load(scaler_path)\n",
        "model  = GatedFusion(\"xlm-roberta-base\", n_feats=cfg.N_FEATURES, n_labels=2, feat_proj=64).to(device)\n",
        "model.load_state_dict(torch.load(model_path, map_location=device), strict=False)\n",
        "model.eval()\n",
        "\n",
        "# 9) Build baseline TEST loader (tokens + scaled feats)\n",
        "X_test_raw = fe.extract_df(test_df)\n",
        "X_test_scaled = scaler.transform(X_test_raw).astype(np.float32)\n",
        "\n",
        "ds_test = TextFeatDS(test_df, tokenizer, X_test_scaled, text_col=cfg.TEXT_COL, label_col=cfg.LABEL_COL, max_len=cfg.MAX_LEN)\n",
        "collator = DataCollatorWithPadding(tokenizer)\n",
        "dl_test  = DataLoader(ds_test, batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_macro_f1(dataloader):\n",
        "    ys, ps = [], []\n",
        "    for b in dataloader:\n",
        "        ids = b[\"input_ids\"].to(device)\n",
        "        am  = b[\"attention_mask\"].to(device)\n",
        "        ft  = b[\"feats\"].to(device)\n",
        "        logits = model(ids, am, ft)\n",
        "        pred = logits.argmax(dim=-1).cpu().numpy()\n",
        "        ys.append(b[\"labels\"].numpy()); ps.append(pred)\n",
        "    y = np.concatenate(ys); p = np.concatenate(ps)\n",
        "    return f1_score(y, p, average=\"macro\", zero_division=0), accuracy_score(y, p)\n",
        "\n",
        "# 10) Baseline metric\n",
        "baseline_f1, baseline_acc = eval_macro_f1(dl_test)\n",
        "print(f\"Baseline (TEST) — Macro F1: {baseline_f1:.4f} | Acc: {baseline_acc:.4f}\")\n",
        "\n",
        "# 11) Permutation importance over 12 features (shuffle column j across samples)\n",
        "feat_names = [\n",
        "    \"Chars\", \"Words\", \"Sents\", \"Flesch RE (en)\", \"Gunning Fog (en)\",\n",
        "    \"% Eng Terms\", \"Punctuation\", \"Number Count\", \"Contains Standard\",\n",
        "    \"Contains Safety\", \"Avg Number Mag\", \"Decimal Ratio\"\n",
        "]\n",
        "\n",
        "rng = np.random.default_rng(SEED)\n",
        "drops = []\n",
        "for j in range(cfg.N_FEATURES):\n",
        "    Xp = X_test_scaled.copy()\n",
        "    rng.shuffle(Xp[:, j])  # permute column j across samples\n",
        "    ds_perm = TextFeatDS(test_df, tokenizer, Xp, text_col=cfg.TEXT_COL, label_col=cfg.LABEL_COL, max_len=cfg.MAX_LEN)\n",
        "    dl_perm = DataLoader(ds_perm, batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
        "    f1_j, _ = eval_macro_f1(dl_perm)\n",
        "    drop = baseline_f1 - f1_j\n",
        "    drops.append(drop)\n",
        "    print(f\"Feature {j:2d} ({feat_names[j]}): drop = {drop:.6f}\")\n",
        "\n",
        "imp_df = pd.DataFrame({\n",
        "    \"Feature\": feat_names[:cfg.N_FEATURES],\n",
        "    \"Drop_in_MacroF1\": drops\n",
        "}).sort_values(\"Drop_in_MacroF1\", ascending=True)\n",
        "\n",
        "# 12) Save CSV and plot (600 dpi)\n",
        "os.makedirs(cfg.GATED_OUTPUTS, exist_ok=True)\n",
        "csv_out = os.path.join(cfg.GATED_OUTPUTS, \"perm_importance_gated_test.csv\")\n",
        "png_out = os.path.join(cfg.GATED_OUTPUTS, \"perm_importance_gated_test.png\")\n",
        "imp_df.to_csv(csv_out, index=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(imp_df[\"Feature\"], imp_df[\"Drop_in_MacroF1\"])\n",
        "plt.title(\"Permutation Importance (Drop in Macro F1) — Gated Fusion\")\n",
        "plt.xlabel(\"Drop in Macro F1 (baseline − permuted)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(png_out, dpi=600)\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved CSV:\", csv_out)\n",
        "print(\"Saved plot (600 dpi):\", png_out)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "paxyqxhelLQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Combined ROC for 4 Models (XGB, XLM-R, Simple Fusion, Gated Fusion) ---\n",
        "# Saves: BASE_DIR/roc_curves_4models.png (600 dpi)\n",
        "#        BASE_DIR/roc_points_4models.csv (model,fpr,tpr,threshold)\n",
        "\n",
        "import os, sys, subprocess\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Optional progress bar\n",
        "try:\n",
        "    from tqdm import tqdm\n",
        "except Exception:\n",
        "    def tqdm(x, **kwargs): return x\n",
        "\n",
        "# Ensure xgboost & joblib\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "except ModuleNotFoundError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"xgboost\"])\n",
        "    import xgboost as xgb\n",
        "try:\n",
        "    import joblib\n",
        "except ModuleNotFoundError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"joblib\"])\n",
        "    import joblib\n",
        "\n",
        "# HF deps\n",
        "from transformers import (\n",
        "    XLMRobertaTokenizerFast,\n",
        "    XLMRobertaForSequenceClassification,\n",
        "    XLMRobertaModel,\n",
        "    DataCollatorWithPadding,\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ---------- 0) Config / defaults ----------\n",
        "try:\n",
        "    cfg\n",
        "except NameError:\n",
        "    from dataclasses import dataclass\n",
        "    @dataclass\n",
        "    class _TmpCfg:\n",
        "        BASE_DIR: str = \"/content/drive/MyDrive/emc\"\n",
        "        CLEAN_TEST_CSV: str = \"/content/drive/MyDrive/emc/test.csv\"\n",
        "        TERMS_CSV: str = \"/content/drive/MyDrive/emc/engineering_terms.csv\"\n",
        "        XGB_OUTPUTS: str = \"/content/drive/MyDrive/emc/xgb_outputs_clean\"\n",
        "        XLM_R_OUTPUTS: str = \"/content/drive/MyDrive/emc/xlmr_only_outputs_clean\"\n",
        "        SIMPLE_OUTPUTS: str = \"/content/drive/MyDrive/emc/simple_fusion_outputs_clean\"\n",
        "        GATED_OUTPUTS: str = \"/content/drive/MyDrive/emc/gated_fusion_outputs_clean\"\n",
        "        TEXT_COL: str = \"content\"\n",
        "        LABEL_COL: str = \"label\"\n",
        "        LANG_COL: str = \"lang\"\n",
        "        MAX_LEN: int = 256\n",
        "        BATCH_SIZE: int = 16\n",
        "        N_FEATURES: int = 12\n",
        "        ID2LABEL: dict = {0: \"Real\", 1: \"Misinformation\"}\n",
        "    cfg = _TmpCfg()\n",
        "\n",
        "def ensure_attr(o, name, value):\n",
        "    if not hasattr(o, name) or getattr(o, name) in (None, \"\", 0):\n",
        "        setattr(o, name, value)\n",
        "\n",
        "for k, v in dict(\n",
        "    BASE_DIR=\"/content/drive/MyDrive/emc\",\n",
        "    CLEAN_TEST_CSV=\"/content/drive/MyDrive/emc/test.csv\",\n",
        "    TERMS_CSV=\"/content/drive/MyDrive/emc/engineering_terms.csv\",\n",
        "    XGB_OUTPUTS=\"/content/drive/MyDrive/emc/xgb_outputs_clean\",\n",
        "    XLM_R_OUTPUTS=\"/content/drive/MyDrive/emc/xlmr_only_outputs_clean\",\n",
        "    SIMPLE_OUTPUTS=\"/content/drive/MyDrive/emc/simple_fusion_outputs_clean\",\n",
        "    GATED_OUTPUTS=\"/content/drive/MyDrive/emc/gated_fusion_outputs_clean\",\n",
        "    TEXT_COL=\"content\", LABEL_COL=\"label\", LANG_COL=\"lang\",\n",
        "    MAX_LEN=256, BATCH_SIZE=16, N_FEATURES=12\n",
        ").items():\n",
        "    ensure_attr(cfg, k, v)\n",
        "\n",
        "# ---------- 1) Load test set ----------\n",
        "test_df = pd.read_csv(cfg.CLEAN_TEST_CSV)\n",
        "y_true = test_df[cfg.LABEL_COL].astype(int).values\n",
        "\n",
        "# ---------- 2) Feature extractor (12D) to rebuild engineered features ----------\n",
        "import re\n",
        "_WORD_RE = re.compile(r\"\\w+\", re.UNICODE)\n",
        "_NUM_RE  = re.compile(r'[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?')\n",
        "STD_TERMS = {\"iso\",\"asme\",\"ieee\",\"din\",\"ansi\",\"iec\",\"ul\",\"astm\",\"en\"}\n",
        "SAFETY_TERMS = {\"safety\",\"hazard\",\"warning\",\"risk\",\"caution\",\"danger\",\"emergency\"}\n",
        "\n",
        "def simple_words(t: str): return _WORD_RE.findall(t or \"\")\n",
        "def sent_count(t: str) -> int:\n",
        "    if not t: return 0\n",
        "    return max(1, len(re.split(r'[.!?]+[\\s\\n]+', t)))\n",
        "def punct_count(t: str) -> int: return sum(1 for ch in (t or \"\") if ch in \".,;:!?\")\n",
        "def extract_numbers(text: str):\n",
        "    nums, dec = [], 0\n",
        "    for m in _NUM_RE.finditer(text or \"\"):\n",
        "        s = m.group(0)\n",
        "        try:\n",
        "            v = float(s)\n",
        "            if ('.' in s) or ('e' in s.lower()): dec += 1\n",
        "            nums.append(abs(v))\n",
        "        except: pass\n",
        "    return nums, dec\n",
        "def _finite_or_zero(x: float):\n",
        "    try:\n",
        "        xx = float(x);\n",
        "        return xx if np.isfinite(xx) else 0.0\n",
        "    except: return 0.0\n",
        "\n",
        "class TermsLexicon:\n",
        "    def __init__(self, csv_path: str, term_col=\"terms\", lang_col=\"lang\"):\n",
        "        if not os.path.exists(csv_path): raise FileNotFoundError(csv_path)\n",
        "        df = pd.read_csv(csv_path)\n",
        "        if term_col not in df.columns: raise ValueError(f\"Missing '{term_col}'\")\n",
        "        if lang_col not in df.columns: df[lang_col] = 'en'\n",
        "        self.by_lang = {\n",
        "            str(l).lower(): set(str(x).strip().lower() for x in d[term_col].dropna().tolist() if str(x).strip())\n",
        "            for l, d in df.groupby(lang_col)\n",
        "        }\n",
        "    def pct_in_text(self, text: str, lang: str) -> float:\n",
        "        if not text: return 0.0\n",
        "        terms = self.by_lang.get((lang or \"en\").lower(), set())\n",
        "        if not terms: return 0.0\n",
        "        ws = [w.lower() for w in simple_words(text)]\n",
        "        if not ws: return 0.0\n",
        "        return sum(1 for w in ws if w in terms) / max(1, len(ws))\n",
        "\n",
        "class FeatureExtractor12:\n",
        "    def __init__(self, tlex: TermsLexicon): self.tlex = tlex\n",
        "    def extract_one(self, text: str, lang: str):\n",
        "        text = \"\" if text is None else str(text); lang = (lang or \"en\").lower()\n",
        "        ws = simple_words(text); n_words = len(ws)\n",
        "        chars = len(text); words = n_words; sents = sent_count(text)\n",
        "        fre, fog = 0.0, 0.0  # omit textstat for portability\n",
        "        eng_pct = self.tlex.pct_in_text(text, lang)\n",
        "        punc = punct_count(text)\n",
        "        nums, dec_cnt = extract_numbers(text); nnums = len(nums)\n",
        "        avg_mag = float(np.mean(nums)) if nums else 0.0\n",
        "        dec_ratio = float(dec_cnt / max(1, len(nums)))\n",
        "        low = text.lower()\n",
        "        has_std = 1.0 if any(t in low for t in STD_TERMS) else 0.0\n",
        "        has_saf = 1.0 if any(t in low for t in SAFETY_TERMS) else 0.0\n",
        "        vals = [chars, words, sents, fre, fog, eng_pct, punc, nnums, has_std, has_saf, avg_mag, dec_ratio]\n",
        "        feats = np.asarray([_finite_or_zero(v) for v in vals], dtype=np.float64)\n",
        "        feats = np.nan_to_num(feats, nan=0.0, posinf=1e12, neginf=0.0)\n",
        "        return np.clip(feats, -1e12, 1e12).astype(np.float32)\n",
        "    def extract_df(self, df):\n",
        "        local = df if cfg.LANG_COL in df.columns else df.assign(**{cfg.LANG_COL:'en'})\n",
        "        rows = [self.extract_one(r.get(cfg.TEXT_COL,\"\"), r.get(cfg.LANG_COL,\"en\")) for _, r in local.iterrows()]\n",
        "        return np.stack(rows, axis=0).astype(np.float32)\n",
        "\n",
        "lex = TermsLexicon(cfg.TERMS_CSV)\n",
        "fe  = FeatureExtractor12(lex)\n",
        "X_raw = fe.extract_df(test_df)\n",
        "\n",
        "# ---------- 3) Tokenization datasets ----------\n",
        "class TextOnlyDS(Dataset):\n",
        "    def __init__(self, df, tokenizer, text_col=\"content\", label_col=\"label\", max_len=256):\n",
        "        self.texts = df[text_col].astype(str).tolist()\n",
        "        self.labels = df[label_col].astype(int).values\n",
        "        self.tok = tokenizer; self.max_len = max_len\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tok(self.texts[idx], truncation=True, padding=False,\n",
        "                       max_length=self.max_len, return_tensors=\"pt\")\n",
        "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
        "        item[\"labels\"] = torch.tensor(int(self.labels[idx]), dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "class TextFeatDS(Dataset):\n",
        "    def __init__(self, df, tokenizer, feats_scaled, text_col=\"content\", label_col=\"label\", max_len=256):\n",
        "        self.texts = df[text_col].astype(str).tolist()\n",
        "        self.labels = df[label_col].astype(int).values\n",
        "        self.tok = tokenizer; self.max_len = max_len\n",
        "        self.feats = feats_scaled.astype(np.float32)\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tok(self.texts[idx], truncation=True, padding=\"max_length\",\n",
        "                       max_length=self.max_len, return_tensors=\"pt\")\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(int(self.labels[idx]), dtype=torch.long),\n",
        "            \"feats\": torch.tensor(self.feats[idx], dtype=torch.float32),\n",
        "        }\n",
        "\n",
        "from transformers import DataCollatorWithPadding\n",
        "collator = DataCollatorWithPadding(XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-base\"))\n",
        "\n",
        "# ---------- 4) Model defs (Simple & Gated) ----------\n",
        "class SimpleFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + n_feats, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (out.last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "        fused = torch.cat([pooled, feats], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "\n",
        "class GatedFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2, feat_proj: int = 64):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.fe_proj = nn.Sequential(nn.Linear(n_feats, feat_proj), nn.ReLU())\n",
        "        self.gate    = nn.Sequential(nn.Linear(H + n_feats, 64), nn.ReLU(), nn.Linear(64, 1), nn.Sigmoid())\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + feat_proj, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (out.last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "        alpha = self.gate(torch.cat([pooled, feats], dim=1))\n",
        "        ef    = self.fe_proj(feats)\n",
        "        fused = torch.cat([pooled, alpha * ef], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "\n",
        "# ---------- 5) Load artifacts ----------\n",
        "# XGBoost\n",
        "xgb_model_path = os.path.join(cfg.XGB_OUTPUTS, \"xgb_model.json\")\n",
        "xgb_scaler_path = os.path.join(cfg.XGB_OUTPUTS, \"scaler12.pkl\")\n",
        "if not (os.path.exists(xgb_model_path) and os.path.exists(xgb_scaler_path)):\n",
        "    raise FileNotFoundError(\"XGBoost model/scaler not found.\")\n",
        "clf_xgb = xgb.XGBClassifier()\n",
        "clf_xgb.load_model(xgb_model_path)\n",
        "scaler_xgb = joblib.load(xgb_scaler_path)\n",
        "X_xgb = scaler_xgb.transform(X_raw)\n",
        "\n",
        "# XLM-R only\n",
        "if not os.path.exists(cfg.XLM_R_OUTPUTS):\n",
        "    raise FileNotFoundError(\"XLM-R outputs dir not found.\")\n",
        "tokenizer_xlmr = XLMRobertaTokenizerFast.from_pretrained(cfg.XLM_R_OUTPUTS)\n",
        "model_xlmr = XLMRobertaForSequenceClassification.from_pretrained(cfg.XLM_R_OUTPUTS).to(device)\n",
        "\n",
        "# Simple Fusion\n",
        "simple_ckpt = os.path.join(cfg.SIMPLE_OUTPUTS, \"fusion_simple.pt\")\n",
        "simple_scaler_path = os.path.join(cfg.SIMPLE_OUTPUTS, \"scaler12.pkl\")\n",
        "if not (os.path.exists(simple_ckpt) and os.path.exists(simple_scaler_path)):\n",
        "    raise FileNotFoundError(\"Simple Fusion checkpoint/scaler not found.\")\n",
        "scaler_simple = joblib.load(simple_scaler_path)\n",
        "X_simple = scaler_simple.transform(X_raw)\n",
        "model_simple = SimpleFusion(\"xlm-roberta-base\", n_feats=cfg.N_FEATURES, n_labels=2).to(device)\n",
        "model_simple.load_state_dict(torch.load(simple_ckpt, map_location=device), strict=False)\n",
        "model_simple.eval()\n",
        "\n",
        "# Gated Fusion\n",
        "gated_ckpt = os.path.join(cfg.GATED_OUTPUTS, \"fusion_gated.pt\")\n",
        "gated_scaler_path = os.path.join(cfg.GATED_OUTPUTS, \"scaler12.pkl\")\n",
        "if not (os.path.exists(gated_ckpt) and os.path.exists(gated_scaler_path)):\n",
        "    raise FileNotFoundError(\"Gated Fusion checkpoint/scaler not found.\")\n",
        "scaler_gated = joblib.load(gated_scaler_path)\n",
        "X_gated = scaler_gated.transform(X_raw)\n",
        "model_gated = GatedFusion(\"xlm-roberta-base\", n_feats=cfg.N_FEATURES, n_labels=2, feat_proj=64).to(device)\n",
        "model_gated.load_state_dict(torch.load(gated_ckpt, map_location=device), strict=False)\n",
        "model_gated.eval()\n",
        "\n",
        "# ---------- 6) DataLoaders ----------\n",
        "from transformers import DataCollatorWithPadding\n",
        "collator = DataCollatorWithPadding(tokenizer_xlmr)\n",
        "\n",
        "# XLM-R DS\n",
        "ds_xlmr = TextOnlyDS(test_df, tokenizer_xlmr, text_col=cfg.TEXT_COL, label_col=cfg.LABEL_COL, max_len=cfg.MAX_LEN)\n",
        "dl_xlmr = DataLoader(ds_xlmr, batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
        "\n",
        "# Simple/Gated DS\n",
        "ds_simple = TextFeatDS(test_df, tokenizer_xlmr, X_simple, text_col=cfg.TEXT_COL, label_col=cfg.LABEL_COL, max_len=cfg.MAX_LEN)\n",
        "ds_gated  = TextFeatDS(test_df, tokenizer_xlmr, X_gated,  text_col=cfg.TEXT_COL, label_col=cfg.LABEL_COL, max_len=cfg.MAX_LEN)\n",
        "dl_simple = DataLoader(ds_simple, batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
        "dl_gated  = DataLoader(ds_gated,  batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
        "\n",
        "# ---------- 7) Collect probabilities ----------\n",
        "def probs_xlmr(dataloader):\n",
        "    ps = []\n",
        "    model_xlmr.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"XLMR proba\"):\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k in (\"input_ids\",\"attention_mask\",\"labels\")}\n",
        "            out = model_xlmr(**inputs)\n",
        "            p = torch.softmax(out.logits, dim=-1)[:, 1].cpu().numpy()  # P(class=1)\n",
        "            ps.append(p)\n",
        "    return np.concatenate(ps)\n",
        "\n",
        "def probs_fusion(model, dataloader):\n",
        "    ps = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Fusion proba\"):\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            am  = batch[\"attention_mask\"].to(device)\n",
        "            ft  = batch[\"feats\"].to(device)\n",
        "            logits = model(ids, am, ft)\n",
        "            p = torch.softmax(logits, dim=-1)[:, 1].cpu().numpy()\n",
        "            ps.append(p)\n",
        "    return np.concatenate(ps)\n",
        "\n",
        "# XGBoost prob (class 1)\n",
        "yprob_xgb = clf_xgb.predict_proba(X_xgb)[:, 1]\n",
        "# XLM-R prob\n",
        "yprob_xlmr = probs_xlmr(dl_xlmr)\n",
        "# Simple/Gated prob\n",
        "yprob_simple = probs_fusion(model_simple, dl_simple)\n",
        "yprob_gated  = probs_fusion(model_gated,  dl_gated)\n",
        "\n",
        "# ---------- 8) Compute ROC + AUC ----------\n",
        "curves = {}\n",
        "for name, prob in [\n",
        "    (\"XGBoost + Features\", yprob_xgb),\n",
        "    (\"XLM-R Only\",         yprob_xlmr),\n",
        "    (\"Simple Fusion\",      yprob_simple),\n",
        "    (\"Gated Fusion\",       yprob_gated),\n",
        "]:\n",
        "    fpr, tpr, thr = roc_curve(y_true, prob)\n",
        "    auc = roc_auc_score(y_true, prob)\n",
        "    curves[name] = {\"fpr\": fpr, \"tpr\": tpr, \"thr\": thr, \"auc\": auc}\n",
        "\n",
        "# ---------- 9) Plot (different colors) & save 600 dpi ----------\n",
        "colors = {\n",
        "    \"XGBoost + Features\": \"tab:blue\",\n",
        "    \"XLM-R Only\":         \"tab:red\",\n",
        "    \"Simple Fusion\":      \"tab:green\",\n",
        "    \"Gated Fusion\":       \"tab:orange\",\n",
        "}\n",
        "plt.figure(figsize=(8, 7))\n",
        "for name, d in curves.items():\n",
        "    plt.plot(d[\"fpr\"], d[\"tpr\"], lw=2, label=f\"{name} (AUC = {d['auc']:.4f})\", color=colors.get(name, None))\n",
        "plt.plot([0,1], [0,1], ls=\"--\", color=\"gray\", lw=1)\n",
        "plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05])\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curves — 4 Models (Test Set)\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.tight_layout()\n",
        "out_png = os.path.join(cfg.BASE_DIR, \"roc_curves_4models.png\")\n",
        "plt.savefig(out_png, dpi=600)\n",
        "plt.show()\n",
        "print(\"Saved ROC figure (600 dpi):\", out_png)\n",
        "\n",
        "# ---------- 10) Save ROC points (long CSV) ----------\n",
        "rows = []\n",
        "for name, d in curves.items():\n",
        "    rows.append(pd.DataFrame({\n",
        "        \"Model\": name,\n",
        "        \"fpr\": d[\"fpr\"],\n",
        "        \"tpr\": d[\"tpr\"],\n",
        "        \"threshold\": d[\"thr\"]\n",
        "    }))\n",
        "roc_points = pd.concat(rows, ignore_index=True)\n",
        "out_csv = os.path.join(cfg.BASE_DIR, \"roc_points_4models.csv\")\n",
        "roc_points.to_csv(out_csv, index=False)\n",
        "print(\"Saved ROC points CSV:\", out_csv)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FnAeS94Mof3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Combined Precision–Recall (PR) Curves for 4 Models (Test Set) ---\n",
        "# Saves: BASE_DIR/pr_curves_4models.png  (600 dpi)\n",
        "#        BASE_DIR/pr_points_4models.csv  (Model, recall, precision, threshold)\n",
        "\n",
        "import os, sys, subprocess\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Optional progress bar\n",
        "try:\n",
        "    from tqdm import tqdm\n",
        "except Exception:\n",
        "    def tqdm(x, **kwargs): return x\n",
        "\n",
        "# Ensure xgboost & joblib\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "except ModuleNotFoundError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"xgboost\"])\n",
        "    import xgboost as xgb\n",
        "try:\n",
        "    import joblib\n",
        "except ModuleNotFoundError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"joblib\"])\n",
        "    import joblib\n",
        "\n",
        "# HF deps\n",
        "from transformers import (\n",
        "    XLMRobertaTokenizerFast,\n",
        "    XLMRobertaForSequenceClassification,\n",
        "    XLMRobertaModel,\n",
        "    DataCollatorWithPadding,\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ---------- 0) Config / defaults ----------\n",
        "try:\n",
        "    cfg\n",
        "except NameError:\n",
        "    from dataclasses import dataclass\n",
        "    @dataclass\n",
        "    class _TmpCfg:\n",
        "        BASE_DIR: str = \"/content/drive/MyDrive/emc\"\n",
        "        CLEAN_TEST_CSV: str = \"/content/drive/MyDrive/emc/test.csv\"\n",
        "        TERMS_CSV: str = \"/content/drive/MyDrive/emc/engineering_terms.csv\"\n",
        "        XGB_OUTPUTS: str = \"/content/drive/MyDrive/emc/xgb_outputs_clean\"\n",
        "        XLM_R_OUTPUTS: str = \"/content/drive/MyDrive/emc/xlmr_only_outputs_clean\"\n",
        "        SIMPLE_OUTPUTS: str = \"/content/drive/MyDrive/emc/simple_fusion_outputs_clean\"\n",
        "        GATED_OUTPUTS: str = \"/content/drive/MyDrive/emc/gated_fusion_outputs_clean\"\n",
        "        TEXT_COL: str = \"content\"\n",
        "        LABEL_COL: str = \"label\"\n",
        "        LANG_COL: str = \"lang\"\n",
        "        MAX_LEN: int = 256\n",
        "        BATCH_SIZE: int = 16\n",
        "        N_FEATURES: int = 12\n",
        "        ID2LABEL: dict = {0: \"Real\", 1: \"Misinformation\"}\n",
        "    cfg = _TmpCfg()\n",
        "\n",
        "def ensure_attr(o, name, value):\n",
        "    if not hasattr(o, name) or getattr(o, name) in (None, \"\", 0):\n",
        "        setattr(o, name, value)\n",
        "\n",
        "for k, v in dict(\n",
        "    BASE_DIR=\"/content/drive/MyDrive/emc\",\n",
        "    CLEAN_TEST_CSV=\"/content/drive/MyDrive/emc/test.csv\",\n",
        "    TERMS_CSV=\"/content/drive/MyDrive/emc/engineering_terms.csv\",\n",
        "    XGB_OUTPUTS=\"/content/drive/MyDrive/emc/xgb_outputs_clean\",\n",
        "    XLM_R_OUTPUTS=\"/content/drive/MyDrive/emc/xlmr_only_outputs_clean\",\n",
        "    SIMPLE_OUTPUTS=\"/content/drive/MyDrive/emc/simple_fusion_outputs_clean\",\n",
        "    GATED_OUTPUTS=\"/content/drive/MyDrive/emc/gated_fusion_outputs_clean\",\n",
        "    TEXT_COL=\"content\", LABEL_COL=\"label\", LANG_COL=\"lang\",\n",
        "    MAX_LEN=256, BATCH_SIZE=16, N_FEATURES=12\n",
        ").items():\n",
        "    ensure_attr(cfg, k, v)\n",
        "\n",
        "# ---------- 1) Load test set ----------\n",
        "test_df = pd.read_csv(cfg.CLEAN_TEST_CSV)\n",
        "y_true = test_df[cfg.LABEL_COL].astype(int).values   # positive class = 1 (Misinformation)\n",
        "\n",
        "# ---------- 2) 12-D feature extractor (same as training) ----------\n",
        "import re\n",
        "_WORD_RE = re.compile(r\"\\w+\", re.UNICODE)\n",
        "_NUM_RE  = re.compile(r'[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?')\n",
        "STD_TERMS = {\"iso\",\"asme\",\"ieee\",\"din\",\"ansi\",\"iec\",\"ul\",\"astm\",\"en\"}\n",
        "SAFETY_TERMS = {\"safety\",\"hazard\",\"warning\",\"risk\",\"caution\",\"danger\",\"emergency\"}\n",
        "\n",
        "def simple_words(t: str): return _WORD_RE.findall(t or \"\")\n",
        "def sent_count(t: str) -> int:\n",
        "    if not t: return 0\n",
        "    return max(1, len(re.split(r'[.!?]+[\\s\\n]+', t)))\n",
        "def punct_count(t: str) -> int: return sum(1 for ch in (t or \"\") if ch in \".,;:!?\")\n",
        "def extract_numbers(text: str):\n",
        "    nums, dec = [], 0\n",
        "    for m in _NUM_RE.finditer(text or \"\"):\n",
        "        s = m.group(0)\n",
        "        try:\n",
        "            v = float(s)\n",
        "            if ('.' in s) or ('e' in s.lower()): dec += 1\n",
        "            nums.append(abs(v))\n",
        "        except: pass\n",
        "    return nums, dec\n",
        "def _finite_or_zero(x: float):\n",
        "    try:\n",
        "        xx = float(x);\n",
        "        return xx if np.isfinite(xx) else 0.0\n",
        "    except: return 0.0\n",
        "\n",
        "class TermsLexicon:\n",
        "    def __init__(self, csv_path: str, term_col=\"terms\", lang_col=\"lang\"):\n",
        "        if not os.path.exists(csv_path): raise FileNotFoundError(csv_path)\n",
        "        df = pd.read_csv(csv_path)\n",
        "        if term_col not in df.columns: raise ValueError(f\"Missing '{term_col}'\")\n",
        "        if lang_col not in df.columns: df[lang_col] = 'en'\n",
        "        self.by_lang = {\n",
        "            str(l).lower(): set(str(x).strip().lower() for x in d[term_col].dropna().tolist() if str(x).strip())\n",
        "            for l, d in df.groupby(lang_col)\n",
        "        }\n",
        "    def pct_in_text(self, text: str, lang: str) -> float:\n",
        "        if not text: return 0.0\n",
        "        terms = self.by_lang.get((lang or \"en\").lower(), set())\n",
        "        if not terms: return 0.0\n",
        "        ws = [w.lower() for w in simple_words(text)]\n",
        "        if not ws: return 0.0\n",
        "        return sum(1 for w in ws if w in terms) / max(1, len(ws))\n",
        "\n",
        "class FeatureExtractor12:\n",
        "    def __init__(self, tlex: TermsLexicon): self.tlex = tlex\n",
        "    def extract_one(self, text: str, lang: str):\n",
        "        text = \"\" if text is None else str(text); lang = (lang or \"en\").lower()\n",
        "        ws = simple_words(text); n_words = len(ws)\n",
        "        chars = len(text); words = n_words; sents = sent_count(text)\n",
        "        fre, fog = 0.0, 0.0  # omit textstat for portability\n",
        "        eng_pct = self.tlex.pct_in_text(text, lang)\n",
        "        punc = punct_count(text)\n",
        "        nums, dec_cnt = extract_numbers(text); nnums = len(nums)\n",
        "        avg_mag = float(np.mean(nums)) if nums else 0.0\n",
        "        dec_ratio = float(dec_cnt / max(1, len(nums)))\n",
        "        low = text.lower()\n",
        "        has_std = 1.0 if any(t in low for t in STD_TERMS) else 0.0\n",
        "        has_saf = 1.0 if any(t in low for t in SAFETY_TERMS) else 0.0\n",
        "        vals = [chars, words, sents, fre, fog, eng_pct, punc, nnums, has_std, has_saf, avg_mag, dec_ratio]\n",
        "        feats = np.asarray([_finite_or_zero(v) for v in vals], dtype=np.float64)\n",
        "        feats = np.nan_to_num(feats, nan=0.0, posinf=1e12, neginf=0.0)\n",
        "        return np.clip(feats, -1e12, 1e12).astype(np.float32)\n",
        "    def extract_df(self, df):\n",
        "        local = df if cfg.LANG_COL in df.columns else df.assign(**{cfg.LANG_COL:'en'})\n",
        "        rows = [self.extract_one(r.get(cfg.TEXT_COL,\"\"), r.get(cfg.LANG_COL,\"en\")) for _, r in local.iterrows()]\n",
        "        return np.stack(rows, axis=0).astype(np.float32)\n",
        "\n",
        "lex = TermsLexicon(cfg.TERMS_CSV)\n",
        "fe  = FeatureExtractor12(lex)\n",
        "X_raw = fe.extract_df(test_df)\n",
        "\n",
        "# ---------- 3) Tokenization datasets ----------\n",
        "class TextOnlyDS(Dataset):\n",
        "    def __init__(self, df, tokenizer, text_col=\"content\", label_col=\"label\", max_len=256):\n",
        "        self.texts = df[text_col].astype(str).tolist()\n",
        "        self.labels = df[label_col].astype(int).values\n",
        "        self.tok = tokenizer; self.max_len = max_len\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tok(self.texts[idx], truncation=True, padding=False,\n",
        "                       max_length=self.max_len, return_tensors=\"pt\")\n",
        "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
        "        item[\"labels\"] = torch.tensor(int(self.labels[idx]), dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "class TextFeatDS(Dataset):\n",
        "    def __init__(self, df, tokenizer, feats_scaled, text_col=\"content\", label_col=\"label\", max_len=256):\n",
        "        self.texts = df[text_col].astype(str).tolist()\n",
        "        self.labels = df[label_col].astype(int).values\n",
        "        self.tok = tokenizer; self.max_len = max_len\n",
        "        self.feats = feats_scaled.astype(np.float32)\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tok(self.texts[idx], truncation=True, padding=\"max_length\",\n",
        "                       max_length=self.max_len, return_tensors=\"pt\")\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(int(self.labels[idx]), dtype=torch.long),\n",
        "            \"feats\": torch.tensor(self.feats[idx], dtype=torch.float32),\n",
        "        }\n",
        "\n",
        "# Use the same tokenizer for all DLs (from fine-tuned XLM-R)\n",
        "tokenizer_xlmr = XLMRobertaTokenizerFast.from_pretrained(cfg.XLM_R_OUTPUTS)\n",
        "collator = DataCollatorWithPadding(tokenizer_xlmr)\n",
        "\n",
        "# ---------- 4) Model defs (Simple & Gated) ----------\n",
        "class SimpleFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + n_feats, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (out.last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "        fused = torch.cat([pooled, feats], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "\n",
        "class GatedFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2, feat_proj: int = 64):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.fe_proj = nn.Sequential(nn.Linear(n_feats, feat_proj), nn.ReLU())\n",
        "        self.gate    = nn.Sequential(nn.Linear(H + n_feats, 64), nn.ReLU(), nn.Linear(64, 1), nn.Sigmoid())\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + feat_proj, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (out.last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "        alpha = self.gate(torch.cat([pooled, feats], dim=1))\n",
        "        ef    = self.fe_proj(feats)\n",
        "        fused = torch.cat([pooled, alpha * ef], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "\n",
        "# ---------- 5) Load artifacts ----------\n",
        "# XGBoost\n",
        "xgb_model_path = os.path.join(cfg.XGB_OUTPUTS, \"xgb_model.json\")\n",
        "xgb_scaler_path = os.path.join(cfg.XGB_OUTPUTS, \"scaler12.pkl\")\n",
        "if not (os.path.exists(xgb_model_path) and os.path.exists(xgb_scaler_path)):\n",
        "    raise FileNotFoundError(\"XGBoost model/scaler not found.\")\n",
        "clf_xgb = xgb.XGBClassifier()\n",
        "clf_xgb.load_model(xgb_model_path)\n",
        "scaler_xgb = joblib.load(xgb_scaler_path)\n",
        "X_xgb = scaler_xgb.transform(X_raw)\n",
        "\n",
        "# XLM-R only (fine-tuned)\n",
        "if not os.path.exists(cfg.XLM_R_OUTPUTS):\n",
        "    raise FileNotFoundError(\"XLM-R outputs dir not found.\")\n",
        "model_xlmr = XLMRobertaForSequenceClassification.from_pretrained(cfg.XLM_R_OUTPUTS).to(device)\n",
        "\n",
        "# Simple Fusion\n",
        "simple_ckpt = os.path.join(cfg.SIMPLE_OUTPUTS, \"fusion_simple.pt\")\n",
        "simple_scaler_path = os.path.join(cfg.SIMPLE_OUTPUTS, \"scaler12.pkl\")\n",
        "if not (os.path.exists(simple_ckpt) and os.path.exists(simple_scaler_path)):\n",
        "    raise FileNotFoundError(\"Simple Fusion checkpoint/scaler not found.\")\n",
        "scaler_simple = joblib.load(simple_scaler_path)\n",
        "X_simple = scaler_simple.transform(X_raw)\n",
        "model_simple = SimpleFusion(\"xlm-roberta-base\", n_feats=cfg.N_FEATURES, n_labels=2).to(device)\n",
        "model_simple.load_state_dict(torch.load(simple_ckpt, map_location=device), strict=False)\n",
        "model_simple.eval()\n",
        "\n",
        "# Gated Fusion\n",
        "gated_ckpt = os.path.join(cfg.GATED_OUTPUTS, \"fusion_gated.pt\")\n",
        "gated_scaler_path = os.path.join(cfg.GATED_OUTPUTS, \"scaler12.pkl\")\n",
        "if not (os.path.exists(gated_ckpt) and os.path.exists(gated_scaler_path)):\n",
        "    raise FileNotFoundError(\"Gated Fusion checkpoint/scaler not found.\")\n",
        "scaler_gated = joblib.load(gated_scaler_path)\n",
        "X_gated = scaler_gated.transform(X_raw)\n",
        "model_gated = GatedFusion(\"xlm-roberta-base\", n_feats=cfg.N_FEATURES, n_labels=2, feat_proj=64).to(device)\n",
        "model_gated.load_state_dict(torch.load(gated_ckpt, map_location=device), strict=False)\n",
        "model_gated.eval()\n",
        "\n",
        "# ---------- 6) DataLoaders ----------\n",
        "# Use the same tokenizer for all since features are separate\n",
        "ds_xlmr = TextOnlyDS(test_df, tokenizer_xlmr, text_col=cfg.TEXT_COL, label_col=cfg.LABEL_COL, max_len=cfg.MAX_LEN)\n",
        "dl_xlmr = DataLoader(ds_xlmr, batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
        "\n",
        "ds_simple = TextFeatDS(test_df, tokenizer_xlmr, X_simple, text_col=cfg.TEXT_COL, label_col=cfg.LABEL_COL, max_len=cfg.MAX_LEN)\n",
        "ds_gated  = TextFeatDS(test_df, tokenizer_xlmr, X_gated,  text_col=cfg.TEXT_COL, label_col=cfg.LABEL_COL, max_len=cfg.MAX_LEN)\n",
        "dl_simple = DataLoader(ds_simple, batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
        "dl_gated  = DataLoader(ds_gated,  batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
        "\n",
        "# ---------- 7) Collect probabilities ----------\n",
        "def probs_xlmr(dataloader):\n",
        "    ps = []\n",
        "    model_xlmr.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"XLMR proba\"):\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k in (\"input_ids\",\"attention_mask\",\"labels\")}\n",
        "            out = model_xlmr(**inputs)\n",
        "            p = torch.softmax(out.logits, dim=-1)[:, 1].cpu().numpy()  # P(class=1 = Misinformation)\n",
        "            ps.append(p)\n",
        "    return np.concatenate(ps)\n",
        "\n",
        "def probs_fusion(model, dataloader):\n",
        "    ps = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Fusion proba\"):\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            am  = batch[\"attention_mask\"].to(device)\n",
        "            ft  = batch[\"feats\"].to(device)\n",
        "            logits = model(ids, am, ft)\n",
        "            p = torch.softmax(logits, dim=-1)[:, 1].cpu().numpy()\n",
        "            ps.append(p)\n",
        "    return np.concatenate(ps)\n",
        "\n",
        "# XGBoost prob (class 1)\n",
        "yprob_xgb = clf_xgb.predict_proba(X_xgb)[:, 1]\n",
        "# XLM-R prob\n",
        "yprob_xlmr = probs_xlmr(dl_xlmr)\n",
        "# Simple/Gated prob\n",
        "yprob_simple = probs_fusion(model_simple, dl_simple)\n",
        "yprob_gated  = probs_fusion(model_gated,  dl_gated)\n",
        "\n",
        "# ---------- 8) Compute PR + AP ----------\n",
        "curves = {}\n",
        "for name, prob in [\n",
        "    (\"XGBoost + Features\", yprob_xgb),\n",
        "    (\"XLM-R Only\",         yprob_xlmr),\n",
        "    (\"Simple Fusion\",      yprob_simple),\n",
        "    (\"Gated Fusion\",       yprob_gated),\n",
        "]:\n",
        "    precision, recall, thr = precision_recall_curve(y_true, prob)  # pos label = 1\n",
        "    ap = average_precision_score(y_true, prob)\n",
        "    curves[name] = {\"precision\": precision, \"recall\": recall, \"thr\": thr, \"ap\": ap}\n",
        "\n",
        "# ---------- 9) Plot PR curves (different colors) & save 600 dpi ----------\n",
        "colors = {\n",
        "    \"XGBoost + Features\": \"tab:blue\",\n",
        "    \"XLM-R Only\":         \"tab:red\",\n",
        "    \"Simple Fusion\":      \"tab:green\",\n",
        "    \"Gated Fusion\":       \"tab:orange\",\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(8, 7))\n",
        "# baseline = prevalence of positive class (random classifier AP)\n",
        "baseline = y_true.mean()\n",
        "plt.hlines(baseline, 0.0, 1.0, colors=\"gray\", linestyles=\"--\", linewidth=1, label=f\"Baseline (prevalence={baseline:.2f})\")\n",
        "\n",
        "for name, d in curves.items():\n",
        "    # PR curves are typically recall on x-axis, precision on y-axis\n",
        "    plt.plot(d[\"recall\"], d[\"precision\"], lw=2, label=f\"{name} (AP = {d['ap']:.4f})\", color=colors.get(name, None))\n",
        "\n",
        "plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05])\n",
        "plt.xlabel(\"Recall (Positive = Misinformation)\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision–Recall Curves — 4 Models\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.tight_layout()\n",
        "out_png = os.path.join(cfg.BASE_DIR, \"pr_curves_4models.png\")\n",
        "plt.savefig(out_png, dpi=600)\n",
        "plt.show()\n",
        "print(\"Saved PR figure (600 dpi):\", out_png)\n",
        "\n",
        "# ---------- 10) Save PR points (long CSV) ----------\n",
        "rows = []\n",
        "for name, d in curves.items():\n",
        "    # thresholds length = len(precision) - 1; pad with NaN for equal length\n",
        "    n = len(d[\"precision\"])\n",
        "    thr = np.concatenate([d[\"thr\"], [np.nan]]) if len(d[\"thr\"]) == n - 1 else d[\"thr\"]\n",
        "    rows.append(pd.DataFrame({\n",
        "        \"Model\": name,\n",
        "        \"recall\": d[\"recall\"],\n",
        "        \"precision\": d[\"precision\"],\n",
        "        \"threshold\": thr\n",
        "    }))\n",
        "pr_points = pd.concat(rows, ignore_index=True)\n",
        "out_csv = os.path.join(cfg.BASE_DIR, \"pr_points_4models.csv\")\n",
        "pr_points.to_csv(out_csv, index=False)\n",
        "print(\"Saved PR points CSV:\", out_csv)\n",
        "\n",
        "# (Optional) print APs\n",
        "for name, d in curves.items():\n",
        "    print(f\"{name:>20s}  AP = {d['ap']:.4f}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "BhUwfcl0srE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Grouped Robustness: Heatmap (Δ Macro-F1) + Grouped Bars per Model (Clean vs Group F1) ---\n",
        "\n",
        "import os, glob, re, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "\n",
        "# Try seaborn (for heatmap). If missing, install; if install fails, fall back to matplotlib-only heatmap.\n",
        "try:\n",
        "    import seaborn as sns\n",
        "    _HAS_SNS = True\n",
        "except Exception:\n",
        "    try:\n",
        "        import sys, subprocess\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"seaborn\"])\n",
        "        import seaborn as sns\n",
        "        _HAS_SNS = True\n",
        "    except Exception:\n",
        "        _HAS_SNS = False\n",
        "\n",
        "# ----------------- paths & settings -----------------\n",
        "BASE_DIR     = \"/content/drive/MyDrive/emc\"\n",
        "ADV_OUT_DIR  = os.path.join(BASE_DIR, \"adv_eval_outputs\")\n",
        "TABLES_DIR   = os.path.join(ADV_OUT_DIR, \"manuscript_tables\")\n",
        "FIG_OUT_DIR  = os.path.join(ADV_OUT_DIR, \"figures_robustness\")\n",
        "os.makedirs(FIG_OUT_DIR, exist_ok=True)\n",
        "\n",
        "# Which grouped table to load if present (match Block 31 default)\n",
        "AGGREGATOR   = \"mean\"   # \"mean\" | \"median\" | \"worst\"\n",
        "SUFFIX_MAP   = {\"mean\":\"avg\", \"median\":\"median\", \"worst\":\"worst\"}\n",
        "suffix       = SUFFIX_MAP.get(AGGREGATOR, \"avg\")\n",
        "GROUPED_CSV  = os.path.join(TABLES_DIR, f\"manuscript_grouped_macro_f1_{suffix}.csv\")\n",
        "\n",
        "# Optional: consistent model colors (used for bar charts)\n",
        "MODEL_COLORS = {\n",
        "    \"XGBoost + Features\": \"tab:blue\",\n",
        "    \"XLM-R Only\":         \"tab:red\",\n",
        "    \"Simple Fusion\":      \"tab:green\",\n",
        "    \"Gated Fusion\":       \"tab:orange\",\n",
        "}\n",
        "\n",
        "# ----------------- fallback: mapping if we need to rebuild -----------------\n",
        "ATTACK_GROUPS = {\n",
        "    \"CharSwap\":\"Typos & Casing\", \"DropVowels\":\"Typos & Casing\", \"CaseToggle\":\"Typos & Casing\",\n",
        "    \"PunctInsert\":\"Punct/Whitespace Noise\", \"WhitespaceNoise\":\"Punct/Whitespace Noise\",\n",
        "    \"UnicodeConfuse\":\"Unicode & Symbols\", \"SymbolAscii\":\"Unicode & Symbols\",\n",
        "    \"NumberPerturb\":\"Numbers\", \"Truncate80w\":\"Truncation\",\n",
        "    \"MaskDomainTerms\":\"Domain Terms\", \"DropDomainTerms\":\"Domain Terms\", \"SynonymSwapDomain\":\"Domain Terms\",\n",
        "    \"StandardNumCorrupt\":\"Standards Corruption\",\n",
        "    \"UnitNeutralizeMask\":\"Units Neutralization\", \"UnitNeutralizeDrop\":\"Units Neutralization\", \"UnitNeutralizeGeneric\":\"Units Neutralization\",\n",
        "    \"AcronymPerturb\":\"Acronyms & Citations\", \"CitationStrip\":\"Acronyms & Citations\",\n",
        "    \"DomainCombo1\":\"Domain Combos\", \"DomainCombo2\":\"Domain Combos\", \"DomainCombo3\":\"Domain Combos\", \"DomainMax\":\"Domain Combos\",\n",
        "}\n",
        "KEEP_GROUPS = [\n",
        "    \"Typos & Casing\",\n",
        "    \"Punct/Whitespace Noise\",\n",
        "    \"Unicode & Symbols\",\n",
        "    \"Numbers\",\n",
        "    \"Truncation\",\n",
        "    \"Domain Terms\",\n",
        "    \"Standards Corruption\",\n",
        "    \"Units Neutralization\",\n",
        "    # \"Acronyms & Citations\",\n",
        "    # \"Domain Combos\",\n",
        "]\n",
        "\n",
        "def _safe_read_csv(p):\n",
        "    try: return pd.read_csv(p)\n",
        "    except Exception as e:\n",
        "        print(f\"Skip {os.path.basename(p)}: {e}\"); return None\n",
        "\n",
        "def _load_grouped_from_disk():\n",
        "    if os.path.exists(GROUPED_CSV):\n",
        "        df = pd.read_csv(GROUPED_CSV)\n",
        "        # Ensure expected cols exist\n",
        "        need = {\"Model\",\"Group\",\"Clean Macro F1\",\"Attack Macro F1\",\"Δ\",\"Δ%\"}\n",
        "        if need.issubset(df.columns):\n",
        "            return df\n",
        "        else:\n",
        "            print(\"Grouped CSV found but missing expected columns, rebuilding from raw.\")\n",
        "    return None\n",
        "\n",
        "def _rebuild_grouped_from_raw():\n",
        "    clean_file = os.path.join(ADV_OUT_DIR, \"clean_eval.csv\")\n",
        "    clean_df = _safe_read_csv(clean_file)\n",
        "    if clean_df is None:\n",
        "        raise FileNotFoundError(\"clean_eval.csv not found to rebuild grouped results.\")\n",
        "    clean_df = clean_df[clean_df[\"Attack\"].astype(str).str.lower()==\"clean\"].copy()\n",
        "    clean_df = clean_df.rename(columns={\"macro_f1\":\"Clean Macro F1\"})\n",
        "    clean_df = clean_df[[\"Model\",\"Clean Macro F1\"]]\n",
        "\n",
        "    paths = sorted(glob.glob(os.path.join(ADV_OUT_DIR, \"adversarial_eval*.csv\")))\n",
        "    frames = []\n",
        "    for p in paths:\n",
        "        if p.endswith(\"clean_eval.csv\"): continue\n",
        "        df = _safe_read_csv(p)\n",
        "        if df is None: continue\n",
        "        if not {\"Model\",\"Attack\",\"macro_f1\"}.issubset(df.columns): continue\n",
        "        frames.append(df[[\"Model\",\"Attack\",\"macro_f1\"]])\n",
        "    if not frames:\n",
        "        raise RuntimeError(\"No adversarial_eval*.csv files found to rebuild grouped results.\")\n",
        "    adv = pd.concat(frames, ignore_index=True)\n",
        "    adv = adv[adv[\"Attack\"].isin(ATTACK_GROUPS.keys())].copy()\n",
        "    adv[\"Group\"] = adv[\"Attack\"].map(ATTACK_GROUPS)\n",
        "    if KEEP_GROUPS:\n",
        "        adv = adv[adv[\"Group\"].isin(KEEP_GROUPS)].copy()\n",
        "\n",
        "    # Aggregate within group\n",
        "    if AGGREGATOR == \"mean\":\n",
        "        agg = adv.groupby([\"Model\",\"Group\"], as_index=False)[\"macro_f1\"].mean()\n",
        "    elif AGGREGATOR == \"median\":\n",
        "        agg = adv.groupby([\"Model\",\"Group\"], as_index=False)[\"macro_f1\"].median()\n",
        "    elif AGGREGATOR == \"worst\":\n",
        "        agg = adv.groupby([\"Model\",\"Group\"], as_index=False)[\"macro_f1\"].min()\n",
        "    else:\n",
        "        raise ValueError(\"AGGREGATOR must be one of {'mean','median','worst'}\")\n",
        "    agg = agg.rename(columns={\"macro_f1\":\"Attack Macro F1\"})\n",
        "\n",
        "    out = agg.merge(clean_df, on=\"Model\", how=\"left\")\n",
        "    out[\"Δ\"]  = out[\"Clean Macro F1\"] - out[\"Attack Macro F1\"]\n",
        "    out[\"Δ%\"] = 100.0 * out[\"Δ\"] / out[\"Clean Macro F1\"].replace(0.0, np.nan)\n",
        "\n",
        "    # Sort groups by mean drop desc\n",
        "    grp_order = out.groupby(\"Group\")[\"Δ\"].mean().sort_values(ascending=False).index.tolist()\n",
        "    out[\"Group\"] = pd.Categorical(out[\"Group\"], categories=grp_order, ordered=True)\n",
        "    out = out.sort_values([\"Group\",\"Model\"]).reset_index(drop=True)\n",
        "    return out\n",
        "\n",
        "# ----------------- 1) get grouped table -----------------\n",
        "try:\n",
        "    grouped_tbl   # already in memory from Block 30/31?\n",
        "    df_grouped = grouped_tbl.copy()\n",
        "except NameError:\n",
        "    df_grouped = _load_grouped_from_disk()\n",
        "    if df_grouped is None:\n",
        "        print(\"Grouped table not found on disk; rebuilding from raw eval files...\")\n",
        "        df_grouped = _rebuild_grouped_from_raw()\n",
        "\n",
        "# round for prettier annotations (keeps full precision internally if needed)\n",
        "df_grouped[\"Clean Macro F1\"]  = df_grouped[\"Clean Macro F1\"].astype(float)\n",
        "df_grouped[\"Attack Macro F1\"] = df_grouped[\"Attack Macro F1\"].astype(float)\n",
        "df_grouped[\"Δ\"]               = df_grouped[\"Δ\"].astype(float)\n",
        "df_grouped[\"Δ%\"]              = df_grouped[\"Δ%\"].astype(float)\n",
        "\n",
        "# ----------------- 2a) HEATMAP of Δ Macro-F1 -----------------\n",
        "# Pivot: rows=Group, cols=Model, values=Δ\n",
        "heat = df_grouped.pivot(index=\"Group\", columns=\"Model\", values=\"Δ\")\n",
        "\n",
        "# Order rows (already categorical ordered by mean drop); order columns by overall AVERAGE drop\n",
        "col_order = heat.mean(axis=0).sort_values(ascending=False).index.to_list()\n",
        "heat = heat[col_order]\n",
        "\n",
        "fig_h, ax_h = plt.subplots(figsize=(1.6 + 0.8*len(col_order), 1.0 + 0.45*len(heat.index)), dpi=100)\n",
        "if _HAS_SNS:\n",
        "    sns.heatmap(\n",
        "        heat, ax=ax_h, cmap=\"Reds\", annot=True, fmt=\".3f\",\n",
        "        cbar_kws={\"label\": r\"Drop $\\Delta$ in Macro F1\"}, linewidths=0.5, linecolor=\"white\",\n",
        "        vmin=0.0, vmax=max(0.05, float(np.nanmax(heat.values)))  # cap for visual spread\n",
        "    )\n",
        "else:\n",
        "    im = ax_h.imshow(heat.values, cmap=\"Reds\", aspect=\"auto\", vmin=0.0, vmax=np.nanmax(heat.values))\n",
        "    ax_h.set_xticks(range(len(heat.columns))); ax_h.set_xticklabels(heat.columns, rotation=45, ha=\"right\")\n",
        "    ax_h.set_yticks(range(len(heat.index)));   ax_h.set_yticklabels(heat.index)\n",
        "    for i in range(heat.shape[0]):\n",
        "        for j in range(heat.shape[1]):\n",
        "            val = heat.values[i, j]\n",
        "            if np.isfinite(val):\n",
        "                ax_h.text(j, i, f\"{val:.3f}\", va=\"center\", ha=\"center\", color=\"black\", fontsize=8)\n",
        "    cbar = fig_h.colorbar(im, ax=ax_h); cbar.set_label(r\"Drop $\\Delta$ in Macro F1\")\n",
        "\n",
        "ax_h.set_title(f\"Grouped Robustness — Δ Macro F1 (aggregator = {AGGREGATOR})\")\n",
        "plt.tight_layout()\n",
        "heat_png = os.path.join(FIG_OUT_DIR, f\"heatmap_grouped_delta_{suffix}.png\")\n",
        "plt.savefig(heat_png, dpi=600)\n",
        "plt.show()\n",
        "print(\"Saved heatmap (600 dpi):\", heat_png)\n",
        "\n",
        "# Also save the heatmap matrix\n",
        "heat_csv = os.path.join(FIG_OUT_DIR, f\"heatmap_grouped_delta_{suffix}.csv\")\n",
        "heat.to_csv(heat_csv)\n",
        "print(\"Saved heatmap data CSV:\", heat_csv)\n",
        "\n",
        "# ----------------- 2b) GROUPED BARS per model (Clean vs Group F1, Δ annotated) -----------------\n",
        "def sanitize_name(s: str) -> str:\n",
        "    return re.sub(r\"[^A-Za-z0-9_.-]+\", \"_\", str(s))\n",
        "\n",
        "models = df_grouped[\"Model\"].unique().tolist()\n",
        "\n",
        "for model in models:\n",
        "    sub = df_grouped[df_grouped[\"Model\"] == model].copy()\n",
        "    # Preserve the group order used in heatmap\n",
        "    sub[\"Group\"] = pd.Categorical(sub[\"Group\"], categories=heat.index.tolist(), ordered=True)\n",
        "    sub = sub.sort_values(\"Group\")\n",
        "\n",
        "    groups = sub[\"Group\"].astype(str).tolist()\n",
        "    clean  = sub[\"Clean Macro F1\"].values\n",
        "    groupf = sub[\"Attack Macro F1\"].values\n",
        "    delta  = sub[\"Δ\"].values\n",
        "\n",
        "    x = np.arange(len(groups))\n",
        "    width = 0.38\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(max(8, 0.6*len(groups)+2), 5), dpi=100)\n",
        "    # Clean F1 is constant per model, but plotted for comparability\n",
        "    bars1 = ax.bar(x - width/2, clean,  width, label=\"Clean F1\", color=\"lightgray\", edgecolor=\"black\")\n",
        "    bars2 = ax.bar(x + width/2, groupf, width, label=\"Group F1\", color=MODEL_COLORS.get(model, \"tab:blue\"), alpha=0.9)\n",
        "\n",
        "    # Annotate Δ above the grouped F1 bars\n",
        "    for xi, gval, dval in zip(x, groupf, delta):\n",
        "        ax.text(xi + width/2, gval + 0.01, f\"Δ={dval:.3f}\", ha=\"center\", va=\"bottom\", fontsize=8, rotation=0)\n",
        "\n",
        "    ax.set_xticks(x); ax.set_xticklabels(groups, rotation=30, ha=\"right\")\n",
        "    ax.set_ylim(0.0, min(1.05, max(1.0, float(np.nanmax(np.r_[clean, groupf])) + 0.05)))\n",
        "    ax.set_ylabel(\"Macro F1\")\n",
        "    ax.set_title(f\"Clean vs Grouped F1 — {model} (aggregator = {AGGREGATOR})\")\n",
        "    ax.legend(loc=\"best\", frameon=True)\n",
        "    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    out_png = os.path.join(FIG_OUT_DIR, f\"grouped_bars_{sanitize_name(model)}_{suffix}.png\")\n",
        "    plt.savefig(out_png, dpi=600)\n",
        "    plt.show()\n",
        "    print(\"Saved grouped bars (600 dpi):\", out_png)\n",
        "\n",
        "print(\"Done.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "80hypqMwuMeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Ablation/Contribution + Gate Behavior (Gated Fusion) ---\n",
        "\n",
        "import os, sys, subprocess, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "from dataclasses import dataclass\n",
        "from sklearn.metrics import f1_score\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Try to import joblib/xgboost; install if missing (Colab-safe)\n",
        "try:\n",
        "    import joblib\n",
        "except ModuleNotFoundError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"joblib\"])\n",
        "    import joblib\n",
        "\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "except ModuleNotFoundError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"xgboost\"])\n",
        "    import xgboost as xgb\n",
        "\n",
        "from transformers import (\n",
        "    XLMRobertaTokenizerFast,\n",
        "    XLMRobertaForSequenceClassification,\n",
        "    XLMRobertaModel,\n",
        "    DataCollatorWithPadding,\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ------------------ Config / defaults ------------------\n",
        "try:\n",
        "    cfg\n",
        "except NameError:\n",
        "    @dataclass\n",
        "    class _TmpCfg:\n",
        "        BASE_DIR: str = \"/content/drive/MyDrive/emc\"\n",
        "        CLEAN_TEST_CSV: str = \"/content/drive/MyDrive/emc/test.csv\"\n",
        "        TERMS_CSV: str = \"/content/drive/MyDrive/emc/engineering_terms.csv\"\n",
        "        XGB_OUTPUTS: str = \"/content/drive/MyDrive/emc/xgb_outputs_clean\"\n",
        "        XLM_R_OUTPUTS: str = \"/content/drive/MyDrive/emc/xlmr_only_outputs_clean\"\n",
        "        SIMPLE_OUTPUTS: str = \"/content/drive/MyDrive/emc/simple_fusion_outputs_clean\"\n",
        "        GATED_OUTPUTS: str = \"/content/drive/MyDrive/emc/gated_fusion_outputs_clean\"\n",
        "        TEXT_COL: str = \"content\"\n",
        "        LABEL_COL: str = \"label\"\n",
        "        LANG_COL: str = \"lang\"\n",
        "        MAX_LEN: int = 256\n",
        "        BATCH_SIZE: int = 16\n",
        "        N_FEATURES: int = 12\n",
        "        ID2LABEL: dict = {0: \"Real\", 1: \"Misinformation\"}\n",
        "    cfg = _TmpCfg()\n",
        "\n",
        "FIG_DIR = os.path.join(cfg.BASE_DIR, \"figures_analysis\")\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "\n",
        "# ------------------ Load test set ------------------\n",
        "test_df = pd.read_csv(cfg.CLEAN_TEST_CSV)\n",
        "y_true = test_df[cfg.LABEL_COL].astype(int).values\n",
        "\n",
        "# ------------------ 12-D features (same as training) ------------------\n",
        "import re\n",
        "_WORD_RE = re.compile(r\"\\w+\", re.UNICODE)\n",
        "_NUM_RE  = re.compile(r'[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?')\n",
        "STD_TERMS = {\"iso\",\"asme\",\"ieee\",\"din\",\"ansi\",\"iec\",\"ul\",\"astm\",\"en\"}\n",
        "SAFETY_TERMS = {\"safety\",\"hazard\",\"warning\",\"risk\",\"caution\",\"danger\",\"emergency\"}\n",
        "\n",
        "def simple_words(t: str): return _WORD_RE.findall(t or \"\")\n",
        "def sent_count(t: str) -> int:\n",
        "    if not t: return 0\n",
        "    return max(1, len(re.split(r'[.!?]+[\\s\\n]+', t)))\n",
        "def punct_count(t: str) -> int: return sum(1 for ch in (t or \"\") if ch in \".,;:!?\")\n",
        "def extract_numbers(text: str):\n",
        "    nums, dec = [], 0\n",
        "    for m in _NUM_RE.finditer(text or \"\"):\n",
        "        s = m.group(0)\n",
        "        try:\n",
        "            v = float(s)\n",
        "            if ('.' in s) or ('e' in s.lower()): dec += 1\n",
        "            nums.append(abs(v))\n",
        "        except: pass\n",
        "    return nums, dec\n",
        "def _finite_or_zero(x: float):\n",
        "    try:\n",
        "        xx = float(x);\n",
        "        return xx if np.isfinite(xx) else 0.0\n",
        "    except: return 0.0\n",
        "\n",
        "class TermsLexicon:\n",
        "    def __init__(self, csv_path: str, term_col=\"terms\", lang_col=\"lang\"):\n",
        "        if not os.path.exists(csv_path): raise FileNotFoundError(csv_path)\n",
        "        df = pd.read_csv(csv_path)\n",
        "        if term_col not in df.columns: raise ValueError(f\"Missing '{term_col}'\")\n",
        "        if lang_col not in df.columns: df[lang_col] = 'en'\n",
        "        self.by_lang = {\n",
        "            str(l).lower(): set(str(x).strip().lower() for x in d[term_col].dropna().tolist() if str(x).strip())\n",
        "            for l, d in df.groupby(lang_col)\n",
        "        }\n",
        "    def pct_in_text(self, text: str, lang: str) -> float:\n",
        "        if not text: return 0.0\n",
        "        terms = self.by_lang.get((lang or \"en\").lower(), set())\n",
        "        if not terms: return 0.0\n",
        "        ws = [w.lower() for w in simple_words(text)]\n",
        "        if not ws: return 0.0\n",
        "        return sum(1 for w in ws if w in terms) / max(1, len(ws))\n",
        "\n",
        "class FeatureExtractor12:\n",
        "    def __init__(self, tlex: TermsLexicon): self.tlex = tlex\n",
        "    def extract_one(self, text: str, lang: str):\n",
        "        text = \"\" if text is None else str(text); lang = (lang or \"en\").lower()\n",
        "        ws = simple_words(text); n_words = len(ws)\n",
        "        chars = len(text); words = n_words; sents = sent_count(text)\n",
        "        fre, fog = 0.0, 0.0  # portable\n",
        "        eng_pct = self.tlex.pct_in_text(text, lang)\n",
        "        punc = punct_count(text)\n",
        "        nums, dec_cnt = extract_numbers(text); nnums = len(nums)\n",
        "        avg_mag = float(np.mean(nums)) if nums else 0.0\n",
        "        dec_ratio = float(dec_cnt / max(1, len(nums)))\n",
        "        low = text.lower()\n",
        "        has_std = 1.0 if any(t in low for t in STD_TERMS) else 0.0\n",
        "        has_saf = 1.0 if any(t in low for t in SAFETY_TERMS) else 0.0\n",
        "        vals = [chars, words, sents, fre, fog, eng_pct, punc, nnums, has_std, has_saf, avg_mag, dec_ratio]\n",
        "        feats = np.asarray([_finite_or_zero(v) for v in vals], dtype=np.float64)\n",
        "        feats = np.nan_to_num(feats, nan=0.0, posinf=1e12, neginf=0.0)\n",
        "        return np.clip(feats, -1e12, 1e12).astype(np.float32)\n",
        "    def extract_df(self, df):\n",
        "        local = df if cfg.LANG_COL in df.columns else df.assign(**{cfg.LANG_COL:'en'})\n",
        "        rows = [self.extract_one(r.get(cfg.TEXT_COL,\"\"), r.get(cfg.LANG_COL,\"en\")) for _, r in local.iterrows()]\n",
        "        return np.stack(rows, axis=0).astype(np.float32)\n",
        "\n",
        "lex = TermsLexicon(cfg.TERMS_CSV)\n",
        "fe  = FeatureExtractor12(lex)\n",
        "X_raw = fe.extract_df(test_df)\n",
        "\n",
        "# ------------------ Tokenization datasets ------------------\n",
        "class TextOnlyDS(Dataset):\n",
        "    def __init__(self, df, tokenizer, text_col=\"content\", label_col=\"label\", max_len=256):\n",
        "        self.texts = df[text_col].astype(str).tolist()\n",
        "        self.labels = df[label_col].astype(int).values\n",
        "        self.tok = tokenizer; self.max_len = max_len\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tok(self.texts[idx], truncation=True, padding=False,\n",
        "                       max_length=self.max_len, return_tensors=\"pt\")\n",
        "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
        "        item[\"labels\"] = torch.tensor(int(self.labels[idx]), dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "class TextFeatDS(Dataset):\n",
        "    def __init__(self, df, tokenizer, feats_scaled, text_col=\"content\", label_col=\"label\", max_len=256):\n",
        "        self.texts = df[text_col].astype(str).tolist()\n",
        "        self.labels = df[label_col].astype(int).values\n",
        "        self.tok = tokenizer; self.max_len = max_len\n",
        "        self.feats = feats_scaled.astype(np.float32)\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tok(self.texts[idx], truncation=True, padding=\"max_length\",\n",
        "                       max_length=self.max_len, return_tensors=\"pt\")\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(int(self.labels[idx]), dtype=torch.long),\n",
        "            \"feats\": torch.tensor(self.feats[idx], dtype=torch.float32),\n",
        "        }\n",
        "\n",
        "# ------------------ Model defs (Simple / Gated) ------------------\n",
        "class SimpleFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + n_feats, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (out.last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "        fused = torch.cat([pooled, feats], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "\n",
        "class GatedFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2, feat_proj: int = 64):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.fe_proj = nn.Sequential(nn.Linear(n_feats, feat_proj), nn.ReLU())\n",
        "        self.gate    = nn.Sequential(nn.Linear(H + n_feats, 64), nn.ReLU(), nn.Linear(64, 1), nn.Sigmoid())\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + feat_proj, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (out.last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "        alpha = self.gate(torch.cat([pooled, feats], dim=1))\n",
        "        ef    = self.fe_proj(feats)\n",
        "        fused = torch.cat([pooled, alpha * ef], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "    # helper to expose alpha\n",
        "    def gate_values(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (out.last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "        alpha = self.gate(torch.cat([pooled, feats], dim=1))\n",
        "        return alpha.squeeze(-1)  # [B]\n",
        "\n",
        "# ------------------ Load artifacts ------------------\n",
        "# Tokenizer from fine-tuned XLM-R\n",
        "tok = XLMRobertaTokenizerFast.from_pretrained(cfg.XLM_R_OUTPUTS)\n",
        "collator = DataCollatorWithPadding(tok)\n",
        "\n",
        "# XGB\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "xgb_model.load_model(os.path.join(cfg.XGB_OUTPUTS, \"xgb_model.json\"))\n",
        "xgb_scaler = joblib.load(os.path.join(cfg.XGB_OUTPUTS, \"scaler12.pkl\"))\n",
        "X_xgb = xgb_scaler.transform(X_raw)\n",
        "\n",
        "# XLM-R (fine-tuned)\n",
        "xlmr = XLMRobertaForSequenceClassification.from_pretrained(cfg.XLM_R_OUTPUTS).to(device)\n",
        "xlmr.eval()\n",
        "\n",
        "# Simple Fusion\n",
        "simple = SimpleFusion(\"xlm-roberta-base\", n_feats=cfg.N_FEATURES, n_labels=2).to(device)\n",
        "simple.load_state_dict(torch.load(os.path.join(cfg.SIMPLE_OUTPUTS, \"fusion_simple.pt\"), map_location=device), strict=False)\n",
        "simple.eval()\n",
        "simple_scaler = joblib.load(os.path.join(cfg.SIMPLE_OUTPUTS, \"scaler12.pkl\"))\n",
        "X_simple = simple_scaler.transform(X_raw)\n",
        "\n",
        "# Gated Fusion\n",
        "gated = GatedFusion(\"xlm-roberta-base\", n_feats=cfg.N_FEATURES, n_labels=2, feat_proj=64).to(device)\n",
        "gated.load_state_dict(torch.load(os.path.join(cfg.GATED_OUTPUTS, \"fusion_gated.pt\"), map_location=device), strict=False)\n",
        "gated.eval()\n",
        "gated_scaler = joblib.load(os.path.join(cfg.GATED_OUTPUTS, \"scaler12.pkl\"))\n",
        "X_gated = gated_scaler.transform(X_raw)\n",
        "\n",
        "# ------------------ If clean_eval.csv exists, use it; else compute ------------------\n",
        "ABLATION_PNG = os.path.join(FIG_DIR, \"ablation_contribution_macroF1.png\")\n",
        "GATE_DISTR_PNG = os.path.join(FIG_DIR, \"gated_alpha_distribution.png\")\n",
        "GATE_HEXBIN_PNG = os.path.join(FIG_DIR, \"gated_alpha_vs_engterms_hexbin.png\")\n",
        "ABLATION_CSV = os.path.join(FIG_DIR, \"ablation_contribution_macroF1.csv\")\n",
        "\n",
        "clean_eval_csv = os.path.join(cfg.BASE_DIR, \"adv_eval_outputs\", \"clean_eval.csv\")\n",
        "use_csv = os.path.exists(clean_eval_csv)\n",
        "\n",
        "if use_csv:\n",
        "    df_clean = pd.read_csv(clean_eval_csv)\n",
        "    df_clean = df_clean[df_clean[\"Attack\"].astype(str).str.lower() == \"clean\"].copy()\n",
        "    # Expect columns: Model, macro_f1\n",
        "    f1_map = df_clean.set_index(\"Model\")[\"macro_f1\"].to_dict()\n",
        "    print(\"Using macro F1 from:\", clean_eval_csv)\n",
        "else:\n",
        "    print(\"No clean_eval.csv found — computing Macro F1 from checkpoints...\")\n",
        "\n",
        "    # XLM-R probs/preds\n",
        "    ds_xlmr = TextOnlyDS(test_df, tok, text_col=cfg.TEXT_COL, label_col=cfg.LABEL_COL, max_len=cfg.MAX_LEN)\n",
        "    dl_xlmr = DataLoader(ds_xlmr, batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
        "    yhat_xlmr = []\n",
        "    with torch.no_grad():\n",
        "        for b in dl_xlmr:\n",
        "            inp = {k: v.to(device) for k, v in b.items() if k in (\"input_ids\",\"attention_mask\")}\n",
        "            logits = xlmr(**inp).logits\n",
        "            yhat_xlmr.append(logits.argmax(dim=-1).cpu().numpy())\n",
        "    yhat_xlmr = np.concatenate(yhat_xlmr)\n",
        "\n",
        "    # XGB preds\n",
        "    yhat_xgb = xgb_model.predict(X_xgb)\n",
        "\n",
        "    # Simple preds\n",
        "    ds_simple = TextFeatDS(test_df, tok, X_simple, text_col=cfg.TEXT_COL, label_col=cfg.LABEL_COL, max_len=cfg.MAX_LEN)\n",
        "    dl_simple = DataLoader(ds_simple, batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
        "    yhat_simple = []\n",
        "    with torch.no_grad():\n",
        "        for b in dl_simple:\n",
        "            ids = b[\"input_ids\"].to(device); am = b[\"attention_mask\"].to(device); ft = b[\"feats\"].to(device)\n",
        "            logits = simple(ids, am, ft)\n",
        "            yhat_simple.append(logits.argmax(dim=-1).cpu().numpy())\n",
        "    yhat_simple = np.concatenate(yhat_simple)\n",
        "\n",
        "    # Gated preds\n",
        "    ds_gated = TextFeatDS(test_df, tok, X_gated, text_col=cfg.TEXT_COL, label_col=cfg.LABEL_COL, max_len=cfg.MAX_LEN)\n",
        "    dl_gated = DataLoader(ds_gated, batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
        "    yhat_gated = []\n",
        "    with torch.no_grad():\n",
        "        for b in dl_gated:\n",
        "            ids = b[\"input_ids\"].to(device); am = b[\"attention_mask\"].to(device); ft = b[\"feats\"].to(device)\n",
        "            logits = gated(ids, am, ft)\n",
        "            yhat_gated.append(logits.argmax(dim=-1).cpu().numpy())\n",
        "    yhat_gated = np.concatenate(yhat_gated)\n",
        "\n",
        "    f1_map = {\n",
        "        \"XLM-R Only\": f1_score(y_true, yhat_xlmr, average=\"macro\"),\n",
        "        \"XGBoost + Features\": f1_score(y_true, yhat_xgb, average=\"macro\"),\n",
        "        \"Simple Fusion\": f1_score(y_true, yhat_simple, average=\"macro\"),\n",
        "        \"Gated Fusion\": f1_score(y_true, yhat_gated, average=\"macro\"),\n",
        "    }\n",
        "\n",
        "# ------------------ (1) Ablation / Contribution Plot ------------------\n",
        "# Order models for visual consistency\n",
        "order_models = [\"XLM-R Only\", \"XGBoost + Features\", \"Simple Fusion\", \"Gated Fusion\"]\n",
        "vals = [f1_map[m] for m in order_models if m in f1_map]\n",
        "\n",
        "plt.figure(figsize=(7.5, 5.0))\n",
        "bars = plt.bar(order_models, vals)\n",
        "# Annotate values on bars\n",
        "for rect, v in zip(bars, vals):\n",
        "    plt.text(rect.get_x() + rect.get_width()/2, rect.get_height() + 0.01, f\"{v:.3f}\",\n",
        "             ha=\"center\", va=\"bottom\", fontsize=9)\n",
        "plt.ylabel(\"Macro F1 (Clean Test)\")\n",
        "plt.title(\"Ablation / Contribution — Clean Macro F1\")\n",
        "plt.ylim(0.0, min(1.05, max(1.0, float(np.max(vals)) + 0.06)))\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(ABLATION_PNG, dpi=600)\n",
        "plt.show()\n",
        "print(\"Saved:\", ABLATION_PNG)\n",
        "\n",
        "pd.DataFrame({\"Model\": order_models, \"Macro_F1\": vals}).to_csv(ABLATION_CSV, index=False)\n",
        "print(\"Saved:\", ABLATION_CSV)\n",
        "\n",
        "# ------------------ (2) Gate Behavior (Gated Fusion) ------------------\n",
        "# Collect alpha for whole test set (using SCALED features for gating)\n",
        "alphas, eng_terms_pct = [], []\n",
        "with torch.no_grad():\n",
        "    for b in dl_gated:\n",
        "        ids = b[\"input_ids\"].to(device); am = b[\"attention_mask\"].to(device); ft = b[\"feats\"].to(device)\n",
        "        a = gated.gate_values(ids, am, ft)  # [B]\n",
        "        alphas.append(a.cpu().numpy())\n",
        "# Concatenate gate values\n",
        "alphas = np.concatenate(alphas)\n",
        "\n",
        "# % Eng Terms from RAW features (for interpretability) — feature index 5\n",
        "eng_terms_pct = X_raw[:, 5].astype(float)\n",
        "\n",
        "# (2a) Violin + Histogram\n",
        "fig, axes = plt.subplots(1, 2, figsize=(11, 4.2), constrained_layout=True)\n",
        "# Violin\n",
        "axes[0].violinplot(alphas, showmeans=True, showextrema=True)\n",
        "axes[0].set_title(\"Gated Fusion — Gate Value $\\\\alpha$ (distribution)\")\n",
        "axes[0].set_xticks([1]); axes[0].set_xticklabels([\"All test samples\"])\n",
        "axes[0].set_ylabel(\"$\\\\alpha$ (0–1)\")\n",
        "\n",
        "# Histogram\n",
        "axes[1].hist(alphas, bins=30)\n",
        "axes[1].set_title(\"Histogram of $\\\\alpha$\")\n",
        "axes[1].set_xlabel(\"$\\\\alpha$ (gate strength)\"); axes[1].set_ylabel(\"Count\")\n",
        "\n",
        "plt.savefig(GATE_DISTR_PNG, dpi=600)\n",
        "plt.show()\n",
        "print(\"Saved:\", GATE_DISTR_PNG)\n",
        "\n",
        "# (2b) 2D density (hexbin) of alpha vs % Eng Terms\n",
        "plt.figure(figsize=(6.5, 5.2))\n",
        "hb = plt.hexbin(eng_terms_pct, alphas, gridsize=35, cmap=\"viridis\", mincnt=1)\n",
        "plt.xlabel(\"% Engineering Terms (raw)\"); plt.ylabel(\"$\\\\alpha$\")\n",
        "plt.title(\"$\\\\alpha$ vs. % Eng Terms — Gated Fusion\")\n",
        "cb = plt.colorbar(hb); cb.set_label(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(GATE_HEXBIN_PNG, dpi=600)\n",
        "plt.show()\n",
        "print(\"Saved:\", GATE_HEXBIN_PNG)\n",
        "\n",
        "print(\"Done.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "_z3AFPIRw1Fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Waterfall (Top-K Δ Macro-F1) per model + Coverage vs Drop Scatter (domain attacks) ---\n",
        "\n",
        "import os, glob, re, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "\n",
        "# ---------------- Paths & settings ----------------\n",
        "BASE_DIR     = \"/content/drive/MyDrive/emc\"\n",
        "ADV_DIR      = os.path.join(BASE_DIR, \"adv_eval_outputs\")\n",
        "PERTURB_DIR  = os.path.join(ADV_DIR, \"perturbed\")\n",
        "FIG_DIR      = os.path.join(ADV_DIR, \"figures_specificity\")\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "\n",
        "CLEAN_EVAL   = os.path.join(ADV_DIR, \"clean_eval.csv\")\n",
        "ADV_EVAL_GLOB= os.path.join(ADV_DIR, \"adversarial_eval*.csv\")\n",
        "\n",
        "TEXT_COL     = \"content\"\n",
        "LABEL_COL    = \"label\"\n",
        "ID_COL       = \"id\"        # if present in clean & perturbed, used to align rows for coverage\n",
        "TOP_K        = 10          # number of attacks to show in waterfall\n",
        "DPI          = 600\n",
        "\n",
        "# If you already produced a coverage summary, put it here (columns: Attack, coverage_pct)\n",
        "COVERAGE_SUMMARY = os.path.join(ADV_DIR, \"coverage_summary.csv\")\n",
        "\n",
        "# Domain-related groups for scatter\n",
        "ATTACK_GROUPS = {\n",
        "    \"CharSwap\":\"Typos & Casing\", \"DropVowels\":\"Typos & Casing\", \"CaseToggle\":\"Typos & Casing\",\n",
        "    \"PunctInsert\":\"Punct/Whitespace Noise\", \"WhitespaceNoise\":\"Punct/Whitespace Noise\",\n",
        "    \"UnicodeConfuse\":\"Unicode & Symbols\", \"SymbolAscii\":\"Unicode & Symbols\",\n",
        "    \"NumberPerturb\":\"Numbers\", \"Truncate80w\":\"Truncation\",\n",
        "    \"MaskDomainTerms\":\"Domain Terms\", \"DropDomainTerms\":\"Domain Terms\", \"SynonymSwapDomain\":\"Domain Terms\",\n",
        "    \"StandardNumCorrupt\":\"Standards Corruption\",\n",
        "    \"UnitNeutralizeMask\":\"Units Neutralization\", \"UnitNeutralizeDrop\":\"Units Neutralization\", \"UnitNeutralizeGeneric\":\"Units Neutralization\",\n",
        "    \"AcronymPerturb\":\"Acronyms & Citations\", \"CitationStrip\":\"Acronyms & Citations\",\n",
        "    \"DomainCombo1\":\"Domain Combos\", \"DomainCombo2\":\"Domain Combos\", \"DomainCombo3\":\"Domain Combos\", \"DomainMax\":\"Domain Combos\",\n",
        "}\n",
        "DOMAIN_GROUPS = {\n",
        "    \"Domain Terms\", \"Standards Corruption\", \"Units Neutralization\",\n",
        "    \"Acronyms & Citations\", \"Domain Combos\"\n",
        "}\n",
        "\n",
        "# Model display order/colors\n",
        "MODELS = [\"XLM-R Only\", \"XGBoost + Features\", \"Simple Fusion\", \"Gated Fusion\"]\n",
        "MODEL_COLORS = {\n",
        "    \"XGBoost + Features\": \"tab:blue\",\n",
        "    \"XLM-R Only\":         \"tab:red\",\n",
        "    \"Simple Fusion\":      \"tab:green\",\n",
        "    \"Gated Fusion\":       \"tab:orange\",\n",
        "}\n",
        "\n",
        "def _read_csv(path):\n",
        "    try:\n",
        "        return pd.read_csv(path)\n",
        "    except Exception as e:\n",
        "        print(f\"Skip {os.path.basename(path)}: {e}\")\n",
        "        return None\n",
        "\n",
        "# ---------------- Load clean & adversarial evals ----------------\n",
        "clean_df = _read_csv(CLEAN_EVAL)\n",
        "if clean_df is None:\n",
        "    raise FileNotFoundError(\"clean_eval.csv not found. Please export clean results first.\")\n",
        "\n",
        "clean_df = clean_df.copy()\n",
        "clean_df[\"Attack_low\"] = clean_df[\"Attack\"].astype(str).str.lower()\n",
        "clean_df = clean_df[clean_df[\"Attack_low\"] == \"clean\"]\n",
        "clean_base = clean_df[[\"Model\",\"macro_f1\"]].rename(columns={\"macro_f1\":\"Clean Macro F1\"})\n",
        "\n",
        "adv_frames = []\n",
        "for p in sorted(glob.glob(ADV_EVAL_GLOB)):\n",
        "    if os.path.basename(p).lower() == \"clean_eval.csv\":\n",
        "        continue\n",
        "    dfp = _read_csv(p)\n",
        "    if dfp is None:\n",
        "        continue\n",
        "    if not {\"Model\",\"Attack\",\"macro_f1\"}.issubset(dfp.columns):\n",
        "        continue\n",
        "    adv_frames.append(dfp[[\"Model\",\"Attack\",\"macro_f1\"]])\n",
        "if not adv_frames:\n",
        "    raise RuntimeError(\"No adversarial_eval*.csv files found.\")\n",
        "\n",
        "adv_all = pd.concat(adv_frames, ignore_index=True)\n",
        "adv_all[\"Attack\"] = adv_all[\"Attack\"].astype(str)\n",
        "adv_all[\"Group\"]  = adv_all[\"Attack\"].map(ATTACK_GROUPS).fillna(\"Other\")\n",
        "\n",
        "# Merge with clean baseline per model to compute Δ\n",
        "adv_all = adv_all.merge(clean_base, on=\"Model\", how=\"left\")\n",
        "adv_all[\"Delta\"] = adv_all[\"Clean Macro F1\"] - adv_all[\"macro_f1\"]\n",
        "adv_all[\"Delta%\"] = 100.0 * adv_all[\"Delta\"] / adv_all[\"Clean Macro F1\"].replace(0.0, np.nan)\n",
        "\n",
        "# Save per-attack deltas (for traceability)\n",
        "delta_csv = os.path.join(FIG_DIR, \"per_attack_delta_macro_f1.csv\")\n",
        "adv_all.to_csv(delta_csv, index=False)\n",
        "print(\"Saved per-attack Δ table:\", delta_csv)\n",
        "\n",
        "# ---------------- (A) Waterfall (Top-K drops) per model ----------------\n",
        "def waterfall_plot_for_model(df_model, model_name, top_k=10):\n",
        "    # Sort attacks by Delta desc (largest drop first)\n",
        "    top = df_model.sort_values(\"Delta\", ascending=False).head(top_k).copy()\n",
        "    clean = float(df_model[\"Clean Macro F1\"].iloc[0])\n",
        "\n",
        "    # Cumulative \"remaining\" after sequentially subtracting these K worst drops\n",
        "    drops = top[\"Delta\"].values.clip(min=0)\n",
        "    remaining = max(0.0, clean - drops.sum())\n",
        "\n",
        "    labels = [\"Clean\"] + top[\"Attack\"].tolist() + [\"Remaining\"]\n",
        "    x = np.arange(len(labels))\n",
        "\n",
        "    # Bar heights and bottoms for a simple waterfall illusion:\n",
        "    heights = []\n",
        "    bottoms = []\n",
        "    colors  = []\n",
        "    # Clean bar\n",
        "    heights.append(clean); bottoms.append(0.0); colors.append(\"lightgray\")\n",
        "    # Drops (draw as downward red blocks sitting on the *post-drop* baseline)\n",
        "    running = clean\n",
        "    for d in drops:\n",
        "        running_after = max(0.0, running - d)\n",
        "        heights.append(d)\n",
        "        bottoms.append(running_after)\n",
        "        colors.append(\"tab:red\")\n",
        "        running = running_after\n",
        "    # Final remaining\n",
        "    heights.append(remaining); bottoms.append(0.0); colors.append(MODEL_COLORS.get(model_name, \"tab:blue\"))\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(max(8, 0.6*len(labels)), 5))\n",
        "    for i in range(len(labels)):\n",
        "        ax.bar(x[i], heights[i], bottom=bottoms[i], color=colors[i], edgecolor=\"black\", linewidth=0.6)\n",
        "\n",
        "    # connectors between tops (optional visual cue)\n",
        "    y_prev = clean\n",
        "    for i, d in enumerate(drops, start=1):\n",
        "        y_new = max(0.0, y_prev - d)\n",
        "        ax.plot([x[i-1]+0.45, x[i]-0.45], [y_prev, y_prev], color=\"gray\", lw=0.8)  # top line segment\n",
        "        ax.plot([x[i]-0.45, x[i]-0.45], [y_prev, y_new], color=\"gray\", lw=0.8)    # vertical drop\n",
        "        y_prev = y_new\n",
        "\n",
        "    # annotate drop values\n",
        "    for i, d in enumerate(drops, start=1):\n",
        "        ax.text(x[i], bottoms[i] + heights[i] + 0.01, f\"−{d:.3f}\", ha=\"center\", va=\"bottom\", fontsize=8)\n",
        "\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(labels, rotation=25, ha=\"right\")\n",
        "    ax.set_ylabel(\"Macro F1\")\n",
        "    ax.set_title(f\"Top-{top_k} Attack Drops — Waterfall ({model_name})\")\n",
        "    ax.set_ylim(0.0, min(1.05, max(1.0, clean + 0.08)))\n",
        "    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    out_png = os.path.join(FIG_DIR, f\"waterfall_top{top_k}_{re.sub(r'[^A-Za-z0-9_.-]+','_',model_name)}.png\")\n",
        "    plt.savefig(out_png, dpi=DPI)\n",
        "    plt.show()\n",
        "    print(\"Saved waterfall:\", out_png)\n",
        "\n",
        "# Generate waterfall per model\n",
        "for m in MODELS:\n",
        "    dfm = adv_all[adv_all[\"Model\"] == m].copy()\n",
        "    if dfm.empty:\n",
        "        print(f\"[WARN] No rows for model: {m}\")\n",
        "        continue\n",
        "    waterfall_plot_for_model(dfm, m, top_k=TOP_K)\n",
        "\n",
        "# ---------------- (B) Coverage vs. Drop Scatter (domain attacks) ----------------\n",
        "# 1) coverage lookup: prefer summary, else compute by comparing clean vs perturbed contents\n",
        "def _load_coverage_summary(path):\n",
        "    if os.path.exists(path):\n",
        "        try:\n",
        "            cov = pd.read_csv(path)\n",
        "            if {\"Attack\",\"coverage_pct\"}.issubset(cov.columns):\n",
        "                cov[\"Attack\"] = cov[\"Attack\"].astype(str)\n",
        "                return cov[[\"Attack\",\"coverage_pct\"]].drop_duplicates()\n",
        "        except Exception as e:\n",
        "            print(\"Coverage summary read failed:\", e)\n",
        "    return None\n",
        "\n",
        "coverage_summary = _load_coverage_summary(COVERAGE_SUMMARY)\n",
        "\n",
        "# Load clean test for coverage fallback\n",
        "clean_test_path = os.path.join(BASE_DIR, \"test.csv\")\n",
        "clean_test_df = _read_csv(clean_test_path)\n",
        "\n",
        "def _estimate_coverage_from_files(attack):\n",
        "    # Find a perturbed file for this attack\n",
        "    cands = [\n",
        "        os.path.join(PERTURB_DIR, f\"{attack}.csv\"),\n",
        "        os.path.join(PERTURB_DIR, attack, \"dataset.csv\"),\n",
        "        os.path.join(PERTURB_DIR, f\"{attack}_test.csv\"),\n",
        "    ]\n",
        "    path = None\n",
        "    for p in cands:\n",
        "        if os.path.exists(p):\n",
        "            path = p; break\n",
        "    if path is None:\n",
        "        g = glob.glob(os.path.join(PERTURB_DIR, f\"**/*{attack}*.csv\"), recursive=True)\n",
        "        if g: path = g[0]\n",
        "    if path is None or clean_test_df is None:\n",
        "        return np.nan\n",
        "\n",
        "    adv_df = _read_csv(path)\n",
        "    if adv_df is None or TEXT_COL not in adv_df.columns:\n",
        "        return np.nan\n",
        "\n",
        "    # align rows\n",
        "    if ID_COL in adv_df.columns and ID_COL in clean_test_df.columns:\n",
        "        merged = clean_test_df[[ID_COL, TEXT_COL]].merge(\n",
        "            adv_df[[ID_COL, TEXT_COL]], on=ID_COL, suffixes=(\"_clean\",\"_adv\")\n",
        "        )\n",
        "        if merged.empty:\n",
        "            return np.nan\n",
        "        changed = (merged[f\"{TEXT_COL}_clean\"].astype(str).values != merged[f\"{TEXT_COL}_adv\"].astype(str).values)\n",
        "        coverage = 100.0 * changed.mean()\n",
        "    else:\n",
        "        # fallback: assume same order & length\n",
        "        n = min(len(clean_test_df), len(adv_df))\n",
        "        changed = (clean_test_df[TEXT_COL].astype(str).values[:n] != adv_df[TEXT_COL].astype(str).values[:n])\n",
        "        coverage = 100.0 * (changed.sum() / max(1, n))\n",
        "    return float(coverage)\n",
        "\n",
        "def get_coverage_pct(attack):\n",
        "    if coverage_summary is not None:\n",
        "        row = coverage_summary[coverage_summary[\"Attack\"] == attack]\n",
        "        if not row.empty:\n",
        "            return float(row[\"coverage_pct\"].iloc[0])\n",
        "    return _estimate_coverage_from_files(attack)\n",
        "\n",
        "# Build dataframe for domain attacks with coverage & Δ per model\n",
        "dom = adv_all.copy()\n",
        "dom = dom[dom[\"Group\"].isin(DOMAIN_GROUPS)].copy()\n",
        "\n",
        "cov_vals = []\n",
        "for atk in sorted(dom[\"Attack\"].unique()):\n",
        "    cov_vals.append((atk, get_coverage_pct(atk)))\n",
        "cov_df = pd.DataFrame(cov_vals, columns=[\"Attack\",\"coverage_pct\"])\n",
        "\n",
        "dom = dom.merge(cov_df, on=\"Attack\", how=\"left\")\n",
        "\n",
        "# Save table\n",
        "cov_csv = os.path.join(FIG_DIR, \"domain_coverage_vs_drop.csv\")\n",
        "dom.to_csv(cov_csv, index=False)\n",
        "print(\"Saved domain coverage vs drop table:\", cov_csv)\n",
        "\n",
        "# 2) Scatter grid: one subplot per model\n",
        "n_models = len(MODELS)\n",
        "n_cols = 2\n",
        "n_rows = int(np.ceil(n_models / n_cols))\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 4.5*n_rows), squeeze=False)\n",
        "\n",
        "for i, m in enumerate(MODELS):\n",
        "    r = i // n_cols\n",
        "    c = i %  n_cols\n",
        "    ax = axes[r][c]\n",
        "    sub = dom[dom[\"Model\"] == m].copy()\n",
        "    sub = sub[np.isfinite(sub[\"coverage_pct\"])]\n",
        "\n",
        "    if sub.empty:\n",
        "        ax.set_title(f\"{m} — no domain attacks/coverage\")\n",
        "        ax.set_xlabel(\"Coverage (%)\"); ax.set_ylabel(\"Δ Macro-F1 (Clean − Attack)\")\n",
        "        ax.grid(True, linestyle=\"--\", alpha=0.3)\n",
        "        continue\n",
        "\n",
        "    x = sub[\"coverage_pct\"].values\n",
        "    y = sub[\"Delta\"].values\n",
        "    ax.scatter(x, y, s=28, alpha=0.9, color=MODEL_COLORS.get(m, None), edgecolors=\"black\", linewidths=0.4)\n",
        "\n",
        "    # (optional) show simple Pearson r\n",
        "    if len(x) >= 2:\n",
        "        r_val = np.corrcoef(x, y)[0,1]\n",
        "        ax.text(0.02, 0.95, f\"r={r_val:.2f}\", transform=ax.transAxes, ha=\"left\", va=\"top\", fontsize=10)\n",
        "\n",
        "    # nice labels\n",
        "    for _, row in sub.iterrows():\n",
        "        ax.annotate(row[\"Attack\"], (row[\"coverage_pct\"], row[\"Delta\"]), fontsize=7, xytext=(3,3), textcoords=\"offset points\")\n",
        "\n",
        "    ax.set_title(f\"{m} — Coverage vs Δ Macro-F1 (Domain attacks)\")\n",
        "    ax.set_xlabel(\"Coverage (%)\")\n",
        "    ax.set_ylabel(\"Δ Macro-F1 (Clean − Attack)\")\n",
        "    ax.grid(True, linestyle=\"--\", alpha=0.3)\n",
        "\n",
        "# remove empty axes if any\n",
        "for j in range(i+1, n_rows*n_cols):\n",
        "    r = j // n_cols; c = j % n_cols\n",
        "    fig.delaxes(axes[r][c])\n",
        "\n",
        "plt.tight_layout()\n",
        "scatter_png = os.path.join(FIG_DIR, \"coverage_vs_drop_scatter_domain.png\")\n",
        "plt.savefig(scatter_png, dpi=DPI)\n",
        "plt.show()\n",
        "print(\"Saved scatter grid:\", scatter_png)\n",
        "\n",
        "print(\"Done.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hYrLNbiN2GAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Confusion Matrices (Clean vs Worst Group) + Resource/Latency Footprint ===\n",
        "# Outputs:\n",
        "#   adv_eval_outputs/figures_diagnostics/cm_<Model>_clean_vs_<Attack>.png  (600 dpi)\n",
        "#   adv_eval_outputs/figures_diagnostics/cm_counts.csv\n",
        "#   adv_eval_outputs/figures_diagnostics/footprint_bars.png  (600 dpi)\n",
        "#   adv_eval_outputs/figures_diagnostics/footprint_table.csv\n",
        "#\n",
        "# Assumptions:\n",
        "# - Clean results:  .../adv_eval_outputs/clean_eval.csv  (rows where Attack == \"Clean\")\n",
        "# - Attack results: .../adv_eval_outputs/adversarial_eval*.csv (Model, Attack, macro_f1)\n",
        "# - Perturbed data: .../adv_eval_outputs/perturbed/<Attack>.csv  (or fuzzy-matched)\n",
        "# - Test set:       .../test.csv  (content, label[, id])\n",
        "\n",
        "import os, re, glob, time, difflib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# ---------------- Paths & config ----------------\n",
        "BASE_DIR   = \"/content/drive/MyDrive/emc\"\n",
        "ADV_DIR    = os.path.join(BASE_DIR, \"adv_eval_outputs\")\n",
        "PERT_DIR   = os.path.join(ADV_DIR, \"perturbed\")\n",
        "FIG_DIR    = os.path.join(ADV_DIR, \"figures_diagnostics\")\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "\n",
        "CLEAN_EVAL = os.path.join(ADV_DIR, \"clean_eval.csv\")\n",
        "ADV_GLOB   = os.path.join(ADV_DIR, \"adversarial_eval*.csv\")\n",
        "TEST_CSV   = os.path.join(BASE_DIR, \"test.csv\")\n",
        "\n",
        "XGB_DIR    = os.path.join(BASE_DIR, \"xgb_outputs_clean\")\n",
        "XLMR_DIR   = os.path.join(BASE_DIR, \"xlmr_only_outputs_clean\")\n",
        "SIMPLE_DIR = os.path.join(BASE_DIR, \"simple_fusion_outputs_clean\")\n",
        "GATED_DIR  = os.path.join(BASE_DIR, \"gated_fusion_outputs_clean\")\n",
        "\n",
        "TEXT_COL   = \"content\"\n",
        "LABEL_COL  = \"label\"\n",
        "LANG_COL   = \"lang\"\n",
        "ID_COL     = \"id\"\n",
        "MAX_LEN    = 256\n",
        "BATCH_SIZE = 32\n",
        "N_FEATS    = 12\n",
        "DPI        = 600\n",
        "\n",
        "MODELS = [\"XLM-R Only\", \"XGBoost + Features\", \"Simple Fusion\", \"Gated Fusion\"]\n",
        "MODEL_COLORS = {\n",
        "    \"XGBoost + Features\": \"tab:blue\",\n",
        "    \"XLM-R Only\":         \"tab:red\",\n",
        "    \"Simple Fusion\":      \"tab:green\",\n",
        "    \"Gated Fusion\":       \"tab:orange\",\n",
        "}\n",
        "\n",
        "# Attack→Group mapping (extend as needed)\n",
        "ATTACK_GROUPS = {\n",
        "    \"CharSwap\":\"Typos & Casing\", \"DropVowels\":\"Typos & Casing\", \"CaseToggle\":\"Typos & Casing\",\n",
        "    \"PunctInsert\":\"Punct/Whitespace Noise\", \"WhitespaceNoise\":\"Punct/Whitespace Noise\",\n",
        "    \"UnicodeConfuse\":\"Unicode & Symbols\", \"SymbolAscii\":\"Unicode & Symbols\",\n",
        "    \"NumberPerturb\":\"Numbers\", \"Truncate80w\":\"Truncation\",\n",
        "    \"MaskDomainTerms\":\"Domain Terms\", \"DropDomainTerms\":\"Domain Terms\", \"SynonymSwapDomain\":\"Domain Terms\",\n",
        "    \"StandardNumCorrupt\":\"Standards Corruption\",\n",
        "    \"UnitNeutralizeMask\":\"Units Neutralization\", \"UnitNeutralizeDrop\":\"Units Neutralization\", \"UnitNeutralizeGeneric\":\"Units Neutralization\",\n",
        "    \"AcronymPerturb\":\"Acronyms & Citations\", \"CitationStrip\":\"Acronyms & Citations\",\n",
        "    \"DomainCombo1\":\"Domain Combos\", \"DomainCombo2\":\"Domain Combos\", \"DomainCombo3\":\"Domain Combos\", \"DomainMax\":\"Domain Combos\",\n",
        "    \"Numbers/Units\":\"Units Neutralization\",\n",
        "    \"Unit Conversion (NEW)\":\"Units Neutralization\",\n",
        "}\n",
        "\n",
        "def _norm(s: str) -> str:\n",
        "    s = str(s).lower()\n",
        "    s = re.sub(r\"[\\s\\-\\/]+\", \"_\", s)\n",
        "    s = re.sub(r\"[^a-z0-9_]+\", \"\", s)\n",
        "    return s\n",
        "\n",
        "# ---------------- Load results & pick worst attacks per model ----------------\n",
        "def _read_csv(p):\n",
        "    try: return pd.read_csv(p)\n",
        "    except Exception as e:\n",
        "        print(f\"[skip] {os.path.basename(p)}: {e}\"); return None\n",
        "\n",
        "clean_eval = _read_csv(CLEAN_EVAL)\n",
        "if clean_eval is None:\n",
        "    raise FileNotFoundError(\"Missing clean_eval.csv\")\n",
        "\n",
        "clean_only = clean_eval[clean_eval[\"Attack\"].astype(str).str.lower()==\"clean\"].copy()\n",
        "clean_base = clean_only[[\"Model\",\"macro_f1\"]].rename(columns={\"macro_f1\":\"Clean Macro F1\"})\n",
        "\n",
        "adv_frames = []\n",
        "for p in sorted(glob.glob(ADV_GLOB)):\n",
        "    if os.path.basename(p).lower() == \"clean_eval.csv\": continue\n",
        "    df = _read_csv(p)\n",
        "    if df is None: continue\n",
        "    if not {\"Model\",\"Attack\",\"macro_f1\"}.issubset(df.columns): continue\n",
        "    adv_frames.append(df[[\"Model\",\"Attack\",\"macro_f1\"]])\n",
        "if not adv_frames:\n",
        "    raise RuntimeError(\"No adversarial_eval*.csv found\")\n",
        "\n",
        "adv_all = pd.concat(adv_frames, ignore_index=True)\n",
        "adv_all[\"Group\"] = adv_all[\"Attack\"].map(ATTACK_GROUPS).fillna(\"Other\")\n",
        "adv_all = adv_all.merge(clean_base, on=\"Model\", how=\"left\")\n",
        "adv_all[\"Delta\"] = adv_all[\"Clean Macro F1\"] - adv_all[\"macro_f1\"]\n",
        "\n",
        "# worst group per model = group with minimal macro_f1 (worst attack averaged is also ok; we choose min inside group)\n",
        "worst_group = (\n",
        "    adv_all.groupby([\"Model\",\"Group\"])[\"macro_f1\"]\n",
        "    .min()\n",
        "    .reset_index()\n",
        "    .sort_values([\"Model\",\"macro_f1\"])\n",
        "    .groupby(\"Model\")\n",
        "    .first()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"macro_f1\":\"WorstGroupMacroF1\"})\n",
        ")\n",
        "# pick worst single attack within that worst group for each model\n",
        "worst_attacks = []\n",
        "for _, row in worst_group.iterrows():\n",
        "    m, g = row[\"Model\"], row[\"Group\"]\n",
        "    sub = adv_all[(adv_all[\"Model\"]==m) & (adv_all[\"Group\"]==g)].copy()\n",
        "    if sub.empty: continue\n",
        "    worst = sub.sort_values(\"macro_f1\").iloc[0]\n",
        "    worst_attacks.append({\"Model\": m, \"Group\": g, \"Attack\": worst[\"Attack\"], \"AttackMacroF1\": worst[\"macro_f1\"]})\n",
        "worst_attacks = pd.DataFrame(worst_attacks)\n",
        "print(\"Worst group & attack per model:\\n\", worst_attacks.to_string(index=False))\n",
        "\n",
        "# ---------------- Load test & helper to find perturbed CSV ----------------\n",
        "test_df = _read_csv(TEST_CSV)\n",
        "if test_df is None or TEXT_COL not in test_df.columns or LABEL_COL not in test_df.columns:\n",
        "    raise FileNotFoundError(\"test.csv missing required columns\")\n",
        "\n",
        "def _find_attack_file(name: str):\n",
        "    # exact variations first\n",
        "    cands = [\n",
        "        os.path.join(PERT_DIR, f\"{name}.csv\"),\n",
        "        os.path.join(PERT_DIR, _norm(name) + \".csv\"),\n",
        "        os.path.join(PERT_DIR, name, \"dataset.csv\"),\n",
        "        os.path.join(PERT_DIR, f\"{name}_test.csv\"),\n",
        "    ]\n",
        "    for p in cands:\n",
        "        if os.path.exists(p): return p\n",
        "    # fuzzy match\n",
        "    pool = glob.glob(os.path.join(PERT_DIR, \"**\", \"*.csv\"), recursive=True)\n",
        "    if not pool: return None\n",
        "    stems = {p: os.path.splitext(os.path.basename(p))[0] for p in pool}\n",
        "    names = list(stems.values())\n",
        "    match = difflib.get_close_matches(name, names, n=1, cutoff=0.5)\n",
        "    if match:\n",
        "        for p, st in stems.items():\n",
        "            if st == match[0]: return p\n",
        "    # substring fallback\n",
        "    for p, st in stems.items():\n",
        "        if _norm(name) in _norm(st) or _norm(st) in _norm(name):\n",
        "            return p\n",
        "    return None\n",
        "\n",
        "# ---------------- Feature extractor (12-D) for XGB/Simple/Gated ----------------\n",
        "import re\n",
        "_WORD_RE = re.compile(r\"\\w+\", re.UNICODE)\n",
        "_NUM_RE  = re.compile(r'[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?')\n",
        "STD_TERMS = {\"iso\",\"asme\",\"ieee\",\"din\",\"ansi\",\"iec\",\"ul\",\"astm\",\"en\"}\n",
        "SAFETY_TERMS = {\"safety\",\"hazard\",\"warning\",\"risk\",\"caution\",\"danger\",\"emergency\"}\n",
        "def simple_words(t: str): return _WORD_RE.findall(t or \"\")\n",
        "def sent_count(t: str) -> int:\n",
        "    if not t: return 0\n",
        "    return max(1, len(re.split(r'[.!?]+[\\s\\n]+', t)))\n",
        "def punct_count(t: str) -> int: return sum(1 for ch in (t or \"\") if ch in \".,;:!?\")\n",
        "def extract_numbers(text: str):\n",
        "    nums, dec = [], 0\n",
        "    for m in _NUM_RE.finditer(text or \"\"):\n",
        "        s = m.group(0)\n",
        "        try:\n",
        "            v = float(s)\n",
        "            if ('.' in s) or ('e' in s.lower()): dec += 1\n",
        "            nums.append(abs(v))\n",
        "        except: pass\n",
        "    return nums, dec\n",
        "def _finite_or_zero(x: float):\n",
        "    try:\n",
        "        xx = float(x);\n",
        "        return xx if np.isfinite(xx) else 0.0\n",
        "    except: return 0.0\n",
        "\n",
        "class TermsLexicon:\n",
        "    def __init__(self, csv_path: str, term_col=\"terms\", lang_col=\"lang\"):\n",
        "        df = pd.read_csv(csv_path)\n",
        "        if term_col not in df.columns: raise ValueError(f\"Missing '{term_col}'\")\n",
        "        if lang_col not in df.columns: df[lang_col] = 'en'\n",
        "        self.by_lang = {str(l).lower(): set(str(x).strip().lower() for x in d[term_col].dropna().tolist() if str(x).strip())\n",
        "                        for l, d in df.groupby(lang_col)}\n",
        "    def pct_in_text(self, text: str, lang: str) -> float:\n",
        "        terms = self.by_lang.get((lang or \"en\").lower(), set())\n",
        "        if not terms: return 0.0\n",
        "        ws = [w.lower() for w in simple_words(text)]\n",
        "        return sum(1 for w in ws if w in terms) / max(1, len(ws)) if ws else 0.0\n",
        "\n",
        "TERMS_CSV = os.path.join(BASE_DIR, \"engineering_terms.csv\")\n",
        "lex = TermsLexicon(TERMS_CSV)\n",
        "\n",
        "class FeatureExtractor12:\n",
        "    def __init__(self, tlex: TermsLexicon): self.tlex = tlex\n",
        "    def extract_one(self, text: str, lang: str):\n",
        "        text = \"\" if text is None else str(text); lang = (lang or \"en\").lower()\n",
        "        ws = simple_words(text); n_words = len(ws)\n",
        "        chars = len(text); words = n_words; sents = sent_count(text)\n",
        "        fre, fog = 0.0, 0.0\n",
        "        eng_pct = self.tlex.pct_in_text(text, lang)\n",
        "        punc = punct_count(text)\n",
        "        nums, dec_cnt = extract_numbers(text); nnums = len(nums)\n",
        "        avg_mag = float(np.mean(nums)) if nums else 0.0\n",
        "        dec_ratio = float(dec_cnt / max(1, len(nums)))\n",
        "        low = text.lower()\n",
        "        has_std = 1.0 if any(t in low for t in STD_TERMS) else 0.0\n",
        "        has_saf = 1.0 if any(t in low for t in SAFETY_TERMS) else 0.0\n",
        "        vals = [chars, words, sents, fre, fog, eng_pct, punc, nnums, has_std, has_saf, avg_mag, dec_ratio]\n",
        "        arr = np.asarray([_finite_or_zero(v) for v in vals], dtype=np.float64)\n",
        "        arr = np.nan_to_num(arr, nan=0.0, posinf=1e12, neginf=0.0)\n",
        "        return np.clip(arr, -1e12, 1e12).astype(np.float32)\n",
        "    def extract_df(self, df):\n",
        "        local = df if LANG_COL in df.columns else df.assign(**{LANG_COL:'en'})\n",
        "        rows = [self.extract_one(r.get(TEXT_COL,\"\"), r.get(LANG_COL,\"en\")) for _, r in local.iterrows()]\n",
        "        return np.stack(rows, axis=0).astype(np.float32)\n",
        "\n",
        "fe = FeatureExtractor12(lex)\n",
        "\n",
        "# ---------------- Tokenization & models ----------------\n",
        "from transformers import XLMRobertaTokenizerFast, XLMRobertaModel, XLMRobertaForSequenceClassification, DataCollatorWithPadding\n",
        "import joblib, xgboost as xgb\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tok = XLMRobertaTokenizerFast.from_pretrained(XLMR_DIR)\n",
        "collator = DataCollatorWithPadding(tok)\n",
        "\n",
        "class TextOnlyDS(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_len=256):\n",
        "        self.texts = df[TEXT_COL].astype(str).tolist()\n",
        "        self.labels = df[LABEL_COL].astype(int).values\n",
        "        self.tok = tokenizer; self.max_len = max_len\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, i):\n",
        "        enc = self.tok(self.texts[i], truncation=True, padding=False, max_length=self.max_len, return_tensors=\"pt\")\n",
        "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
        "        item[\"labels\"] = torch.tensor(int(self.labels[i]), dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "class TextFeatDS(Dataset):\n",
        "    def __init__(self, df, tokenizer, feats_scaled, max_len=256):\n",
        "        self.texts = df[TEXT_COL].astype(str).tolist()\n",
        "        self.labels = df[LABEL_COL].astype(int).values\n",
        "        self.tok = tokenizer; self.max_len = max_len\n",
        "        self.feats = feats_scaled.astype(np.float32)\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, i):\n",
        "        enc = self.tok(self.texts[i], truncation=True, padding=\"max_length\", max_length=self.max_len, return_tensors=\"pt\")\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(int(self.labels[i]), dtype=torch.long),\n",
        "            \"feats\": torch.tensor(self.feats[i], dtype=torch.float32),\n",
        "        }\n",
        "\n",
        "class SimpleFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + n_feats, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (out.last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "        fused = torch.cat([pooled, feats], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "\n",
        "class GatedFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2, feat_proj: int = 64):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.fe_proj = nn.Sequential(nn.Linear(n_feats, feat_proj), nn.ReLU())\n",
        "        self.gate    = nn.Sequential(nn.Linear(H + n_feats, 64), nn.ReLU(), nn.Linear(64, 1), nn.Sigmoid())\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + feat_proj, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (out.last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "        alpha = self.gate(torch.cat([pooled, feats], dim=1))\n",
        "        ef    = self.fe_proj(feats)\n",
        "        fused = torch.cat([pooled, alpha * ef], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "\n",
        "# Load artifacts\n",
        "# XGB\n",
        "xgb_model = xgb.XGBClassifier(); xgb_model.load_model(os.path.join(XGB_DIR, \"xgb_model.json\"))\n",
        "xgb_scaler = joblib.load(os.path.join(XGB_DIR, \"scaler12.pkl\"))\n",
        "\n",
        "# XLM-R\n",
        "xlmr = XLMRobertaForSequenceClassification.from_pretrained(XLMR_DIR).to(device); xlmr.eval()\n",
        "\n",
        "# Simple\n",
        "simple_scaler = joblib.load(os.path.join(SIMPLE_DIR, \"scaler12.pkl\"))\n",
        "simple = SimpleFusion(\"xlm-roberta-base\", N_FEATS, 2).to(device)\n",
        "simple.load_state_dict(torch.load(os.path.join(SIMPLE_DIR, \"fusion_simple.pt\"), map_location=device), strict=False); simple.eval()\n",
        "\n",
        "# Gated\n",
        "gated_scaler = joblib.load(os.path.join(GATED_DIR, \"scaler12.pkl\"))\n",
        "gated = GatedFusion(\"xlm-roberta-base\", N_FEATS, 2, feat_proj=64).to(device)\n",
        "gated.load_state_dict(torch.load(os.path.join(GATED_DIR, \"fusion_gated.pt\"), map_location=device), strict=False); gated.eval()\n",
        "\n",
        "# ---------------- Prediction helpers ----------------\n",
        "@torch.no_grad()\n",
        "def preds_xlmr(df):\n",
        "    ds = TextOnlyDS(df, tok, MAX_LEN); dl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
        "    out = []\n",
        "    for b in dl:\n",
        "        inp = {k: v.to(device) for k, v in b.items() if k in (\"input_ids\",\"attention_mask\")}\n",
        "        out.append(xlmr(**inp).logits.argmax(dim=-1).cpu().numpy())\n",
        "    return np.concatenate(out)\n",
        "\n",
        "@torch.no_grad()\n",
        "def preds_fusion(df, scaler, model):\n",
        "    X = fe.extract_df(df); Xs = scaler.transform(X).astype(np.float32)\n",
        "    ds = TextFeatDS(df, tok, Xs, MAX_LEN); dl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
        "    out = []\n",
        "    for b in dl:\n",
        "        ids = b[\"input_ids\"].to(device); am = b[\"attention_mask\"].to(device); ft = b[\"feats\"].to(device)\n",
        "        out.append(model(ids, am, ft).argmax(dim=-1).cpu().numpy())\n",
        "    return np.concatenate(out)\n",
        "\n",
        "def preds_xgb(df):\n",
        "    X = fe.extract_df(df); Xs = xgb_scaler.transform(X); return xgb_model.predict(Xs)\n",
        "\n",
        "# ---------------- Plot confusion matrices per model ----------------\n",
        "def plot_cm(ax, y_true, y_pred, title):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
        "    # normalize rows (per true class)\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        cm_norm = cm / cm.sum(axis=1, keepdims=True)\n",
        "    im = ax.imshow(cm_norm, cmap=\"Blues\", vmin=0.0, vmax=1.0)\n",
        "    for i in range(2):\n",
        "        for j in range(2):\n",
        "            ax.text(j, i, f\"{cm[i,j]}\\n({cm_norm[i,j]:.2f})\",\n",
        "                    ha=\"center\", va=\"center\", fontsize=9, color=\"black\")\n",
        "    ax.set_xticks([0,1]); ax.set_yticks([0,1])\n",
        "    ax.set_xticklabels([\"Real (0)\",\"Misinformation (1)\"])\n",
        "    ax.set_yticklabels([\"Real (0)\",\"Misinformation (1)\"])\n",
        "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
        "    ax.set_title(title)\n",
        "    return cm\n",
        "\n",
        "cm_records = []  # rows -> Model, Split, TN, FP, FN, TP, Attack\n",
        "\n",
        "for _, row in worst_attacks.iterrows():\n",
        "    model_name = row[\"Model\"]; worst_attack = row[\"Attack\"]; worst_group = row[\"Group\"]\n",
        "    # find perturbed file\n",
        "    atk_path = _find_attack_file(worst_attack)\n",
        "    if atk_path is None:\n",
        "        print(f\"[warn] Could not find perturbed CSV for attack '{worst_attack}'. Skipping CM plot for {model_name}.\")\n",
        "        continue\n",
        "    df_attack = _read_csv(atk_path)\n",
        "    if df_attack is None or TEXT_COL not in df_attack.columns or LABEL_COL not in df_attack.columns:\n",
        "        print(f\"[warn] Bad attack CSV for '{worst_attack}'. Skipping {model_name}.\")\n",
        "        continue\n",
        "\n",
        "    # predictions\n",
        "    y_true_clean = test_df[LABEL_COL].astype(int).values\n",
        "    if model_name == \"XLM-R Only\":\n",
        "        y_pred_clean = preds_xlmr(test_df)\n",
        "        y_pred_attack = preds_xlmr(df_attack)\n",
        "    elif model_name == \"XGBoost + Features\":\n",
        "        y_pred_clean = preds_xgb(test_df)\n",
        "        y_pred_attack = preds_xgb(df_attack)\n",
        "    elif model_name == \"Simple Fusion\":\n",
        "        y_pred_clean = preds_fusion(test_df, simple_scaler, simple)\n",
        "        y_pred_attack = preds_fusion(df_attack, simple_scaler, simple)\n",
        "    else:  # Gated Fusion\n",
        "        y_pred_clean = preds_fusion(test_df, gated_scaler, gated)\n",
        "        y_pred_attack = preds_fusion(df_attack, gated_scaler, gated)\n",
        "\n",
        "    # plot side-by-side\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(10, 4.5), constrained_layout=True)\n",
        "    cm_clean  = plot_cm(axes[0], y_true_clean, y_pred_clean, title=f\"{model_name} — Clean\")\n",
        "    cm_attack = plot_cm(axes[1], df_attack[LABEL_COL].astype(int).values, y_pred_attack,\n",
        "                        title=f\"{model_name} — Worst: {worst_group}\\n({worst_attack})\")\n",
        "    out_png = os.path.join(FIG_DIR, f\"cm_{re.sub(r'[^A-Za-z0-9_.-]+','_',model_name)}_clean_vs_{_norm(worst_attack)}.png\")\n",
        "    plt.savefig(out_png, dpi=DPI)\n",
        "    plt.show()\n",
        "    print(\"Saved:\", out_png)\n",
        "\n",
        "    # store counts\n",
        "    TN, FP, FN, TP = cm_clean[0,0], cm_clean[0,1], cm_clean[1,0], cm_clean[1,1]\n",
        "    cm_records.append([model_name, \"Clean\", worst_group, worst_attack, TN, FP, FN, TP])\n",
        "    TN, FP, FN, TP = cm_attack[0,0], cm_attack[0,1], cm_attack[1,0], cm_attack[1,1]\n",
        "    cm_records.append([model_name, \"Worst\", worst_group, worst_attack, TN, FP, FN, TP])\n",
        "\n",
        "# save CM counts\n",
        "cm_df = pd.DataFrame(cm_records, columns=[\"Model\",\"Split\",\"Group\",\"Attack\",\"TN\",\"FP\",\"FN\",\"TP\"])\n",
        "cm_csv = os.path.join(FIG_DIR, \"cm_counts.csv\")\n",
        "cm_df.to_csv(cm_csv, index=False)\n",
        "print(\"Saved:\", cm_csv)\n",
        "\n",
        "# ---------------- Resource / Latency Footprint ----------------\n",
        "# Count parameters (DL); approximate XGB \"params\" via total tree nodes (booster.trees_to_dataframe)\n",
        "def count_params_torch(model: nn.Module) -> int:\n",
        "    return int(sum(p.numel() for p in model.parameters()))\n",
        "\n",
        "def xgb_node_count(xgb_clf) -> int:\n",
        "    try:\n",
        "        df = xgb_clf.get_booster().trees_to_dataframe()\n",
        "        return int(df.shape[0])  # nodes = rows\n",
        "    except Exception:\n",
        "        # fallback: unknown\n",
        "        return np.nan\n",
        "\n",
        "# Measure latency & VRAM (GPU) @ inference on clean test set\n",
        "def measure_latency_and_vram(model_kind: str):\n",
        "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "    start = time.perf_counter()\n",
        "    peak_vram_mb = 0.0\n",
        "\n",
        "    if model_kind == \"XLM-R Only\":\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.reset_peak_memory_stats()\n",
        "        _ = preds_xlmr(test_df)  # runs full test set\n",
        "        if torch.cuda.is_available():\n",
        "            peak_vram_mb = torch.cuda.max_memory_allocated() / (1024**2)\n",
        "        elapsed = time.perf_counter() - start\n",
        "        ms_per_doc = 1000.0 * elapsed / max(1, len(test_df))\n",
        "\n",
        "    elif model_kind == \"Simple Fusion\":\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.reset_peak_memory_stats()\n",
        "        _ = preds_fusion(test_df, simple_scaler, simple)\n",
        "        if torch.cuda.is_available():\n",
        "            peak_vram_mb = torch.cuda.max_memory_allocated() / (1024**2)\n",
        "        elapsed = time.perf_counter() - start\n",
        "        ms_per_doc = 1000.0 * elapsed / max(1, len(test_df))\n",
        "\n",
        "    elif model_kind == \"Gated Fusion\":\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.reset_peak_memory_stats()\n",
        "        _ = preds_fusion(test_df, gated_scaler, gated)\n",
        "        if torch.cuda.is_available():\n",
        "            peak_vram_mb = torch.cuda.max_memory_allocated() / (1024**2)\n",
        "        elapsed = time.perf_counter() - start\n",
        "        ms_per_doc = 1000.0 * elapsed / max(1, len(test_df))\n",
        "\n",
        "    else:  # XGB (CPU)\n",
        "        start = time.perf_counter()\n",
        "        _ = preds_xgb(test_df)\n",
        "        elapsed = time.perf_counter() - start\n",
        "        ms_per_doc = 1000.0 * elapsed / max(1, len(test_df))\n",
        "        peak_vram_mb = 0.0  # GPU VRAM not used\n",
        "\n",
        "    return ms_per_doc, peak_vram_mb\n",
        "\n",
        "# Compute table\n",
        "import xgboost as xgb\n",
        "foot_rows = []\n",
        "\n",
        "# XGB\n",
        "xgb_params = xgb_node_count(xgb_model)\n",
        "xgb_ms, xgb_vram = measure_latency_and_vram(\"XGBoost + Features\")\n",
        "foot_rows.append([\"XGBoost + Features\", xgb_params, xgb_vram, xgb_ms])\n",
        "\n",
        "# XLM-R\n",
        "xlmr_params = count_params_torch(xlmr)\n",
        "xlmr_ms, xlmr_vram = measure_latency_and_vram(\"XLM-R Only\")\n",
        "foot_rows.append([\"XLM-R Only\", xlmr_params, xlmr_vram, xlmr_ms])\n",
        "\n",
        "# Simple\n",
        "simple_params = count_params_torch(simple)\n",
        "simple_ms, simple_vram = measure_latency_and_vram(\"Simple Fusion\")\n",
        "foot_rows.append([\"Simple Fusion\", simple_params, simple_vram, simple_ms])\n",
        "\n",
        "# Gated\n",
        "gated_params = count_params_torch(gated)\n",
        "gated_ms, gated_vram = measure_latency_and_vram(\"Gated Fusion\")\n",
        "foot_rows.append([\"Gated Fusion\", gated_params, gated_vram, gated_ms])\n",
        "\n",
        "foot = pd.DataFrame(foot_rows, columns=[\"Model\",\"Params\",\"Peak VRAM (MB)\",\"Latency (ms/doc)\"])\n",
        "# Convert Params to \"M\" for plotting readability\n",
        "foot[\"Params (M)\"] = foot[\"Params\"] / 1_000_000.0\n",
        "foot_csv = os.path.join(FIG_DIR, \"footprint_table.csv\")\n",
        "foot.to_csv(foot_csv, index=False)\n",
        "print(\"Saved:\", foot_csv)\n",
        "print(foot)\n",
        "\n",
        "# Plot bars (three aligned subplots)\n",
        "fig, axes = plt.subplots(1, 3, figsize=(13.5, 4.2), constrained_layout=True)\n",
        "# Params\n",
        "axes[0].bar(foot[\"Model\"], foot[\"Params (M)\"], color=[MODEL_COLORS.get(m, \"tab:gray\") for m in foot[\"Model\"]])\n",
        "axes[0].set_title(\"Parameters (Millions)\"); axes[0].set_ylabel(\"M parameters\")\n",
        "axes[0].tick_params(axis='x', rotation=20)\n",
        "# VRAM\n",
        "axes[1].bar(foot[\"Model\"], foot[\"Peak VRAM (MB)\"], color=[MODEL_COLORS.get(m, \"tab:gray\") for m in foot[\"Model\"]])\n",
        "axes[1].set_title(\"Peak VRAM during Inference\"); axes[1].set_ylabel(\"MB\")\n",
        "axes[1].tick_params(axis='x', rotation=20)\n",
        "# Latency\n",
        "axes[2].bar(foot[\"Model\"], foot[\"Latency (ms/doc)\"], color=[MODEL_COLORS.get(m, \"tab:gray\") for m in foot[\"Model\"]])\n",
        "axes[2].set_title(\"Latency per Document\"); axes[2].set_ylabel(\"ms / doc\")\n",
        "axes[2].tick_params(axis='x', rotation=20)\n",
        "\n",
        "for ax in axes:\n",
        "    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
        "\n",
        "out_png = os.path.join(FIG_DIR, \"footprint_bars.png\")\n",
        "plt.savefig(out_png, dpi=DPI)\n",
        "plt.show()\n",
        "print(\"Saved:\", out_png)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "HXbPurNL6nmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Clean vs After-Attack Macro-F1 per model (aggregated over all attacks) ---\n",
        "\n",
        "import os, glob, numpy as np, pandas as pd\n",
        "\n",
        "BASE_DIR   = \"/content/drive/MyDrive/emc\"\n",
        "ADV_DIR    = os.path.join(BASE_DIR, \"adv_eval_outputs\")\n",
        "CLEAN_CSV  = os.path.join(ADV_DIR, \"clean_eval.csv\")\n",
        "ADV_GLOB   = os.path.join(ADV_DIR, \"adversarial_eval*.csv\")\n",
        "OUT_CSV    = os.path.join(ADV_DIR, \"clean_vs_attack_macro_f1_summary.csv\")\n",
        "\n",
        "# Aggregation over all attacks: \"mean\" | \"median\" | \"worst\"\n",
        "AGGREGATOR = \"median\"\n",
        "\n",
        "def _read_csv(p):\n",
        "    try:\n",
        "        return pd.read_csv(p)\n",
        "    except Exception as e:\n",
        "        print(f\"[skip] {os.path.basename(p)}: {e}\")\n",
        "        return None\n",
        "\n",
        "# 1) Load clean Macro-F1 (Attack == Clean)\n",
        "clean_df = _read_csv(CLEAN_CSV)\n",
        "if clean_df is None:\n",
        "    raise FileNotFoundError(f\"Cannot find clean results at: {CLEAN_CSV}\")\n",
        "\n",
        "clean_only = clean_df[clean_df[\"Attack\"].astype(str).str.lower() == \"clean\"].copy()\n",
        "if clean_only.empty:\n",
        "    raise RuntimeError(\"clean_eval.csv has no rows with Attack == 'Clean'.\")\n",
        "\n",
        "clean_only = clean_only[[\"Model\", \"macro_f1\"]].rename(columns={\"macro_f1\": \"Clean Macro F1\"})\n",
        "\n",
        "# 2) Load all adversarial evals\n",
        "adv_frames = []\n",
        "for p in sorted(glob.glob(ADV_GLOB)):\n",
        "    if os.path.basename(p).lower() == \"clean_eval.csv\":\n",
        "        continue\n",
        "    dfp = _read_csv(p)\n",
        "    if dfp is None:\n",
        "        continue\n",
        "    if not {\"Model\",\"Attack\",\"macro_f1\"}.issubset(dfp.columns):\n",
        "        print(f\"[warn] Missing required cols in {p}, skipping.\")\n",
        "        continue\n",
        "    adv_frames.append(dfp[[\"Model\",\"Attack\",\"macro_f1\"]])\n",
        "\n",
        "if not adv_frames:\n",
        "    raise RuntimeError(\"No adversarial_eval*.csv files found (or all unreadable).\")\n",
        "\n",
        "adv_all = pd.concat(adv_frames, ignore_index=True)\n",
        "# Filter out any accidental 'Clean' rows that slipped into adversarial files\n",
        "adv_all = adv_all[adv_all[\"Attack\"].astype(str).str.lower() != \"clean\"].copy()\n",
        "\n",
        "# 3) Aggregate per model across ALL attacks\n",
        "if AGGREGATOR == \"mean\":\n",
        "    agg = adv_all.groupby(\"Model\", as_index=False)[\"macro_f1\"].mean()\n",
        "elif AGGREGATOR == \"median\":\n",
        "    agg = adv_all.groupby(\"Model\", as_index=False)[\"macro_f1\"].median()\n",
        "elif AGGREGATOR == \"worst\":\n",
        "    agg = adv_all.groupby(\"Model\", as_index=False)[\"macro_f1\"].min()\n",
        "else:\n",
        "    raise ValueError(\"AGGREGATOR must be one of: 'mean', 'median', 'worst'.\")\n",
        "\n",
        "agg = agg.rename(columns={\"macro_f1\": \"After-Attack Macro F1\"})\n",
        "\n",
        "# 4) Merge with clean and compute drops\n",
        "summary = clean_only.merge(agg, on=\"Model\", how=\"inner\")\n",
        "summary[\"Δ (Drop)\"]  = summary[\"Clean Macro F1\"] - summary[\"After-Attack Macro F1\"]\n",
        "summary[\"Δ%\"]        = 100.0 * summary[\"Δ (Drop)\"] / summary[\"Clean Macro F1\"].replace(0.0, np.nan)\n",
        "\n",
        "# 5) Sort (largest drop first for diagnostic readability)\n",
        "summary = summary.sort_values(\"Δ (Drop)\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "# 6) Round for display, but keep unrounded copy if you need\n",
        "display_df = summary.copy()\n",
        "for col in [\"Clean Macro F1\", \"After-Attack Macro F1\", \"Δ (Drop)\", \"Δ%\"]:\n",
        "    display_df[col] = display_df[col].astype(float).round(4)\n",
        "\n",
        "print(f\"\\n--- Clean vs After-Attack Macro-F1 (aggregator = {AGGREGATOR}) ---\")\n",
        "print(display_df.to_string(index=False))\n",
        "\n",
        "# 7) Save CSV\n",
        "summary.to_csv(OUT_CSV, index=False)\n",
        "print(\"\\nSaved (full precision):\", OUT_CSV)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qgzTK7WqB_eQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 1: Config & Group definitions ---\n",
        "\n",
        "import os, re, glob, difflib, json, numpy as np, pandas as pd\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class CFG:\n",
        "    BASE_DIR: str = \"/content/drive/MyDrive/emc\"\n",
        "    TEST_CSV: str = \"/content/drive/MyDrive/emc/test.csv\"\n",
        "    TERMS_CSV: str = \"/content/drive/MyDrive/emc/engineering_terms.csv\"\n",
        "\n",
        "    # Model artifact dirs\n",
        "    XGB_DIR: str    = \"/content/drive/MyDrive/emc/xgb_outputs_clean\"\n",
        "    XLMR_DIR: str   = \"/content/drive/MyDrive/emc/xlmr_only_outputs_clean\"\n",
        "    SIMPLE_DIR: str = \"/content/drive/MyDrive/emc/simple_fusion_outputs_clean\"\n",
        "    GATED_DIR: str  = \"/content/drive/MyDrive/emc/gated_fusion_outputs_clean\"\n",
        "\n",
        "    # Adversarial inputs & outputs\n",
        "    ADV_DIR: str    = \"/content/drive/MyDrive/emc/adv_eval_outputs\"\n",
        "    PERT_DIR: str   = \"/content/drive/MyDrive/emc/adv_eval_outputs/perturbed\"\n",
        "    OUT_DIR: str    = \"/content/drive/MyDrive/emc/adv_eval_outputs/grouped_eval\"\n",
        "\n",
        "    TEXT_COL: str = \"content\"\n",
        "    LABEL_COL: str = \"label\"\n",
        "    LANG_COL: str  = \"lang\"\n",
        "    ID_COL: str    = \"id\"\n",
        "\n",
        "    MAX_LEN: int = 256\n",
        "    BATCH_SIZE: int = 32\n",
        "    N_FEATS: int = 12\n",
        "    POS_LABEL: int = 1   # 1 = Misinformation\n",
        "\n",
        "    DPI: int = 600\n",
        "    AGGREGATOR: str = \"mean\"    # \"mean\" | \"median\" | \"worst\"\n",
        "\n",
        "cfg = CFG()\n",
        "os.makedirs(cfg.OUT_DIR, exist_ok=True)\n",
        "\n",
        "# ********** GROUPS (3 big buckets) **********\n",
        "# Map each atomic attack (normalized name) to one of 3 groups.\n",
        "def _norm(s: str) -> str:\n",
        "    s = str(s).lower()\n",
        "    s = re.sub(r\"[\\s\\-\\/]+\", \"_\", s)    # space/hyphen/slash -> underscore\n",
        "    s = re.sub(r\"[^a-z0-9_]+\", \"\", s)   # drop other non-alnum\n",
        "    return s\n",
        "\n",
        "GROUP_MAP = {\n",
        "    # Structural\n",
        "    _norm(\"CharSwap\"): \"Structural\",\n",
        "    _norm(\"CaseToggle\"): \"Structural\",\n",
        "    _norm(\"PunctInsert\"): \"Structural\",\n",
        "    _norm(\"WhitespaceNoise\"): \"Structural\",\n",
        "    _norm(\"UnicodeConfuse\"): \"Structural\",\n",
        "    _norm(\"SymbolAscii\"): \"Structural\",\n",
        "    _norm(\"Truncate80w\"): \"Structural\",\n",
        "\n",
        "    # Semantic/Cue\n",
        "    _norm(\"MaskDomainTerms\"): \"Semantic/Cue\",\n",
        "    _norm(\"DropDomainTerms\"): \"Semantic/Cue\",\n",
        "    _norm(\"SynonymSwapDomain\"): \"Semantic/Cue\",\n",
        "    _norm(\"AcronymPerturb\"): \"Semantic/Cue\",\n",
        "    _norm(\"CitationStrip\"): \"Semantic/Cue\",\n",
        "\n",
        "    # Feature-Targeted\n",
        "    _norm(\"NumberPerturb\"): \"Feature-Targeted\",\n",
        "    _norm(\"StandardNumCorrupt\"): \"Feature-Targeted\",\n",
        "    _norm(\"UnitNeutralizeMask\"): \"Feature-Targeted\",\n",
        "    _norm(\"UnitNeutralizeDrop\"): \"Feature-Targeted\",\n",
        "    _norm(\"UnitNeutralizeGeneric\"): \"Feature-Targeted\",\n",
        "\n",
        "    # Aliases seen in your runs\n",
        "    _norm(\"Numbers/Units\"): \"Feature-Targeted\",\n",
        "    _norm(\"Unit Conversion (NEW)\"): \"Feature-Targeted\",\n",
        "    _norm(\"DomainCombo1\"): \"Semantic/Cue\",\n",
        "    _norm(\"DomainCombo2\"): \"Semantic/Cue\",\n",
        "    _norm(\"DomainCombo3\"): \"Semantic/Cue\",\n",
        "    _norm(\"DomainMax\"):   \"Semantic/Cue\",\n",
        "}\n",
        "\n",
        "MODELS = [\"XLM-R Only\", \"XGBoost + Features\", \"Simple Fusion\", \"Gated Fusion\"]\n",
        "MODEL_COLORS = {\n",
        "    \"XGBoost + Features\": \"tab:blue\",\n",
        "    \"XLM-R Only\":         \"tab:red\",\n",
        "    \"Simple Fusion\":      \"tab:green\",\n",
        "    \"Gated Fusion\":       \"tab:orange\",\n",
        "}\n"
      ],
      "metadata": {
        "id": "BKblnzNtPdyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 2: Utilities, features, loaders, heads ---\n",
        "\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    XLMRobertaTokenizerFast, XLMRobertaForSequenceClassification,\n",
        "    XLMRobertaModel, DataCollatorWithPadding\n",
        ")\n",
        "import joblib, xgboost as xgb\n",
        "from sklearn.metrics import f1_score, roc_auc_score, average_precision_score, roc_curve, precision_recall_curve\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ---------- Feature extractor (12-D) ----------\n",
        "import re\n",
        "_WORD_RE = re.compile(r\"\\w+\", re.UNICODE)\n",
        "_NUM_RE  = re.compile(r'[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?')\n",
        "STD_TERMS = {\"iso\",\"asme\",\"ieee\",\"din\",\"ansi\",\"iec\",\"ul\",\"astm\",\"en\"}\n",
        "SAFETY_TERMS = {\"safety\",\"hazard\",\"warning\",\"risk\",\"caution\",\"danger\",\"emergency\"}\n",
        "\n",
        "def simple_words(t: str): return _WORD_RE.findall(t or \"\")\n",
        "def sent_count(t: str) -> int:\n",
        "    if not t: return 0\n",
        "    return max(1, len(re.split(r'[.!?]+[\\s\\n]+', t)))\n",
        "def punct_count(t: str) -> int: return sum(1 for ch in (t or \"\") if ch in \".,;:!?\")\n",
        "def extract_numbers(text: str):\n",
        "    nums, dec = [], 0\n",
        "    for m in _NUM_RE.finditer(text or \"\"):\n",
        "        s = m.group(0)\n",
        "        try:\n",
        "            v = float(s)\n",
        "            if ('.' in s) or ('e' in s.lower()): dec += 1\n",
        "            nums.append(abs(v))\n",
        "        except: pass\n",
        "    return nums, dec\n",
        "def _finite_or_zero(x: float):\n",
        "    try:\n",
        "        xx = float(x)\n",
        "        return xx if np.isfinite(xx) else 0.0\n",
        "    except: return 0.0\n",
        "\n",
        "class TermsLexicon:\n",
        "    def __init__(self, csv_path: str, term_col=\"terms\", lang_col=\"lang\"):\n",
        "        df = pd.read_csv(csv_path)\n",
        "        if term_col not in df.columns: raise ValueError(f\"Missing '{term_col}'\")\n",
        "        if lang_col not in df.columns: df[lang_col] = 'en'\n",
        "        self.by_lang = {str(l).lower(): set(str(x).strip().lower()\n",
        "                         for x in d[term_col].dropna().tolist() if str(x).strip())\n",
        "                        for l, d in df.groupby(lang_col)}\n",
        "    def pct_in_text(self, text: str, lang: str) -> float:\n",
        "        terms = self.by_lang.get((lang or \"en\").lower(), set())\n",
        "        if not terms: return 0.0\n",
        "        ws = [w.lower() for w in simple_words(text)]\n",
        "        return sum(1 for w in ws if w in terms) / max(1, len(ws)) if ws else 0.0\n",
        "\n",
        "class FeatureExtractor12:\n",
        "    def __init__(self, tlex: TermsLexicon): self.tlex = tlex\n",
        "    def extract_one(self, text: str, lang: str):\n",
        "        text = \"\" if text is None else str(text); lang = (lang or \"en\").lower()\n",
        "        ws = simple_words(text); n_words = len(ws)\n",
        "        chars = len(text); words = n_words; sents = sent_count(text)\n",
        "        fre, fog = 0.0, 0.0\n",
        "        eng_pct = self.tlex.pct_in_text(text, lang)\n",
        "        punc = punct_count(text)\n",
        "        nums, dec_cnt = extract_numbers(text); nnums = len(nums)\n",
        "        avg_mag = float(np.mean(nums)) if nums else 0.0\n",
        "        dec_ratio = float(dec_cnt / max(1, len(nums)))\n",
        "        low = text.lower()\n",
        "        has_std = 1.0 if any(t in low for t in STD_TERMS) else 0.0\n",
        "        has_saf = 1.0 if any(t in low for t in SAFETY_TERMS) else 0.0\n",
        "        vals = [chars, words, sents, fre, fog, eng_pct, punc, nnums, has_std, has_saf, avg_mag, dec_ratio]\n",
        "        arr = np.asarray([_finite_or_zero(v) for v in vals], dtype=np.float64)\n",
        "        arr = np.nan_to_num(arr, nan=0.0, posinf=1e12, neginf=0.0)\n",
        "        return np.clip(arr, -1e12, 1e12).astype(np.float32)\n",
        "    def extract_df(self, df):\n",
        "        local = df if cfg.LANG_COL in df.columns else df.assign(**{cfg.LANG_COL:'en'})\n",
        "        rows = [self.extract_one(r.get(cfg.TEXT_COL,\"\"), r.get(cfg.LANG_COL,\"en\")) for _, r in local.iterrows()]\n",
        "        return np.stack(rows, axis=0).astype(np.float32)\n",
        "\n",
        "lex = TermsLexicon(cfg.TERMS_CSV)\n",
        "fe  = FeatureExtractor12(lex)\n",
        "\n",
        "# ---------- Datasets ----------\n",
        "class TextOnlyDS(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_len=256):\n",
        "        self.texts = df[cfg.TEXT_COL].astype(str).tolist()\n",
        "        self.labels = df[cfg.LABEL_COL].astype(int).values\n",
        "        self.tok = tokenizer; self.max_len = max_len\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, i):\n",
        "        enc = self.tok(self.texts[i], truncation=True, padding=False,\n",
        "                       max_length=self.max_len, return_tensors=\"pt\")\n",
        "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
        "        item[\"labels\"] = torch.tensor(int(self.labels[i]), dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "class TextFeatDS(Dataset):\n",
        "    def __init__(self, df, tokenizer, feats_scaled, max_len=256):\n",
        "        self.texts = df[cfg.TEXT_COL].astype(str).tolist()\n",
        "        self.labels = df[cfg.LABEL_COL].astype(int).values\n",
        "        self.tok = tokenizer; self.max_len = max_len\n",
        "        self.feats = feats_scaled.astype(np.float32)\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, i):\n",
        "        enc = self.tok(self.texts[i], truncation=True, padding=\"max_length\",\n",
        "                       max_length=self.max_len, return_tensors=\"pt\")\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(int(self.labels[i]), dtype=torch.long),\n",
        "            \"feats\": torch.tensor(self.feats[i], dtype=torch.float32),\n",
        "        }\n",
        "\n",
        "# ---------- Fusion heads ----------\n",
        "class SimpleFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + n_feats, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (out.last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "        fused = torch.cat([pooled, feats], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "\n",
        "class GatedFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2, feat_proj: int = 64):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.fe_proj = nn.Sequential(nn.Linear(n_feats, feat_proj), nn.ReLU())\n",
        "        self.gate    = nn.Sequential(nn.Linear(H + n_feats, 64), nn.ReLU(), nn.Linear(64, 1), nn.Sigmoid())\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + feat_proj, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (out.last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "        alpha = self.gate(torch.cat([pooled, feats], dim=1))\n",
        "        ef    = self.fe_proj(feats)\n",
        "        fused = torch.cat([pooled, alpha * ef], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "\n",
        "# ---------- Load artifacts ----------\n",
        "tok = XLMRobertaTokenizerFast.from_pretrained(cfg.XLMR_DIR)\n",
        "collator = DataCollatorWithPadding(tok)\n",
        "\n",
        "# XGB\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "xgb_model.load_model(os.path.join(cfg.XGB_DIR, \"xgb_model.json\"))\n",
        "xgb_scaler = joblib.load(os.path.join(cfg.XGB_DIR, \"scaler12.pkl\"))\n",
        "\n",
        "# XLM-R\n",
        "xlmr = XLMRobertaForSequenceClassification.from_pretrained(cfg.XLMR_DIR).to(device)\n",
        "xlmr.eval()\n",
        "\n",
        "# Simple Fusion\n",
        "simple = SimpleFusion(\"xlm-roberta-base\", cfg.N_FEATS, 2).to(device)\n",
        "simple.load_state_dict(torch.load(os.path.join(cfg.SIMPLE_DIR, \"fusion_simple.pt\"), map_location=device), strict=False)\n",
        "simple.eval()\n",
        "simple_scaler = joblib.load(os.path.join(cfg.SIMPLE_DIR, \"scaler12.pkl\"))\n",
        "\n",
        "# Gated Fusion\n",
        "gated = GatedFusion(\"xlm-roberta-base\", cfg.N_FEATS, 2, feat_proj=64).to(device)\n",
        "gated.load_state_dict(torch.load(os.path.join(cfg.GATED_DIR, \"fusion_gated.pt\"), map_location=device), strict=False)\n",
        "gated.eval()\n",
        "gated_scaler = joblib.load(os.path.join(cfg.GATED_DIR, \"scaler12.pkl\"))\n",
        "\n",
        "# ---------- Metrics helpers ----------\n",
        "@torch.no_grad()\n",
        "def eval_xlmr(df):\n",
        "    ds = TextOnlyDS(df, tok, cfg.MAX_LEN)\n",
        "    dl = DataLoader(ds, batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
        "    probs = []\n",
        "    for b in dl:\n",
        "        inp = {k: v.to(device) for k, v in b.items() if k in (\"input_ids\",\"attention_mask\")}\n",
        "        logits = xlmr(**inp).logits\n",
        "        pr = torch.softmax(logits, dim=-1)[:, cfg.POS_LABEL].cpu().numpy()\n",
        "        probs.append(pr)\n",
        "    y_prob = np.concatenate(probs)\n",
        "    y_pred = (y_prob >= 0.5).astype(int)\n",
        "    y_true = df[cfg.LABEL_COL].astype(int).values\n",
        "    return y_true, y_pred, y_prob\n",
        "\n",
        "def eval_xgb(df):\n",
        "    X = fe.extract_df(df); Xs = xgb_scaler.transform(X)\n",
        "    y_prob = xgb_model.predict_proba(Xs)[:, cfg.POS_LABEL]\n",
        "    y_pred = (y_prob >= 0.5).astype(int)\n",
        "    y_true = df[cfg.LABEL_COL].astype(int).values\n",
        "    return y_true, y_pred, y_prob\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_fusion(df, scaler, model):\n",
        "    X = fe.extract_df(df); Xs = scaler.transform(X).astype(np.float32)\n",
        "    ds = TextFeatDS(df, tok, Xs, cfg.MAX_LEN)\n",
        "    dl = DataLoader(ds, batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
        "    probs = []\n",
        "    for b in dl:\n",
        "        ids = b[\"input_ids\"].to(device); am = b[\"attention_mask\"].to(device); ft = b[\"feats\"].to(device)\n",
        "        logits = model(ids, am, ft)\n",
        "        pr = torch.softmax(logits, dim=-1)[:, cfg.POS_LABEL].cpu().numpy()\n",
        "        probs.append(pr)\n",
        "    y_prob = np.concatenate(probs)\n",
        "    y_pred = (y_prob >= 0.5).astype(int)\n",
        "    y_true = df[cfg.LABEL_COL].astype(int).values\n",
        "    return y_true, y_pred, y_prob\n",
        "\n",
        "def metrics_from(y_true, y_pred, y_prob):\n",
        "    out = {}\n",
        "    out[\"macro_f1\"] = f1_score(y_true, y_pred, average=\"macro\")\n",
        "    out[\"micro_f1\"] = f1_score(y_true, y_pred, average=\"micro\")\n",
        "    out[\"weighted_f1\"] = f1_score(y_true, y_pred, average=\"weighted\")\n",
        "    # Safe AUC/AP (guard degenerate)\n",
        "    try: out[\"auc_roc\"] = roc_auc_score(y_true, y_prob)\n",
        "    except: out[\"auc_roc\"] = np.nan\n",
        "    try: out[\"ap\"] = average_precision_score(y_true, y_prob)\n",
        "    except: out[\"ap\"] = np.nan\n",
        "    # FPR at 95% TPR\n",
        "    try:\n",
        "        fpr, tpr, thr = roc_curve(y_true, y_prob)\n",
        "        target = 0.95\n",
        "        mask = tpr >= target\n",
        "        out[\"fpr_at_95tpr\"] = float(np.min(fpr[mask])) if np.any(mask) else np.nan\n",
        "    except:\n",
        "        out[\"fpr_at_95tpr\"] = np.nan\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "jsBsP-hGPiuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 3: Evaluate clean baseline for all models ---\n",
        "\n",
        "test_df = pd.read_csv(cfg.TEST_CSV)\n",
        "assert cfg.TEXT_COL in test_df.columns and cfg.LABEL_COL in test_df.columns, \"Missing content/label columns.\"\n",
        "\n",
        "rows = []\n",
        "for model_name in MODELS:\n",
        "    if model_name == \"XLM-R Only\":\n",
        "        y_true, y_pred, y_prob = eval_xlmr(test_df)\n",
        "    elif model_name == \"XGBoost + Features\":\n",
        "        y_true, y_pred, y_prob = eval_xgb(test_df)\n",
        "    elif model_name == \"Simple Fusion\":\n",
        "        y_true, y_pred, y_prob = eval_fusion(test_df, simple_scaler, simple)\n",
        "    else:\n",
        "        y_true, y_pred, y_prob = eval_fusion(test_df, gated_scaler, gated)\n",
        "\n",
        "    m = metrics_from(y_true, y_pred, y_prob)\n",
        "    rows.append({\"Model\": model_name, \"Attack\": \"Clean\", **m})\n",
        "\n",
        "clean_df = pd.DataFrame(rows)\n",
        "clean_path = os.path.join(cfg.OUT_DIR, \"clean_eval_grouped.csv\")\n",
        "clean_df.to_csv(clean_path, index=False)\n",
        "print(\"Saved:\", clean_path)\n",
        "clean_df\n"
      ],
      "metadata": {
        "id": "R7byKA0NQJzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block 4: Per-attack eval -> Group aggregation ---\n",
        "\n",
        "# Find a perturbed CSV for an attack name (fuzzy)\n",
        "def find_attack_csv(attack_name: str):\n",
        "    # try exact and normalized variants\n",
        "    cands = [\n",
        "        os.path.join(cfg.PERT_DIR, f\"{attack_name}.csv\"),\n",
        "        os.path.join(cfg.PERT_DIR, f\"{_norm(attack_name)}.csv\"),\n",
        "        os.path.join(cfg.PERT_DIR, attack_name, \"dataset.csv\"),\n",
        "        os.path.join(cfg.PERT_DIR, f\"{attack_name}_test.csv\"),\n",
        "    ]\n",
        "    for p in cands:\n",
        "        if os.path.exists(p): return p\n",
        "    # fuzzy: scan all CSVs once\n",
        "    pool = glob.glob(os.path.join(cfg.PERT_DIR, \"**\", \"*.csv\"), recursive=True)\n",
        "    if not pool: return None\n",
        "    stems = {p: os.path.splitext(os.path.basename(p))[0] for p in pool}\n",
        "    names = list(stems.values())\n",
        "    match = difflib.get_close_matches(attack_name, names, n=1, cutoff=0.55)\n",
        "    if match:\n",
        "        for p, st in stems.items():\n",
        "            if st == match[0]: return p\n",
        "    # substring fallback\n",
        "    for p, st in stems.items():\n",
        "        if _norm(attack_name) in _norm(st) or _norm(st) in _norm(attack_name):\n",
        "            return p\n",
        "    return None\n",
        "\n",
        "# Collect ALL candidate attacks from the mapping (keys) that we can find on disk\n",
        "attack_norms = sorted(set(GROUP_MAP.keys()))\n",
        "attack_rows = []\n",
        "\n",
        "for a_norm in attack_norms:\n",
        "    csv_path = find_attack_csv(a_norm)\n",
        "    if not csv_path:\n",
        "        print(f\"[skip] No file for attack: {a_norm}\")\n",
        "        continue\n",
        "\n",
        "    atk_df = pd.read_csv(csv_path)\n",
        "    if cfg.TEXT_COL not in atk_df.columns or cfg.LABEL_COL not in atk_df.columns:\n",
        "        print(f\"[skip] Missing columns in {os.path.basename(csv_path)}\")\n",
        "        continue\n",
        "\n",
        "    group = GROUP_MAP.get(a_norm, \"Unassigned\")\n",
        "    # evaluate each model\n",
        "    for model_name in MODELS:\n",
        "        if model_name == \"XLM-R Only\":\n",
        "            y_true, y_pred, y_prob = eval_xlmr(atk_df)\n",
        "        elif model_name == \"XGBoost + Features\":\n",
        "            y_true, y_pred, y_prob = eval_xgb(atk_df)\n",
        "        elif model_name == \"Simple Fusion\":\n",
        "            y_true, y_pred, y_prob = eval_fusion(atk_df, simple_scaler, simple)\n",
        "        else:\n",
        "            y_true, y_pred, y_prob = eval_fusion(atk_df, gated_scaler, gated)\n",
        "\n",
        "        m = metrics_from(y_true, y_pred, y_prob)\n",
        "        attack_rows.append({\n",
        "            \"Model\": model_name,\n",
        "            \"Attack\": a_norm,\n",
        "            \"Group\": group,\n",
        "            **m\n",
        "        })\n",
        "\n",
        "atk_eval = pd.DataFrame(attack_rows)\n",
        "raw_path = os.path.join(cfg.OUT_DIR, \"per_attack_eval_raw.csv\")\n",
        "atk_eval.to_csv(raw_path, index=False)\n",
        "print(\"Saved:\", raw_path)\n",
        "atk_eval.head()\n"
      ],
      "metadata": {
        "id": "1CXIhif7QtSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NEW-DEBUGGING ATTACKS"
      ],
      "metadata": {
        "id": "OVFh7hQyR3zC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block GA-1: Generate perturbed datasets + coverage summary ---\n",
        "\n",
        "import os, re, glob, random, difflib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------- Config ----------------\n",
        "BASE_DIR   = \"/content/drive/MyDrive/emc\"\n",
        "TEST_CSV   = os.path.join(BASE_DIR, \"test.csv\")\n",
        "TERMS_CSV  = os.path.join(BASE_DIR, \"engineering_terms.csv\")\n",
        "\n",
        "ADV_DIR    = os.path.join(BASE_DIR, \"adv_eval_outputs\")\n",
        "PERT_DIR   = os.path.join(ADV_DIR, \"perturbed\")\n",
        "os.makedirs(PERT_DIR, exist_ok=True)\n",
        "\n",
        "TEXT_COL   = \"content\"\n",
        "LABEL_COL  = \"label\"\n",
        "LANG_COL   = \"lang\"\n",
        "ID_COL     = \"id\"\n",
        "\n",
        "SEED       = 1337\n",
        "rng        = np.random.default_rng(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "def _norm(s: str) -> str:\n",
        "    s = str(s).lower()\n",
        "    s = re.sub(r\"[\\s\\-\\/]+\", \"_\", s)\n",
        "    s = re.sub(r\"[^a-z0-9_]+\", \"\", s)\n",
        "    return s\n",
        "\n",
        "# ---------------- Domain resources ----------------\n",
        "# minimal lexicon for domain terms (read from engineering_terms.csv if present)\n",
        "try:\n",
        "    terms_df = pd.read_csv(TERMS_CSV)\n",
        "    if \"terms\" in terms_df.columns:\n",
        "        DOMAIN_TERMS = {str(t).strip().lower() for t in terms_df[\"terms\"].dropna().tolist() if str(t).strip()}\n",
        "    else:\n",
        "        DOMAIN_TERMS = set()\n",
        "except Exception:\n",
        "    DOMAIN_TERMS = set()\n",
        "\n",
        "SAFETY_TERMS = {\"safety\",\"hazard\",\"warning\",\"risk\",\"caution\",\"danger\",\"emergency\"}\n",
        "STD_ACRO = {\"iso\",\"iec\",\"ieee\",\"ansi\",\"asme\",\"astm\",\"din\",\"en\",\"ul\"}  # for acronym perturb + standards corruption\n",
        "ALL_DOMAIN = DOMAIN_TERMS | SAFETY_TERMS | STD_ACRO\n",
        "\n",
        "# Basic synonyms (no WordNet dependency)\n",
        "SYNONYMS = {\n",
        "    \"safety\":\"protection\",\"hazard\":\"danger\",\"warning\":\"alert\",\"risk\":\"threat\",\n",
        "    \"standard\":\"norm\",\"standards\":\"norms\",\"requirement\":\"specification\",\n",
        "    \"failure\":\"fault\",\"error\":\"mistake\",\"probability\":\"likelihood\",\n",
        "    \"temperature\":\"heat\",\"pressure\":\"force\",\"voltage\":\"electric potential\",\n",
        "    \"speed\":\"rate\",\"flow\":\"throughput\"\n",
        "}\n",
        "\n",
        "# Units inventory (short list)\n",
        "UNITS = [\n",
        "    \"m\",\"km\",\"cm\",\"mm\",\"µm\",\"um\",\"nm\",\n",
        "    \"kg\",\"g\",\"mg\",\"µg\",\"ug\",\n",
        "    \"s\",\"ms\",\"µs\",\"us\",\n",
        "    \"A\",\"V\",\"W\",\"J\",\"N\",\"Pa\",\"bar\",\n",
        "    \"°C\",\"C\",\"K\",\n",
        "    \"Hz\",\"kHz\",\"MHz\",\"GHz\",\n",
        "    \"rpm\",\"%\",\n",
        "]\n",
        "\n",
        "# Unicode confusables (small, safe subset)\n",
        "CONFUSE = {\n",
        "    \"a\":\"а\",  # cyrillic a\n",
        "    \"e\":\"ｅ\",  # fullwidth e\n",
        "    \"o\":\"о\",  # cyrillic o\n",
        "    \"c\":\"с\",  # cyrillic c\n",
        "    \"p\":\"р\",  # cyrillic p\n",
        "    \"x\":\"×\",  # multiply sign\n",
        "    \"i\":\"і\",  # ukrainian i\n",
        "    \"y\":\"у\",  # cyrillic u\n",
        "    \"H\":\"Н\",  # cyrillic en\n",
        "}\n",
        "SYMBOL_ASCII = {\n",
        "    \"±\":\"+/-\", \"µ\":\"u\", \"μ\":\"u\", \"×\":\"x\", \"·\":\".\", \"−\":\"-\", \"–\":\"-\", \"—\":\"-\",\n",
        "    \"°\":\"deg\", \"Ω\":\"Ohm\", \"λ\":\"lambda\"\n",
        "}\n",
        "\n",
        "# ---------------- Atomic attacks ----------------\n",
        "def char_swap(text, p=0.02):\n",
        "    cs = list(text)\n",
        "    i = 0\n",
        "    while i < len(cs)-1:\n",
        "        if cs[i].isalpha() and cs[i+1].isalpha() and rng.random() < p:\n",
        "            cs[i], cs[i+1] = cs[i+1], cs[i]\n",
        "            i += 2\n",
        "        else:\n",
        "            i += 1\n",
        "    return \"\".join(cs)\n",
        "\n",
        "def case_toggle(text, p=0.05):\n",
        "    out = []\n",
        "    for ch in text:\n",
        "        if ch.isalpha() and rng.random() < p:\n",
        "            out.append(ch.lower() if ch.isupper() else ch.upper())\n",
        "        else:\n",
        "            out.append(ch)\n",
        "    return \"\".join(out)\n",
        "\n",
        "def punct_insert(text, p=0.02):\n",
        "    punct = [\",\",\".\",\":\",\";\",\"!\",\"?\",\"-\",\"/\"]\n",
        "    out = []\n",
        "    for ch in text:\n",
        "        if ch.isspace() and rng.random() < p:\n",
        "            out.append(random.choice(punct))\n",
        "            out.append(\" \")\n",
        "        out.append(ch)\n",
        "    return \"\".join(out)\n",
        "\n",
        "def whitespace_noise(text, p=0.03):\n",
        "    out = []\n",
        "    for ch in text:\n",
        "        if ch == \" \" and rng.random() < p:\n",
        "            out.append(\"  \")  # double space\n",
        "            if rng.random() < 0.2:\n",
        "                out.append(\"\\n\")\n",
        "        else:\n",
        "            out.append(ch)\n",
        "    return \"\".join(out)\n",
        "\n",
        "def unicode_confuse(text, p=0.03):\n",
        "    out = []\n",
        "    for ch in text:\n",
        "        low = ch\n",
        "        key = ch\n",
        "        # try lowercase first\n",
        "        repl = None\n",
        "        if ch in CONFUSE: repl = CONFUSE[ch]\n",
        "        elif ch.lower() in CONFUSE and rng.random() < p:\n",
        "            repl = CONFUSE[ch.lower()]\n",
        "            if ch.isupper():\n",
        "                repl = repl.upper()\n",
        "        if repl and rng.random() < p:\n",
        "            out.append(repl)\n",
        "        else:\n",
        "            out.append(ch)\n",
        "    return \"\".join(out)\n",
        "\n",
        "def symbol_ascii(text):\n",
        "    return \"\".join(SYMBOL_ASCII.get(ch, ch) for ch in text)\n",
        "\n",
        "def truncate_80w(text, n=80):\n",
        "    words = text.split()\n",
        "    return \" \".join(words[:n])\n",
        "\n",
        "_num_re = re.compile(r'(?P<num>[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?)')\n",
        "def number_perturb(text, low=0.95, high=1.05):\n",
        "    def repl(m):\n",
        "        try:\n",
        "            v = float(m.group(\"num\"))\n",
        "            factor = rng.uniform(low, high)\n",
        "            return f\"{v*factor:.4g}\"\n",
        "        except Exception:\n",
        "            return m.group(0)\n",
        "    return _num_re.sub(repl, text)\n",
        "\n",
        "def mask_domain_terms(text):\n",
        "    ws = re.findall(r\"\\w+|\\W+\", text, flags=re.UNICODE)\n",
        "    out = []\n",
        "    for tok in ws:\n",
        "        if tok.isalnum() and tok.lower() in ALL_DOMAIN:\n",
        "            out.append(\"[TERM]\")\n",
        "        else:\n",
        "            out.append(tok)\n",
        "    return \"\".join(out)\n",
        "\n",
        "def drop_domain_terms(text):\n",
        "    ws = re.findall(r\"\\w+|\\W+\", text, flags=re.UNICODE)\n",
        "    out = []\n",
        "    for tok in ws:\n",
        "        if tok.isalnum() and tok.lower() in ALL_DOMAIN:\n",
        "            continue\n",
        "        out.append(tok)\n",
        "    return \"\".join(out)\n",
        "\n",
        "def synonym_swap_domain(text):\n",
        "    ws = re.findall(r\"\\w+|\\W+\", text, flags=re.UNICODE)\n",
        "    out = []\n",
        "    for tok in ws:\n",
        "        if tok.isalnum():\n",
        "            low = tok.lower()\n",
        "            if low in SYNONYMS:\n",
        "                repl = SYNONYMS[low]\n",
        "                if tok[0].isupper(): repl = repl.capitalize()\n",
        "                out.append(repl)\n",
        "                continue\n",
        "        out.append(tok)\n",
        "    return \"\".join(out)\n",
        "\n",
        "# Standards corruption: keep prefix, fuzz numeric tail\n",
        "_std_pat = re.compile(r'\\b(?P<pfx>(?:ISO|IEC|EN|ASTM|ANSI|IEEE|ASME))\\s*[-:]?\\s*(?P<num>\\d[\\d\\-:\\/]*)', re.IGNORECASE)\n",
        "def standard_num_corrupt(text):\n",
        "    def repl(m):\n",
        "        pfx = m.group(\"pfx\")\n",
        "        num = m.group(\"num\")\n",
        "        if not num: return m.group(0)\n",
        "        # replace digits with '…' (or 'X') but keep separators\n",
        "        obf = re.sub(r'\\d', '…', num)\n",
        "        return f\"{pfx} {obf}\"\n",
        "    return _std_pat.sub(repl, text)\n",
        "\n",
        "# Unit neutralization\n",
        "_units_alt = sorted(UNITS, key=len, reverse=True)\n",
        "_units_re = re.compile(r'\\b(' + \"|\".join(re.escape(u) for u in _units_alt) + r')\\b')\n",
        "\n",
        "def unit_mask(text):\n",
        "    return _units_re.sub(\"[UNIT]\", text)\n",
        "\n",
        "def unit_drop(text):\n",
        "    return _units_re.sub(\"\", text)\n",
        "\n",
        "def unit_generic(text):\n",
        "    return _units_re.sub(\"unit\", text)\n",
        "\n",
        "# Acronym perturbation\n",
        "def acronym_perturb(text):\n",
        "    def repl(m):\n",
        "        acr = m.group(0)\n",
        "        low = acr.lower()\n",
        "        if rng.random() < 0.5:\n",
        "            return \".\".join(list(acr)) + \".\"\n",
        "        else:\n",
        "            return acr.title()\n",
        "    acr_re = re.compile(r'\\b(?:ISO|IEC|EN|ASTM|ANSI|IEEE|ASME|UL)\\b', re.IGNORECASE)\n",
        "    return acr_re.sub(repl, text)\n",
        "\n",
        "# Citation strip ([12], (Smith, 2020))\n",
        "def citation_strip(text):\n",
        "    t = re.sub(r'\\[[^\\]]{1,40}\\]', ' ', text)  # [ ... ]\n",
        "    t = re.sub(r'\\((?:[^()]+,\\s*\\d{4}[a-z]?)\\)', ' ', t)  # (Author, 2020)\n",
        "    return t\n",
        "\n",
        "# ---------------- Compose (domain combos) ----------------\n",
        "def domain_combo1(x):  # mask domain + mask units\n",
        "    return unit_mask(mask_domain_terms(x))\n",
        "def domain_combo2(x):  # drop domain + standards + generic units\n",
        "    return unit_generic(standard_num_corrupt(drop_domain_terms(x)))\n",
        "def domain_combo3(x):  # synonyms + numbers + acronyms\n",
        "    return acronym_perturb(number_perturb(synonym_swap_domain(x)))\n",
        "def domain_max(x):     # heavy chain\n",
        "    return unit_generic(standard_num_corrupt(acronym_perturb(\n",
        "           number_perturb(synonym_swap_domain(mask_domain_terms(x))))))\n",
        "\n",
        "# ---------------- Attack registry (name -> function) ----------------\n",
        "ATTACKS = {\n",
        "    \"CharSwap\":              char_swap,\n",
        "    \"CaseToggle\":            case_toggle,\n",
        "    \"PunctInsert\":           punct_insert,\n",
        "    \"WhitespaceNoise\":       whitespace_noise,\n",
        "    \"UnicodeConfuse\":        unicode_confuse,\n",
        "    \"SymbolAscii\":           symbol_ascii,\n",
        "    \"Truncate80w\":           truncate_80w,\n",
        "\n",
        "    \"NumberPerturb\":         number_perturb,\n",
        "    \"MaskDomainTerms\":       mask_domain_terms,\n",
        "    \"DropDomainTerms\":       drop_domain_terms,\n",
        "    \"SynonymSwapDomain\":     synonym_swap_domain,\n",
        "    \"StandardNumCorrupt\":    standard_num_corrupt,\n",
        "    \"UnitNeutralizeMask\":    unit_mask,\n",
        "    \"UnitNeutralizeDrop\":    unit_drop,\n",
        "    \"UnitNeutralizeGeneric\": unit_generic,\n",
        "    \"AcronymPerturb\":        acronym_perturb,\n",
        "    \"CitationStrip\":         citation_strip,\n",
        "\n",
        "    # Composites\n",
        "    \"DomainCombo1\":          domain_combo1,\n",
        "    \"DomainCombo2\":          domain_combo2,\n",
        "    \"DomainCombo3\":          domain_combo3,\n",
        "    \"DomainMax\":             domain_max,\n",
        "}\n",
        "\n",
        "# ---------------- Run all attacks on test set ----------------\n",
        "test_df = pd.read_csv(TEST_CSV)\n",
        "assert TEXT_COL in test_df.columns and LABEL_COL in test_df.columns, \"test.csv must have content + label\"\n",
        "\n",
        "coverage_rows = []\n",
        "for name, fn in ATTACKS.items():\n",
        "    atk = []\n",
        "    changed = 0\n",
        "    for txt in test_df[TEXT_COL].astype(str).tolist():\n",
        "        adv = fn(txt)\n",
        "        atk.append(adv)\n",
        "        if adv != txt:\n",
        "            changed += 1\n",
        "    df_out = test_df.copy()\n",
        "    df_out[TEXT_COL] = atk\n",
        "    out_name = _norm(name) + \".csv\"\n",
        "    out_path = os.path.join(PERT_DIR, out_name)\n",
        "    df_out.to_csv(out_path, index=False)\n",
        "    cov = 100.0 * changed / max(1, len(test_df))\n",
        "    coverage_rows.append({\"Attack\": name, \"Attack_norm\": _norm(name), \"coverage_pct\": cov, \"rows\": len(test_df)})\n",
        "    print(f\"Saved {name} -> {out_path} | coverage={cov:.1f}%\")\n",
        "\n",
        "cov_df = pd.DataFrame(coverage_rows)\n",
        "cov_path = os.path.join(ADV_DIR, \"coverage_summary.csv\")\n",
        "cov_df.to_csv(cov_path, index=False)\n",
        "print(\"\\nCoverage summary:\", cov_path)\n",
        "cov_df\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "D0XDJNI4R9_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Block GA-2: Evaluate attacks by groups; export tables & figures ---\n",
        "\n",
        "import os, re, glob, difflib, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    XLMRobertaTokenizerFast, XLMRobertaForSequenceClassification,\n",
        "    XLMRobertaModel, DataCollatorWithPadding\n",
        ")\n",
        "import joblib, xgboost as xgb\n",
        "from sklearn.metrics import f1_score, roc_auc_score, average_precision_score, roc_curve\n",
        "\n",
        "# ---------------- Config (match your training artifacts) ----------------\n",
        "class _Cfg:\n",
        "    BASE_DIR   = \"/content/drive/MyDrive/emc\"\n",
        "    TEST_CSV   = os.path.join(BASE_DIR, \"test.csv\")\n",
        "    TERMS_CSV  = os.path.join(BASE_DIR, \"engineering_terms.csv\")\n",
        "\n",
        "    XGB_DIR    = os.path.join(BASE_DIR, \"xgb_outputs_clean\")\n",
        "    XLMR_DIR   = os.path.join(BASE_DIR, \"xlmr_only_outputs_clean\")\n",
        "    SIMPLE_DIR = os.path.join(BASE_DIR, \"simple_fusion_outputs_clean\")\n",
        "    GATED_DIR  = os.path.join(BASE_DIR, \"gated_fusion_outputs_clean\")\n",
        "\n",
        "    ADV_DIR    = os.path.join(BASE_DIR, \"adv_eval_outputs\")\n",
        "    PERT_DIR   = os.path.join(ADV_DIR, \"perturbed\")\n",
        "    OUT_DIR    = os.path.join(ADV_DIR, \"grouped_eval\")\n",
        "\n",
        "    TEXT_COL   = \"content\"\n",
        "    LABEL_COL  = \"label\"\n",
        "    LANG_COL   = \"lang\"\n",
        "    ID_COL     = \"id\"\n",
        "\n",
        "    MAX_LEN    = 256\n",
        "    BATCH_SIZE = 32\n",
        "    N_FEATS    = 12\n",
        "    POS_LABEL  = 1\n",
        "    DPI        = 600\n",
        "    AGGREGATOR = \"median\"   # \"mean\" | \"median\" | \"worst\"\n",
        "\n",
        "cfg = _Cfg()\n",
        "os.makedirs(cfg.OUT_DIR, exist_ok=True)\n",
        "\n",
        "def _norm(s: str) -> str:\n",
        "    s = str(s).lower()\n",
        "    s = re.sub(r\"[\\s\\-\\/]+\", \"_\", s)\n",
        "    s = re.sub(r\"[^a-z0-9_]+\", \"\", s)\n",
        "    return s\n",
        "\n",
        "# ---------------- Group map (3 buckets) ----------------\n",
        "GROUP_MAP = {\n",
        "    # Structural\n",
        "    _norm(\"CharSwap\"): \"Structural\",\n",
        "    _norm(\"CaseToggle\"): \"Structural\",\n",
        "    _norm(\"PunctInsert\"): \"Structural\",\n",
        "    _norm(\"WhitespaceNoise\"): \"Structural\",\n",
        "    _norm(\"UnicodeConfuse\"): \"Structural\",\n",
        "    _norm(\"SymbolAscii\"): \"Structural\",\n",
        "    _norm(\"Truncate80w\"): \"Structural\",\n",
        "    # Semantic/Cue\n",
        "    _norm(\"MaskDomainTerms\"): \"Semantic/Cue\",\n",
        "    _norm(\"DropDomainTerms\"): \"Semantic/Cue\",\n",
        "    _norm(\"SynonymSwapDomain\"): \"Semantic/Cue\",\n",
        "    _norm(\"AcronymPerturb\"): \"Semantic/Cue\",\n",
        "    _norm(\"CitationStrip\"): \"Semantic/Cue\",\n",
        "    _norm(\"DomainCombo1\"): \"Semantic/Cue\",\n",
        "    _norm(\"DomainCombo2\"): \"Semantic/Cue\",\n",
        "    _norm(\"DomainCombo3\"): \"Semantic/Cue\",\n",
        "    _norm(\"DomainMax\"): \"Semantic/Cue\",\n",
        "    # Feature-Targeted\n",
        "    _norm(\"NumberPerturb\"): \"Feature-Targeted\",\n",
        "    _norm(\"StandardNumCorrupt\"): \"Feature-Targeted\",\n",
        "    _norm(\"UnitNeutralizeMask\"): \"Feature-Targeted\",\n",
        "    _norm(\"UnitNeutralizeDrop\"): \"Feature-Targeted\",\n",
        "    _norm(\"UnitNeutralizeGeneric\"): \"Feature-Targeted\",\n",
        "    _norm(\"Numbers/Units\"): \"Feature-Targeted\",\n",
        "    _norm(\"Unit Conversion (NEW)\"): \"Feature-Targeted\",\n",
        "}\n",
        "\n",
        "MODELS = [\"XLM-R Only\", \"XGBoost + Features\", \"Simple Fusion\", \"Gated Fusion\"]\n",
        "MODEL_COLORS = {\n",
        "    \"XGBoost + Features\": \"tab:blue\",\n",
        "    \"XLM-R Only\":         \"tab:red\",\n",
        "    \"Simple Fusion\":      \"tab:green\",\n",
        "    \"Gated Fusion\":       \"tab:orange\",\n",
        "}\n",
        "\n",
        "# ---------------- Feature extractor (12-D) ----------------\n",
        "import re\n",
        "_WORD_RE = re.compile(r\"\\w+\", re.UNICODE)\n",
        "_NUM_RE  = re.compile(r'[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?')\n",
        "STD_TERMS = {\"iso\",\"asme\",\"ieee\",\"din\",\"ansi\",\"iec\",\"ul\",\"astm\",\"en\"}\n",
        "SAFETY_TERMS = {\"safety\",\"hazard\",\"warning\",\"risk\",\"caution\",\"danger\",\"emergency\"}\n",
        "\n",
        "def simple_words(t: str): return _WORD_RE.findall(t or \"\")\n",
        "def sent_count(t: str) -> int:\n",
        "    if not t: return 0\n",
        "    return max(1, len(re.split(r'[.!?]+[\\s\\n]+', t)))\n",
        "def punct_count(t: str) -> int: return sum(1 for ch in (t or \"\") if ch in \".,;:!?\")\n",
        "def extract_numbers(text: str):\n",
        "    nums, dec = [], 0\n",
        "    for m in _NUM_RE.finditer(text or \"\"):\n",
        "        s = m.group(0)\n",
        "        try:\n",
        "            v = float(s)\n",
        "            if ('.' in s) or ('e' in s.lower()): dec += 1\n",
        "            nums.append(abs(v))\n",
        "        except: pass\n",
        "    return nums, dec\n",
        "def _finite_or_zero(x: float):\n",
        "    try:\n",
        "        xx = float(x)\n",
        "        return xx if np.isfinite(xx) else 0.0\n",
        "    except: return 0.0\n",
        "\n",
        "class TermsLexicon:\n",
        "    def __init__(self, csv_path: str, term_col=\"terms\", lang_col=\"lang\"):\n",
        "        df = pd.read_csv(csv_path)\n",
        "        if term_col not in df.columns: raise ValueError(f\"Missing '{term_col}'\")\n",
        "        if lang_col not in df.columns: df[lang_col] = 'en'\n",
        "        self.by_lang = {str(l).lower(): set(str(x).strip().lower()\n",
        "                         for x in d[term_col].dropna().tolist() if str(x).strip())\n",
        "                        for l, d in df.groupby(lang_col)}\n",
        "    def pct_in_text(self, text: str, lang: str) -> float:\n",
        "        terms = self.by_lang.get((lang or \"en\").lower(), set())\n",
        "        if not terms: return 0.0\n",
        "        ws = [w.lower() for w in simple_words(text)]\n",
        "        return sum(1 for w in ws if w in terms) / max(1, len(ws)) if ws else 0.0\n",
        "\n",
        "lex = TermsLexicon(cfg.TERMS_CSV)\n",
        "def engineered_features(df):\n",
        "    def extract_one(text, lang=\"en\"):\n",
        "        text = \"\" if text is None else str(text); lang = (lang or \"en\").lower()\n",
        "        ws = simple_words(text); n_words = len(ws)\n",
        "        chars = len(text); words = n_words; sents = sent_count(text)\n",
        "        fre, fog = 0.0, 0.0\n",
        "        eng_pct = lex.pct_in_text(text, lang)\n",
        "        punc = punct_count(text)\n",
        "        nums, dec_cnt = extract_numbers(text); nnums = len(nums)\n",
        "        avg_mag = float(np.mean(nums)) if nums else 0.0\n",
        "        dec_ratio = float(dec_cnt / max(1, len(nums)))\n",
        "        low = text.lower()\n",
        "        has_std = 1.0 if any(t in low for t in STD_TERMS) else 0.0\n",
        "        has_saf = 1.0 if any(t in low for t in SAFETY_TERMS) else 0.0\n",
        "        vals = [chars, words, sents, fre, fog, eng_pct, punc, nnums, has_std, has_saf, avg_mag, dec_ratio]\n",
        "        arr = np.asarray([_finite_or_zero(v) for v in vals], dtype=np.float64)\n",
        "        arr = np.nan_to_num(arr, nan=0.0, posinf=1e12, neginf=0.0)\n",
        "        return np.clip(arr, -1e12, 1e12).astype(np.float32)\n",
        "    local = df if cfg.LANG_COL in df.columns else df.assign(**{cfg.LANG_COL:'en'})\n",
        "    rows = [extract_one(r.get(cfg.TEXT_COL,\"\"), r.get(cfg.LANG_COL,\"en\")) for _, r in local.iterrows()]\n",
        "    return np.stack(rows, axis=0).astype(np.float32)\n",
        "\n",
        "# ---------------- Datasets & heads ----------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tok = XLMRobertaTokenizerFast.from_pretrained(cfg.XLMR_DIR)\n",
        "collator = DataCollatorWithPadding(tok)\n",
        "\n",
        "class TextOnlyDS(torch.utils.data.Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.x = df[cfg.TEXT_COL].astype(str).tolist()\n",
        "        self.y = df[cfg.LABEL_COL].astype(int).values\n",
        "    def __len__(self): return len(self.x)\n",
        "    def __getitem__(self, i):\n",
        "        enc = tok(self.x[i], truncation=True, padding=False, max_length=cfg.MAX_LEN, return_tensors=\"pt\")\n",
        "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
        "        item[\"labels\"] = torch.tensor(int(self.y[i]), dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "class TextFeatDS(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, feats_scaled):\n",
        "        self.x = df[cfg.TEXT_COL].astype(str).tolist()\n",
        "        self.y = df[cfg.LABEL_COL].astype(int).values\n",
        "        self.fe = feats_scaled.astype(np.float32)\n",
        "    def __len__(self): return len(self.x)\n",
        "    def __getitem__(self, i):\n",
        "        enc = tok(self.x[i], truncation=True, padding=\"max_length\", max_length=cfg.MAX_LEN, return_tensors=\"pt\")\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(int(self.y[i]), dtype=torch.long),\n",
        "            \"feats\": torch.tensor(self.fe[i], dtype=torch.float32),\n",
        "        }\n",
        "\n",
        "class SimpleFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + n_feats, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (out.last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "        fused = torch.cat([pooled, feats], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "\n",
        "class GatedFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2, feat_proj: int = 64):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.fe_proj = nn.Sequential(nn.Linear(n_feats, feat_proj), nn.ReLU())\n",
        "        self.gate    = nn.Sequential(nn.Linear(H + n_feats, 64), nn.ReLU(), nn.Linear(64, 1), nn.Sigmoid())\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + feat_proj, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (out.last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "        alpha = self.gate(torch.cat([pooled, feats], dim=1))\n",
        "        ef    = self.fe_proj(feats)\n",
        "        fused = torch.cat([pooled, alpha * ef], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "\n",
        "# load models\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "xgb_model.load_model(os.path.join(cfg.XGB_DIR, \"xgb_model.json\"))\n",
        "xgb_scaler = joblib.load(os.path.join(cfg.XGB_DIR, \"scaler12.pkl\"))\n",
        "\n",
        "xlmr = XLMRobertaForSequenceClassification.from_pretrained(cfg.XLMR_DIR).to(device); xlmr.eval()\n",
        "\n",
        "simple = SimpleFusion(\"xlm-roberta-base\", cfg.N_FEATS, 2).to(device)\n",
        "simple.load_state_dict(torch.load(os.path.join(cfg.SIMPLE_DIR, \"fusion_simple.pt\"), map_location=device), strict=False); simple.eval()\n",
        "simple_scaler = joblib.load(os.path.join(cfg.SIMPLE_DIR, \"scaler12.pkl\"))\n",
        "\n",
        "gated = GatedFusion(\"xlm-roberta-base\", cfg.N_FEATS, 2, feat_proj=64).to(device)\n",
        "gated.load_state_dict(torch.load(os.path.join(cfg.GATED_DIR, \"fusion_gated.pt\"), map_location=device), strict=False); gated.eval()\n",
        "gated_scaler = joblib.load(os.path.join(cfg.GATED_DIR, \"scaler12.pkl\"))\n",
        "\n",
        "# metrics helpers\n",
        "@torch.no_grad()\n",
        "def eval_xlmr(df):\n",
        "    ds = TextOnlyDS(df); dl = DataLoader(ds, batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=DataCollatorWithPadding(tok))\n",
        "    probs = []\n",
        "    for b in dl:\n",
        "        inp = {k: v.to(device) for k, v in b.items() if k in (\"input_ids\",\"attention_mask\")}\n",
        "        pr = torch.softmax(xlmr(**inp).logits, dim=-1)[:, cfg.POS_LABEL].cpu().numpy()\n",
        "        probs.append(pr)\n",
        "    y_prob = np.concatenate(probs); y_pred = (y_prob >= 0.5).astype(int)\n",
        "    y_true = df[cfg.LABEL_COL].astype(int).values\n",
        "    return y_true, y_pred, y_prob\n",
        "\n",
        "def eval_xgb(df):\n",
        "    X = engineered_features(df); Xs = xgb_scaler.transform(X)\n",
        "    y_prob = xgb_model.predict_proba(Xs)[:, cfg.POS_LABEL]; y_pred = (y_prob >= 0.5).astype(int)\n",
        "    y_true = df[cfg.LABEL_COL].astype(int).values\n",
        "    return y_true, y_pred, y_prob\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_fusion(df, scaler, model):\n",
        "    X = engineered_features(df); Xs = scaler.transform(X).astype(np.float32)\n",
        "    ds = TextFeatDS(df, Xs); dl = DataLoader(ds, batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=DataCollatorWithPadding(tok))\n",
        "    probs = []\n",
        "    for b in dl:\n",
        "        ids = b[\"input_ids\"].to(device); am = b[\"attention_mask\"].to(device); ft = b[\"feats\"].to(device)\n",
        "        pr = torch.softmax(model(ids, am, ft), dim=-1)[:, cfg.POS_LABEL].cpu().numpy()\n",
        "        probs.append(pr)\n",
        "    y_prob = np.concatenate(probs); y_pred = (y_prob >= 0.5).astype(int)\n",
        "    y_true = df[cfg.LABEL_COL].astype(int).values\n",
        "    return y_true, y_pred, y_prob\n",
        "\n",
        "def metrics_from(y_true, y_pred, y_prob):\n",
        "    out = {}\n",
        "    out[\"macro_f1\"] = f1_score(y_true, y_pred, average=\"macro\")\n",
        "    try: out[\"auc_roc\"] = roc_auc_score(y_true, y_prob)\n",
        "    except: out[\"auc_roc\"] = np.nan\n",
        "    return out\n",
        "\n",
        "# ---- 1) Clean baseline ----\n",
        "test_df = pd.read_csv(cfg.TEST_CSV)\n",
        "rows = []\n",
        "for m in MODELS:\n",
        "    if m == \"XLM-R Only\":         y_true, y_pred, y_prob = eval_xlmr(test_df)\n",
        "    elif m == \"XGBoost + Features\": y_true, y_pred, y_prob = eval_xgb(test_df)\n",
        "    elif m == \"Simple Fusion\":    y_true, y_pred, y_prob = eval_fusion(test_df, simple_scaler, simple)\n",
        "    else:                         y_true, y_pred, y_prob = eval_fusion(test_df, gated_scaler, gated)\n",
        "    rows.append({\"Model\": m, \"Attack_norm\": _norm(\"Clean\"), \"Group\": \"Clean\", **metrics_from(y_true,y_pred,y_prob)})\n",
        "clean_df = pd.DataFrame(rows)\n",
        "\n",
        "# ---- 2) Per-attack eval (from freshly generated files) ----\n",
        "attack_frames = []\n",
        "for p in sorted(glob.glob(os.path.join(cfg.ADV_DIR, \"perturbed\", \"*.csv\"))):\n",
        "    name = os.path.splitext(os.path.basename(p))[0]\n",
        "    if name == _norm(\"Clean\"):\n",
        "        continue\n",
        "    dfp = pd.read_csv(p)\n",
        "    if cfg.TEXT_COL not in dfp.columns or cfg.LABEL_COL not in dfp.columns:\n",
        "        continue\n",
        "    group = GROUP_MAP.get(name, \"Unassigned\")\n",
        "    for m in MODELS:\n",
        "        if m == \"XLM-R Only\":         y_true, y_pred, y_prob = eval_xlmr(dfp)\n",
        "        elif m == \"XGBoost + Features\": y_true, y_pred, y_prob = eval_xgb(dfp)\n",
        "        elif m == \"Simple Fusion\":    y_true, y_pred, y_prob = eval_fusion(dfp, simple_scaler, simple)\n",
        "        else:                         y_true, y_pred, y_prob = eval_fusion(dfp, gated_scaler, gated)\n",
        "        attack_frames.append({\"Model\": m, \"Attack_norm\": name, \"Group\": group, **metrics_from(y_true,y_pred,y_prob)})\n",
        "\n",
        "atk_eval = pd.DataFrame(attack_frames)\n",
        "atk_raw_path = os.path.join(cfg.OUT_DIR, \"per_attack_eval_raw.csv\")\n",
        "atk_eval.to_csv(atk_raw_path, index=False)\n",
        "print(\"Saved:\", atk_raw_path)\n",
        "\n",
        "# ---- 3) Aggregate by the 3 groups ----\n",
        "clean_macro = clean_df[[\"Model\",\"macro_f1\"]].rename(columns={\"macro_f1\":\"Clean Macro F1\"})\n",
        "\n",
        "agg = cfg.AGGREGATOR.lower()\n",
        "if agg == \"mean\":\n",
        "    g_agg = atk_eval.groupby([\"Model\",\"Group\"], as_index=False)[\"macro_f1\"].mean()\n",
        "elif agg == \"median\":\n",
        "    g_agg = atk_eval.groupby([\"Model\",\"Group\"], as_index=False)[\"macro_f1\"].median()\n",
        "elif agg == \"worst\":\n",
        "    g_agg = atk_eval.groupby([\"Model\",\"Group\"], as_index=False)[\"macro_f1\"].min()\n",
        "else:\n",
        "    raise ValueError(\"AGGREGATOR must be one of: mean|median|worst\")\n",
        "\n",
        "g_agg = g_agg.rename(columns={\"macro_f1\":\"Group Macro F1\"})\n",
        "grouped_tbl = g_agg.merge(clean_macro, on=\"Model\", how=\"left\")\n",
        "grouped_tbl[\"Δ\"]  = grouped_tbl[\"Clean Macro F1\"] - grouped_tbl[\"Group Macro F1\"]\n",
        "grouped_tbl[\"Δ%\"] = 100.0 * grouped_tbl[\"Δ\"] / grouped_tbl[\"Clean Macro F1\"].replace(0.0, np.nan)\n",
        "\n",
        "# order + export\n",
        "order_groups = [\"Structural\",\"Semantic/Cue\",\"Feature-Targeted\"]\n",
        "grouped_tbl[\"Group\"] = pd.Categorical(grouped_tbl[\"Group\"], categories=order_groups, ordered=True)\n",
        "grouped_tbl = grouped_tbl.sort_values([\"Model\",\"Group\"]).reset_index(drop=True)\n",
        "\n",
        "suffix = {\"mean\":\"avg\",\"median\":\"median\",\"worst\":\"worst\"}[agg]\n",
        "csv_path = os.path.join(cfg.OUT_DIR, f\"grouped_macro_f1_{suffix}.csv\")\n",
        "md_path  = os.path.join(cfg.OUT_DIR, f\"grouped_macro_f1_{suffix}.md\")\n",
        "tex_path = os.path.join(cfg.OUT_DIR, f\"grouped_macro_f1_{suffix}.tex\")\n",
        "\n",
        "grouped_tbl.to_csv(csv_path, index=False)\n",
        "with open(md_path, \"w\") as f:\n",
        "    f.write(grouped_tbl.rename(columns={\"Δ\":\"Delta\",\"Δ%\":\"Delta%\"}).to_markdown(index=False))\n",
        "latex_tbl = grouped_tbl.rename(columns={\n",
        "    \"Group\":\"Attack Group\",\"Clean Macro F1\":\"Clean~F1\",\"Group Macro F1\":\"Group~F1\",\n",
        "    \"Δ\":r\"$\\Delta$~F1\",\"Δ%\":r\"$\\Delta$~(\\%)\"\n",
        "}).to_latex(index=False, escape=True, longtable=False, column_format=\"l l r r r r\",\n",
        "            na_rep=\"--\", float_format=\"%.3f\".__mod__,\n",
        "            caption=f\"Clean vs. grouped adversarial Macro-F1 (aggregator = {agg}).\",\n",
        "            label=f\"tab:grouped_macroF1_{suffix}\")\n",
        "with open(tex_path, \"w\") as f:\n",
        "    f.write(\"% Requires \\\\usepackage{booktabs}\\n\")\n",
        "    f.write(latex_tbl)\n",
        "\n",
        "print(\"Wrote tables:\")\n",
        "print(\" \", csv_path)\n",
        "print(\" \", md_path)\n",
        "print(\" \", tex_path)\n",
        "print(\"\\nGrouped table (rounded):\")\n",
        "print(grouped_tbl.round(4).to_string(index=False))\n",
        "\n",
        "# ---- 4) Figures (600 dpi): Group bars & Δ heatmap ----\n",
        "FIG_DIR = os.path.join(cfg.OUT_DIR, \"figures_grouped\"); os.makedirs(FIG_DIR, exist_ok=True)\n",
        "\n",
        "# (A) per-model bars\n",
        "for model_name in MODELS:\n",
        "    sub = grouped_tbl[grouped_tbl[\"Model\"]==model_name].copy()\n",
        "    if sub.empty: continue\n",
        "    labels = sub[\"Group\"].astype(str).tolist()\n",
        "    clean_vals = sub[\"Clean Macro F1\"].values\n",
        "    group_vals = sub[\"Group Macro F1\"].values\n",
        "    x = np.arange(len(labels)); w = 0.35\n",
        "\n",
        "    plt.figure(figsize=(8.5,4.8))\n",
        "    plt.bar(x - w/2, clean_vals, width=w, label=\"Clean F1\", color=\"lightgray\", edgecolor=\"black\", linewidth=0.6)\n",
        "    plt.bar(x + w/2, group_vals, width=w, label=\"Group F1\", color=MODEL_COLORS.get(model_name,\"tab:blue\"), edgecolor=\"black\", linewidth=0.6)\n",
        "    for i,(c,g) in enumerate(zip(clean_vals, group_vals)):\n",
        "        plt.text(x[i]-w/2, c+0.01, f\"{c:.3f}\", ha=\"center\", va=\"bottom\", fontsize=8)\n",
        "        plt.text(x[i]+w/2, g+0.01, f\"{g:.3f}\", ha=\"center\", va=\"bottom\", fontsize=8)\n",
        "    plt.xticks(x, labels); plt.ylabel(\"Macro F1\")\n",
        "    plt.title(f\"Grouped Robustness — {model_name} ({cfg.AGGREGATOR})\")\n",
        "    plt.legend(); plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
        "    out_png = os.path.join(FIG_DIR, f\"grouped_bars_{re.sub(r'[^A-Za-z0-9_.-]+','_',model_name)}.png\")\n",
        "    plt.tight_layout(); plt.savefig(out_png, dpi=cfg.DPI); plt.show()\n",
        "    print(\"Saved:\", out_png)\n",
        "\n",
        "# (B) Δ heatmap\n",
        "heat = grouped_tbl.pivot(index=\"Model\", columns=\"Group\", values=\"Δ\").reindex(index=MODELS)[order_groups]\n",
        "plt.figure(figsize=(8.2,4.8))\n",
        "im = plt.imshow(heat.values, cmap=\"Reds\", vmin=0, vmax=np.nanmax(heat.values) if np.isfinite(heat.values).any() else 1)\n",
        "for i in range(heat.shape[0]):\n",
        "    for j in range(heat.shape[1]):\n",
        "        v = heat.values[i,j]\n",
        "        if np.isfinite(v):\n",
        "            plt.text(j, i, f\"{v:.3f}\", ha=\"center\", va=\"center\", fontsize=9, color=\"black\")\n",
        "plt.xticks(np.arange(len(order_groups)), order_groups)\n",
        "plt.yticks(np.arange(len(MODELS)), MODELS)\n",
        "plt.colorbar(im, label=\"Δ Macro-F1 (Clean − Group)\")\n",
        "plt.title(f\"Grouped Δ Macro-F1 (aggregator = {cfg.AGGREGATOR})\")\n",
        "hm_png = os.path.join(FIG_DIR, \"heatmap_delta_macroF1.png\")\n",
        "plt.tight_layout(); plt.savefig(hm_png, dpi=cfg.DPI); plt.show()\n",
        "print(\"Saved:\", hm_png)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "z7h143l2UNF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === PR-AUC + ΔFPR@95%TPR (Grouped) + Single Multi-Panel Figure (600 dpi) ===\n",
        "# Outputs:\n",
        "#   adv_eval_outputs/grouped_eval/group_pr_fpr95_summary.csv\n",
        "#   adv_eval_outputs/grouped_eval/figures_grouped/panel_pr_and_deltafpr.png\n",
        "#\n",
        "# Assumptions:\n",
        "# - Clean test set:        /content/drive/MyDrive/emc/test.csv\n",
        "# - Perturbed datasets:    /content/drive/MyDrive/emc/adv_eval_outputs/perturbed/*.csv\n",
        "#   (Use GA-1 to generate them if missing.)\n",
        "# - Model artifacts:\n",
        "#     XGB:    /content/drive/MyDrive/emc/xgb_outputs_clean/{xgb_model.json, scaler12.pkl}\n",
        "#     XLM-R:  /content/drive/MyDrive/emc/xlmr_only_outputs_clean\n",
        "#     Simple: /content/drive/MyDrive/emc/simple_fusion_outputs_clean/{fusion_simple.pt, scaler12.pkl}\n",
        "#     Gated:  /content/drive/MyDrive/emc/gated_fusion_outputs_clean/{fusion_gated.pt, scaler12.pkl}\n",
        "\n",
        "import os, re, glob, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import joblib, xgboost as xgb\n",
        "from transformers import (\n",
        "    XLMRobertaTokenizerFast, XLMRobertaModel, XLMRobertaForSequenceClassification,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from sklearn.metrics import (\n",
        "    precision_recall_curve, average_precision_score,\n",
        "    roc_curve\n",
        ")\n",
        "\n",
        "# ---------------- Config ----------------\n",
        "class CFG:\n",
        "    BASE_DIR   = \"/content/drive/MyDrive/emc\"\n",
        "    TEST_CSV   = os.path.join(BASE_DIR, \"test.csv\")\n",
        "    TERMS_CSV  = os.path.join(BASE_DIR, \"engineering_terms.csv\")\n",
        "\n",
        "    XGB_DIR    = os.path.join(BASE_DIR, \"xgb_outputs_clean\")\n",
        "    XLMR_DIR   = os.path.join(BASE_DIR, \"xlmr_only_outputs_clean\")\n",
        "    SIMPLE_DIR = os.path.join(BASE_DIR, \"simple_fusion_outputs_clean\")\n",
        "    GATED_DIR  = os.path.join(BASE_DIR, \"gated_fusion_outputs_clean\")\n",
        "\n",
        "    ADV_DIR    = os.path.join(BASE_DIR, \"adv_eval_outputs\")\n",
        "    PERT_DIR   = os.path.join(ADV_DIR, \"perturbed\")\n",
        "    OUT_DIR    = os.path.join(ADV_DIR, \"grouped_eval\")\n",
        "    FIG_DIR    = os.path.join(OUT_DIR, \"figures_grouped\")\n",
        "\n",
        "    TEXT_COL   = \"content\"\n",
        "    LABEL_COL  = \"label\"\n",
        "    LANG_COL   = \"lang\"\n",
        "    MAX_LEN    = 256\n",
        "    BATCH_SIZE = 32\n",
        "    N_FEATS    = 12\n",
        "    POS_LABEL  = 1\n",
        "    DPI        = 600\n",
        "\n",
        "cfg = CFG()\n",
        "os.makedirs(cfg.OUT_DIR, exist_ok=True)\n",
        "os.makedirs(cfg.FIG_DIR, exist_ok=True)\n",
        "\n",
        "def _norm(s: str) -> str:\n",
        "    s = str(s).lower()\n",
        "    s = re.sub(r\"[\\s\\-\\/]+\", \"_\", s)\n",
        "    s = re.sub(r\"[^a-z0-9_]+\", \"\", s)\n",
        "    return s\n",
        "\n",
        "# ------------- Group mapping (3 buckets) -------------\n",
        "GROUP_MAP = {\n",
        "    # Structural\n",
        "    _norm(\"CharSwap\"): \"Structural\",\n",
        "    _norm(\"CaseToggle\"): \"Structural\",\n",
        "    _norm(\"PunctInsert\"): \"Structural\",\n",
        "    _norm(\"WhitespaceNoise\"): \"Structural\",\n",
        "    _norm(\"UnicodeConfuse\"): \"Structural\",\n",
        "    _norm(\"SymbolAscii\"): \"Structural\",\n",
        "    _norm(\"Truncate80w\"): \"Structural\",\n",
        "    # Semantic/Cue\n",
        "    _norm(\"MaskDomainTerms\"): \"Semantic/Cue\",\n",
        "    _norm(\"DropDomainTerms\"): \"Semantic/Cue\",\n",
        "    _norm(\"SynonymSwapDomain\"): \"Semantic/Cue\",\n",
        "    _norm(\"AcronymPerturb\"): \"Semantic/Cue\",\n",
        "    _norm(\"CitationStrip\"): \"Semantic/Cue\",\n",
        "    _norm(\"DomainCombo1\"): \"Semantic/Cue\",\n",
        "    _norm(\"DomainCombo2\"): \"Semantic/Cue\",\n",
        "    _norm(\"DomainCombo3\"): \"Semantic/Cue\",\n",
        "    _norm(\"DomainMax\"): \"Semantic/Cue\",\n",
        "    # Feature-Targeted\n",
        "    _norm(\"NumberPerturb\"): \"Feature-Targeted\",\n",
        "    _norm(\"StandardNumCorrupt\"): \"Feature-Targeted\",\n",
        "    _norm(\"UnitNeutralizeMask\"): \"Feature-Targeted\",\n",
        "    _norm(\"UnitNeutralizeDrop\"): \"Feature-Targeted\",\n",
        "    _norm(\"UnitNeutralizeGeneric\"): \"Feature-Targeted\",\n",
        "    _norm(\"Numbers/Units\"): \"Feature-Targeted\",\n",
        "    _norm(\"Unit Conversion (NEW)\"): \"Feature-Targeted\",\n",
        "}\n",
        "ORDER_GROUPS = [\"Structural\", \"Semantic/Cue\", \"Feature-Targeted\"]\n",
        "\n",
        "MODELS = [\"XLM-R Only\", \"XGBoost + Features\", \"Simple Fusion\", \"Gated Fusion\"]\n",
        "MODEL_COLORS = {\n",
        "    \"XGBoost + Features\": \"tab:blue\",\n",
        "    \"XLM-R Only\":         \"tab:red\",\n",
        "    \"Simple Fusion\":      \"tab:green\",\n",
        "    \"Gated Fusion\":       \"tab:orange\",\n",
        "}\n",
        "GROUP_COLORS = {\n",
        "    \"Structural\":      \"tab:blue\",\n",
        "    \"Semantic/Cue\":    \"tab:orange\",\n",
        "    \"Feature-Targeted\":\"tab:green\",\n",
        "}\n",
        "CLEAN_COLOR = \"black\"\n",
        "\n",
        "# ---------------- Feature extractor (12-D) ----------------\n",
        "import re\n",
        "_WORD_RE = re.compile(r\"\\w+\", re.UNICODE)\n",
        "_NUM_RE  = re.compile(r'[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?')\n",
        "STD_TERMS = {\"iso\",\"asme\",\"ieee\",\"din\",\"ansi\",\"iec\",\"ul\",\"astm\",\"en\"}\n",
        "SAFETY_TERMS = {\"safety\",\"hazard\",\"warning\",\"risk\",\"caution\",\"danger\",\"emergency\"}\n",
        "\n",
        "def simple_words(t: str): return _WORD_RE.findall(t or \"\")\n",
        "def sent_count(t: str) -> int:\n",
        "    if not t: return 0\n",
        "    return max(1, len(re.split(r'[.!?]+[\\s\\n]+', t)))\n",
        "def punct_count(t: str) -> int: return sum(1 for ch in (t or \"\") if ch in \".,;:!?\")\n",
        "def extract_numbers(text: str):\n",
        "    nums, dec = [], 0\n",
        "    for m in _NUM_RE.finditer(text or \"\"):\n",
        "        s = m.group(0)\n",
        "        try:\n",
        "            v = float(s)\n",
        "            if ('.' in s) or ('e' in s.lower()): dec += 1\n",
        "            nums.append(abs(v))\n",
        "        except: pass\n",
        "    return nums, dec\n",
        "def _finite_or_zero(x: float):\n",
        "    try:\n",
        "        xx = float(x)\n",
        "        return xx if np.isfinite(xx) else 0.0\n",
        "    except: return 0.0\n",
        "\n",
        "class TermsLexicon:\n",
        "    def __init__(self, csv_path: str, term_col=\"terms\", lang_col=\"lang\"):\n",
        "        df = pd.read_csv(csv_path)\n",
        "        if term_col not in df.columns: raise ValueError(f\"Missing '{term_col}'\")\n",
        "        if lang_col not in df.columns: df[lang_col] = 'en'\n",
        "        self.by_lang = {str(l).lower(): set(str(x).strip().lower()\n",
        "                         for x in d[term_col].dropna().tolist() if str(x).strip())\n",
        "                        for l, d in df.groupby(lang_col)}\n",
        "    def pct_in_text(self, text: str, lang: str) -> float:\n",
        "        terms = self.by_lang.get((lang or \"en\").lower(), set())\n",
        "        if not terms: return 0.0\n",
        "        ws = [w.lower() for w in simple_words(text)]\n",
        "        return sum(1 for w in ws if w in terms) / max(1, len(ws)) if ws else 0.0\n",
        "\n",
        "lex = TermsLexicon(cfg.TERMS_CSV)\n",
        "\n",
        "def engineered_features(df):\n",
        "    def extract_one(text, lang=\"en\"):\n",
        "        text = \"\" if text is None else str(text); lang = (lang or \"en\").lower()\n",
        "        ws = simple_words(text); n_words = len(ws)\n",
        "        chars = len(text); words = n_words; sents = sent_count(text)\n",
        "        fre, fog = 0.0, 0.0\n",
        "        eng_pct = lex.pct_in_text(text, lang)\n",
        "        punc = punct_count(text)\n",
        "        nums, dec_cnt = extract_numbers(text); nnums = len(nums)\n",
        "        avg_mag = float(np.mean(nums)) if nums else 0.0\n",
        "        dec_ratio = float(dec_cnt / max(1, len(nums)))\n",
        "        low = text.lower()\n",
        "        has_std = 1.0 if any(t in low for t in STD_TERMS) else 0.0\n",
        "        has_saf = 1.0 if any(t in low for t in SAFETY_TERMS) else 0.0\n",
        "        vals = [chars, words, sents, fre, fog, eng_pct, punc, nnums, has_std, has_saf, avg_mag, dec_ratio]\n",
        "        arr = np.asarray([_finite_or_zero(v) for v in vals], dtype=np.float64)\n",
        "        arr = np.nan_to_num(arr, nan=0.0, posinf=1e12, neginf=0.0)\n",
        "        return np.clip(arr, -1e12, 1e12).astype(np.float32)\n",
        "    local = df if cfg.LANG_COL in df.columns else df.assign(**{cfg.LANG_COL:'en'})\n",
        "    rows = [extract_one(r.get(cfg.TEXT_COL,\"\"), r.get(cfg.LANG_COL,\"en\")) for _, r in local.iterrows()]\n",
        "    return np.stack(rows, axis=0).astype(np.float32)\n",
        "\n",
        "# ---------------- Tokenizer & models ----------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tok = XLMRobertaTokenizerFast.from_pretrained(cfg.XLMR_DIR)\n",
        "collator = DataCollatorWithPadding(tok)\n",
        "\n",
        "class TextOnlyDS(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.x = df[cfg.TEXT_COL].astype(str).tolist()\n",
        "        self.y = df[cfg.LABEL_COL].astype(int).values\n",
        "    def __len__(self): return len(self.x)\n",
        "    def __getitem__(self, i):\n",
        "        enc = tok(self.x[i], truncation=True, padding=False, max_length=cfg.MAX_LEN, return_tensors=\"pt\")\n",
        "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
        "        item[\"labels\"] = torch.tensor(int(self.y[i]), dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "class TextFeatDS(Dataset):\n",
        "    def __init__(self, df, feats_scaled):\n",
        "        self.x = df[cfg.TEXT_COL].astype(str).tolist()\n",
        "        self.y = df[cfg.LABEL_COL].astype(int).values\n",
        "        self.fe = feats_scaled.astype(np.float32)\n",
        "    def __len__(self): return len(self.x)\n",
        "    def __getitem__(self, i):\n",
        "        enc = tok(self.x[i], truncation=True, padding=\"max_length\", max_length=cfg.MAX_LEN, return_tensors=\"pt\")\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(int(self.y[i]), dtype=torch.long),\n",
        "            \"feats\": torch.tensor(self.fe[i], dtype=torch.float32),\n",
        "        }\n",
        "\n",
        "class SimpleFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + n_feats, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (out.last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "        fused = torch.cat([pooled, feats], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "\n",
        "class GatedFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2, feat_proj: int = 64):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.fe_proj = nn.Sequential(nn.Linear(n_feats, feat_proj), nn.ReLU())\n",
        "        self.gate    = nn.Sequential(nn.Linear(H + n_feats, 64), nn.ReLU(), nn.Linear(64, 1), nn.Sigmoid())\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + feat_proj, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (out.last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "        alpha = self.gate(torch.cat([pooled, feats], dim=1))\n",
        "        ef    = self.fe_proj(feats)\n",
        "        fused = torch.cat([pooled, alpha * ef], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "\n",
        "# Load artifacts\n",
        "xgb_model = xgb.XGBClassifier(); xgb_model.load_model(os.path.join(cfg.XGB_DIR, \"xgb_model.json\"))\n",
        "xgb_scaler = joblib.load(os.path.join(cfg.XGB_DIR, \"scaler12.pkl\"))\n",
        "\n",
        "xlmr = XLMRobertaForSequenceClassification.from_pretrained(cfg.XLMR_DIR).to(device); xlmr.eval()\n",
        "\n",
        "simple = SimpleFusion(\"xlm-roberta-base\", cfg.N_FEATS, 2).to(device)\n",
        "simple.load_state_dict(torch.load(os.path.join(cfg.SIMPLE_DIR, \"fusion_simple.pt\"), map_location=device), strict=False); simple.eval()\n",
        "simple_scaler = joblib.load(os.path.join(cfg.SIMPLE_DIR, \"scaler12.pkl\"))\n",
        "\n",
        "gated = GatedFusion(\"xlm-roberta-base\", cfg.N_FEATS, 2, feat_proj=64).to(device)\n",
        "gated.load_state_dict(torch.load(os.path.join(cfg.GATED_DIR, \"fusion_gated.pt\"), map_location=device), strict=False); gated.eval()\n",
        "gated_scaler = joblib.load(os.path.join(cfg.GATED_DIR, \"scaler12.pkl\"))\n",
        "\n",
        "# ---------------- Eval helpers (return y_true, y_prob) ----------------\n",
        "@torch.no_grad()\n",
        "def eval_xlmr(df):\n",
        "    ds = TextOnlyDS(df); dl = DataLoader(ds, batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=DataCollatorWithPadding(tok))\n",
        "    probs = []\n",
        "    for b in dl:\n",
        "        inp = {k: v.to(device) for k, v in b.items() if k in (\"input_ids\",\"attention_mask\")}\n",
        "        pr = torch.softmax(xlmr(**inp).logits, dim=-1)[:, cfg.POS_LABEL].cpu().numpy()\n",
        "        probs.append(pr)\n",
        "    return df[cfg.LABEL_COL].astype(int).values, np.concatenate(probs)\n",
        "\n",
        "def eval_xgb(df):\n",
        "    X = engineered_features(df); Xs = xgb_scaler.transform(X)\n",
        "    y_prob = xgb_model.predict_proba(Xs)[:, cfg.POS_LABEL]\n",
        "    return df[cfg.LABEL_COL].astype(int).values, y_prob\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_fusion(df, scaler, model):\n",
        "    X = engineered_features(df); Xs = scaler.transform(X).astype(np.float32)\n",
        "    ds = TextFeatDS(df, Xs); dl = DataLoader(ds, batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=DataCollatorWithPadding(tok))\n",
        "    probs = []\n",
        "    for b in dl:\n",
        "        ids = b[\"input_ids\"].to(device); am = b[\"attention_mask\"].to(device); ft = b[\"feats\"].to(device)\n",
        "        pr = torch.softmax(model(ids, am, ft), dim=-1)[:, cfg.POS_LABEL].cpu().numpy()\n",
        "        probs.append(pr)\n",
        "    return df[cfg.LABEL_COL].astype(int).values, np.concatenate(probs)\n",
        "\n",
        "def eval_model(df, model_name):\n",
        "    if model_name == \"XLM-R Only\":\n",
        "        return eval_xlmr(df)\n",
        "    elif model_name == \"XGBoost + Features\":\n",
        "        return eval_xgb(df)\n",
        "    elif model_name == \"Simple Fusion\":\n",
        "        return eval_fusion(df, simple_scaler, simple)\n",
        "    else:\n",
        "        return eval_fusion(df, gated_scaler, gated)\n",
        "\n",
        "# ---------------- Build datasets: clean + groups (concat attacks) ----------------\n",
        "test_df = pd.read_csv(cfg.TEST_CSV)\n",
        "assert cfg.TEXT_COL in test_df.columns and cfg.LABEL_COL in test_df.columns, \"test.csv must have content + label\"\n",
        "\n",
        "# Map attack CSVs to groups\n",
        "files = sorted(glob.glob(os.path.join(cfg.PERT_DIR, \"*.csv\")))\n",
        "attack_to_group = {}\n",
        "for p in files:\n",
        "    name = os.path.splitext(os.path.basename(p))[0]  # normalized name\n",
        "    if name == _norm(\"Clean\"):  # ignore\n",
        "        continue\n",
        "    grp = GROUP_MAP.get(name, None)\n",
        "    if grp:\n",
        "        attack_to_group.setdefault(grp, []).append(p)\n",
        "\n",
        "# For each group, concatenate the perturbed rows from *all* attacks in the group\n",
        "group_frames = {}\n",
        "for grp in ORDER_GROUPS:\n",
        "    paths = attack_to_group.get(grp, [])\n",
        "    if not paths:\n",
        "        continue\n",
        "    dfs = []\n",
        "    for p in paths:\n",
        "        dfp = pd.read_csv(p)\n",
        "        if cfg.TEXT_COL in dfp.columns and cfg.LABEL_COL in dfp.columns:\n",
        "            dfs.append(dfp[[cfg.TEXT_COL, cfg.LABEL_COL]])\n",
        "    if dfs:\n",
        "        group_frames[grp] = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# ---------------- Compute PR curves, AP, FPR@95%TPR ----------------\n",
        "def pr_ap(y_true, y_prob):\n",
        "    # Handle degenerate cases gracefully\n",
        "    try:\n",
        "        prec, rec, _ = precision_recall_curve(y_true, y_prob, pos_label=cfg.POS_LABEL)\n",
        "        ap = average_precision_score(y_true, y_prob)\n",
        "    except Exception:\n",
        "        prec, rec, ap = np.array([1.0, 0.0]), np.array([0.0, 1.0]), np.nan\n",
        "    return prec, rec, ap\n",
        "\n",
        "def fpr_at_95_tpr(y_true, y_prob):\n",
        "    try:\n",
        "        fpr, tpr, thr = roc_curve(y_true, y_prob, pos_label=cfg.POS_LABEL)\n",
        "        mask = tpr >= 0.95\n",
        "        return float(np.min(fpr[mask])) if np.any(mask) else np.nan\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "rows = []\n",
        "# Precompute clean for all models\n",
        "clean_curves = {}\n",
        "group_curves = {m: {} for m in MODELS}\n",
        "\n",
        "for model_name in MODELS:\n",
        "    # Clean\n",
        "    y_true_c, y_prob_c = eval_model(test_df, model_name)\n",
        "    pc, rc, ap_c = pr_ap(y_true_c, y_prob_c)\n",
        "    fpr95_c = fpr_at_95_tpr(y_true_c, y_prob_c)\n",
        "    clean_curves[model_name] = (pc, rc, ap_c, fpr95_c)\n",
        "\n",
        "    # Groups\n",
        "    for grp in ORDER_GROUPS:\n",
        "        df_g = group_frames.get(grp, None)\n",
        "        if df_g is None or df_g.empty:\n",
        "            group_curves[model_name][grp] = (None, None, np.nan, np.nan)\n",
        "            continue\n",
        "        y_true_g, y_prob_g = eval_model(df_g, model_name)\n",
        "        pg, rg, ap_g = pr_ap(y_true_g, y_prob_g)\n",
        "        fpr95_g = fpr_at_95_tpr(y_true_g, y_prob_g)\n",
        "        group_curves[model_name][grp] = (pg, rg, ap_g, fpr95_g)\n",
        "\n",
        "        rows.append({\n",
        "            \"Model\": model_name,\n",
        "            \"Group\": grp,\n",
        "            \"Clean AP\": ap_c,\n",
        "            \"Group AP\": ap_g,\n",
        "            \"ΔAP\": ap_c - ap_g if np.isfinite(ap_c) and np.isfinite(ap_g) else np.nan,\n",
        "            \"Clean FPR@95\": fpr95_c,\n",
        "            \"Group FPR@95\": fpr95_g,\n",
        "            \"ΔFPR@95\": (fpr95_g - fpr95_c) if np.isfinite(fpr95_c) and np.isfinite(fpr95_g) else np.nan,\n",
        "        })\n",
        "\n",
        "summary = pd.DataFrame(rows)\n",
        "sum_csv = os.path.join(cfg.OUT_DIR, \"group_pr_fpr95_summary.csv\")\n",
        "summary.to_csv(sum_csv, index=False)\n",
        "print(\"Saved:\", sum_csv)\n",
        "print(summary.round(4).to_string(index=False))\n",
        "\n",
        "# ---------------- Single Multi-Panel Figure ----------------\n",
        "# Layout: 2 rows x Ncols (Ncols = number of models)\n",
        "n_models = len(MODELS)\n",
        "fig, axes = plt.subplots(2, n_models, figsize=(5*n_models, 8.5), constrained_layout=True)\n",
        "\n",
        "for j, model_name in enumerate(MODELS):\n",
        "    # --- Top row: PR curves (Clean vs Groups) ---\n",
        "    ax_pr = axes[0, j] if n_models > 1 else axes[0]\n",
        "    pc, rc, ap_c, _ = clean_curves[model_name]\n",
        "    ax_pr.plot(rc, pc, label=f\"Clean (AP={ap_c:.3f})\", color=CLEAN_COLOR, linewidth=2)\n",
        "\n",
        "    for grp in ORDER_GROUPS:\n",
        "        pg, rg, ap_g, _ = group_curves[model_name].get(grp, (None, None, np.nan, np.nan))\n",
        "        if pg is None or rg is None:\n",
        "            continue\n",
        "        ax_pr.plot(rg, pg, label=f\"{grp} (AP={ap_g:.3f})\", color=GROUP_COLORS.get(grp, \"gray\"), alpha=0.9)\n",
        "\n",
        "    ax_pr.set_title(f\"{model_name} — PR Curves\")\n",
        "    ax_pr.set_xlabel(\"Recall\")\n",
        "    ax_pr.set_ylabel(\"Precision\")\n",
        "    ax_pr.set_xlim(0, 1); ax_pr.set_ylim(0, 1)\n",
        "    ax_pr.grid(True, linestyle=\"--\", alpha=0.3)\n",
        "    ax_pr.legend(fontsize=8, loc=\"lower left\")\n",
        "\n",
        "    # --- Bottom row: ΔFPR@95%TPR bars (Group − Clean) ---\n",
        "    ax_df = axes[1, j] if n_models > 1 else axes[1]\n",
        "    deltas = []\n",
        "    labels = []\n",
        "    colors = []\n",
        "    for grp in ORDER_GROUPS:\n",
        "        _, _, _, fpr95_g = group_curves[model_name].get(grp, (None, None, np.nan, np.nan))\n",
        "        _, _, _, fpr95_c = clean_curves[model_name]\n",
        "        if np.isfinite(fpr95_g) and np.isfinite(fpr95_c):\n",
        "            deltas.append(fpr95_g - fpr95_c)\n",
        "            labels.append(grp)\n",
        "            colors.append(GROUP_COLORS.get(grp, \"gray\"))\n",
        "\n",
        "    if deltas:\n",
        "        xs = np.arange(len(deltas))\n",
        "        ax_df.bar(xs, deltas, color=colors, edgecolor=\"black\", linewidth=0.7)\n",
        "        for xi, v in enumerate(deltas):\n",
        "            ax_df.text(xi, v + (0.01 if v >= 0 else -0.01), f\"{v:.3f}\",\n",
        "                       ha=\"center\", va=\"bottom\" if v >= 0 else \"top\", fontsize=8)\n",
        "        ax_df.set_xticks(xs); ax_df.set_xticklabels(labels, rotation=0)\n",
        "        ax_df.set_ylabel(\"ΔFPR @ 95% TPR\")\n",
        "        ax_df.set_title(f\"{model_name} — ΔFPR@95%TPR (Group − Clean)\")\n",
        "        ax_df.axhline(0, color=\"black\", linewidth=0.8)\n",
        "        ax_df.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
        "    else:\n",
        "        ax_df.set_title(f\"{model_name} — ΔFPR@95%TPR\")\n",
        "        ax_df.text(0.5, 0.5, \"No valid groups\", ha=\"center\", va=\"center\")\n",
        "        ax_df.axis(\"off\")\n",
        "\n",
        "panel_path = os.path.join(cfg.FIG_DIR, \"panel_pr_and_deltafpr.png\")\n",
        "plt.savefig(panel_path, dpi=cfg.DPI)\n",
        "plt.show()\n",
        "print(\"Saved:\", panel_path)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LW8Hi3pKtfFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === WORST-CASE grouped robustness: PR-AUC (AP) & ΔFPR@95%TPR ===\n",
        "# Outputs:\n",
        "#   adv_eval_outputs/grouped_eval/group_pr_fpr95_worst_summary.csv\n",
        "#   adv_eval_outputs/grouped_eval/figures_grouped/panel_pr_and_deltafpr_worst.png\n",
        "\n",
        "import os, re, glob, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "import torch, torch.nn as nn, joblib, xgboost as xgb\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    XLMRobertaTokenizerFast, XLMRobertaModel, XLMRobertaForSequenceClassification,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score, roc_curve\n",
        "\n",
        "# ---------------- Config ----------------\n",
        "class CFG:\n",
        "    BASE_DIR   = \"/content/drive/MyDrive/emc\"\n",
        "    TEST_CSV   = os.path.join(BASE_DIR, \"test.csv\")\n",
        "    TERMS_CSV  = os.path.join(BASE_DIR, \"engineering_terms.csv\")\n",
        "\n",
        "    XGB_DIR    = os.path.join(BASE_DIR, \"xgb_outputs_clean\")\n",
        "    XLMR_DIR   = os.path.join(BASE_DIR, \"xlmr_only_outputs_clean\")\n",
        "    SIMPLE_DIR = os.path.join(BASE_DIR, \"simple_fusion_outputs_clean\")\n",
        "    GATED_DIR  = os.path.join(BASE_DIR, \"gated_fusion_outputs_clean\")\n",
        "\n",
        "    ADV_DIR    = os.path.join(BASE_DIR, \"adv_eval_outputs\")\n",
        "    PERT_DIR   = os.path.join(ADV_DIR, \"perturbed\")\n",
        "    OUT_DIR    = os.path.join(ADV_DIR, \"grouped_eval\")\n",
        "    FIG_DIR    = os.path.join(OUT_DIR, \"figures_grouped\")\n",
        "\n",
        "    TEXT_COL   = \"content\"\n",
        "    LABEL_COL  = \"label\"\n",
        "    LANG_COL   = \"lang\"\n",
        "    MAX_LEN    = 256\n",
        "    BATCH_SIZE = 32\n",
        "    N_FEATS    = 12\n",
        "    POS_LABEL  = 1\n",
        "    DPI        = 600\n",
        "\n",
        "cfg = CFG()\n",
        "os.makedirs(cfg.OUT_DIR, exist_ok=True)\n",
        "os.makedirs(cfg.FIG_DIR, exist_ok=True)\n",
        "\n",
        "def _norm(s: str) -> str:\n",
        "    s = str(s).lower()\n",
        "    s = re.sub(r\"[\\s\\-\\/]+\", \"_\", s)\n",
        "    s = re.sub(r\"[^a-z0-9_]+\", \"\", s)\n",
        "    return s\n",
        "\n",
        "# ------------- Group mapping (3 buckets) -------------\n",
        "GROUP_MAP = {\n",
        "    # Structural\n",
        "    _norm(\"CharSwap\"): \"Structural\",\n",
        "    _norm(\"CaseToggle\"): \"Structural\",\n",
        "    _norm(\"PunctInsert\"): \"Structural\",\n",
        "    _norm(\"WhitespaceNoise\"): \"Structural\",\n",
        "    _norm(\"UnicodeConfuse\"): \"Structural\",\n",
        "    _norm(\"SymbolAscii\"): \"Structural\",\n",
        "    _norm(\"Truncate80w\"): \"Structural\",\n",
        "    # Semantic/Cue\n",
        "    _norm(\"MaskDomainTerms\"): \"Semantic/Cue\",\n",
        "    _norm(\"DropDomainTerms\"): \"Semantic/Cue\",\n",
        "    _norm(\"SynonymSwapDomain\"): \"Semantic/Cue\",\n",
        "    _norm(\"AcronymPerturb\"): \"Semantic/Cue\",\n",
        "    _norm(\"CitationStrip\"): \"Semantic/Cue\",\n",
        "    _norm(\"DomainCombo1\"): \"Semantic/Cue\",\n",
        "    _norm(\"DomainCombo2\"): \"Semantic/Cue\",\n",
        "    _norm(\"DomainCombo3\"): \"Semantic/Cue\",\n",
        "    _norm(\"DomainMax\"): \"Semantic/Cue\",\n",
        "    # Feature-Targeted\n",
        "    _norm(\"NumberPerturb\"): \"Feature-Targeted\",\n",
        "    _norm(\"StandardNumCorrupt\"): \"Feature-Targeted\",\n",
        "    _norm(\"UnitNeutralizeMask\"): \"Feature-Targeted\",\n",
        "    _norm(\"UnitNeutralizeDrop\"): \"Feature-Targeted\",\n",
        "    _norm(\"UnitNeutralizeGeneric\"): \"Feature-Targeted\",\n",
        "    _norm(\"Numbers/Units\"): \"Feature-Targeted\",\n",
        "    _norm(\"Unit Conversion (NEW)\"): \"Feature-Targeted\",\n",
        "}\n",
        "ORDER_GROUPS = [\"Structural\", \"Semantic/Cue\", \"Feature-Targeted\"]\n",
        "\n",
        "MODELS = [\"XLM-R Only\", \"XGBoost + Features\", \"Simple Fusion\", \"Gated Fusion\"]\n",
        "MODEL_COLORS = {\n",
        "    \"XGBoost + Features\": \"tab:blue\",\n",
        "    \"XLM-R Only\":         \"tab:red\",\n",
        "    \"Simple Fusion\":      \"tab:green\",\n",
        "    \"Gated Fusion\":       \"tab:orange\",\n",
        "}\n",
        "GROUP_COLORS = {\n",
        "    \"Structural\":      \"tab:blue\",\n",
        "    \"Semantic/Cue\":    \"tab:orange\",\n",
        "    \"Feature-Targeted\":\"tab:green\",\n",
        "}\n",
        "CLEAN_COLOR = \"black\"\n",
        "\n",
        "# ---------------- Feature extractor (12-D) ----------------\n",
        "import re\n",
        "_WORD_RE = re.compile(r\"\\w+\", re.UNICODE)\n",
        "_NUM_RE  = re.compile(r'[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?')\n",
        "STD_TERMS = {\"iso\",\"asme\",\"ieee\",\"din\",\"ansi\",\"iec\",\"ul\",\"astm\",\"en\"}\n",
        "SAFETY_TERMS = {\"safety\",\"hazard\",\"warning\",\"risk\",\"caution\",\"danger\",\"emergency\"}\n",
        "\n",
        "def simple_words(t: str): return _WORD_RE.findall(t or \"\")\n",
        "def sent_count(t: str) -> int:\n",
        "    if not t: return 0\n",
        "    return max(1, len(re.split(r'[.!?]+[\\s\\n]+', t)))\n",
        "def punct_count(t: str) -> int: return sum(1 for ch in (t or \"\") if ch in \".,;:!?\")\n",
        "def extract_numbers(text: str):\n",
        "    nums, dec = [], 0\n",
        "    for m in _NUM_RE.finditer(text or \"\"):\n",
        "        s = m.group(0)\n",
        "        try:\n",
        "            v = float(s)\n",
        "            if ('.' in s) or ('e' in s.lower()): dec += 1\n",
        "            nums.append(abs(v))\n",
        "        except: pass\n",
        "    return nums, dec\n",
        "def _finite_or_zero(x: float):\n",
        "    try:\n",
        "        xx = float(x)\n",
        "        return xx if np.isfinite(xx) else 0.0\n",
        "    except: return 0.0\n",
        "\n",
        "class TermsLexicon:\n",
        "    def __init__(self, csv_path: str, term_col=\"terms\", lang_col=\"lang\"):\n",
        "        df = pd.read_csv(csv_path)\n",
        "        if term_col not in df.columns: raise ValueError(f\"Missing '{term_col}'\")\n",
        "        if lang_col not in df.columns: df[lang_col] = 'en'\n",
        "        self.by_lang = {str(l).lower(): set(str(x).strip().lower()\n",
        "                         for x in d[term_col].dropna().tolist() if str(x).strip())\n",
        "                        for l, d in df.groupby(lang_col)}\n",
        "    def pct_in_text(self, text: str, lang: str) -> float:\n",
        "        terms = self.by_lang.get((lang or \"en\").lower(), set())\n",
        "        if not terms: return 0.0\n",
        "        ws = [w.lower() for w in simple_words(text)]\n",
        "        return sum(1 for w in ws if w in terms) / max(1, len(ws)) if ws else 0.0\n",
        "\n",
        "lex = TermsLexicon(cfg.TERMS_CSV)\n",
        "\n",
        "def engineered_features(df):\n",
        "    def extract_one(text, lang=\"en\"):\n",
        "        text = \"\" if text is None else str(text); lang = (lang or \"en\").lower()\n",
        "        ws = simple_words(text); n_words = len(ws)\n",
        "        chars = len(text); words = n_words; sents = sent_count(text)\n",
        "        fre, fog = 0.0, 0.0\n",
        "        eng_pct = lex.pct_in_text(text, lang)\n",
        "        punc = punct_count(text)\n",
        "        nums, dec_cnt = extract_numbers(text); nnums = len(nums)\n",
        "        avg_mag = float(np.mean(nums)) if nums else 0.0\n",
        "        dec_ratio = float(dec_cnt / max(1, len(nums)))\n",
        "        low = text.lower()\n",
        "        has_std = 1.0 if any(t in low for t in STD_TERMS) else 0.0\n",
        "        has_saf = 1.0 if any(t in low for t in SAFETY_TERMS) else 0.0\n",
        "        vals = [chars, words, sents, fre, fog, eng_pct, punc, nnums, has_std, has_saf, avg_mag, dec_ratio]\n",
        "        arr = np.asarray([_finite_or_zero(v) for v in vals], dtype=np.float64)\n",
        "        arr = np.nan_to_num(arr, nan=0.0, posinf=1e12, neginf=0.0)\n",
        "        return np.clip(arr, -1e12, 1e12).astype(np.float32)\n",
        "    local = df if cfg.LANG_COL in df.columns else df.assign(**{cfg.LANG_COL:'en'})\n",
        "    rows = [extract_one(r.get(cfg.TEXT_COL,\"\"), r.get(cfg.LANG_COL,\"en\")) for _, r in local.iterrows()]\n",
        "    return np.stack(rows, axis=0).astype(np.float32)\n",
        "\n",
        "# ---------------- Tokenizer & models ----------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tok = XLMRobertaTokenizerFast.from_pretrained(cfg.XLMR_DIR)\n",
        "collator = DataCollatorWithPadding(tok)\n",
        "\n",
        "class TextOnlyDS(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.x = df[cfg.TEXT_COL].astype(str).tolist()\n",
        "               # guard against non-int types\n",
        "        self.y = df[cfg.LABEL_COL].astype(int).values\n",
        "    def __len__(self): return len(self.x)\n",
        "    def __getitem__(self, i):\n",
        "        enc = tok(self.x[i], truncation=True, padding=False, max_length=cfg.MAX_LEN, return_tensors=\"pt\")\n",
        "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
        "        item[\"labels\"] = torch.tensor(int(self.y[i]), dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "class TextFeatDS(Dataset):\n",
        "    def __init__(self, df, feats_scaled):\n",
        "        self.x = df[cfg.TEXT_COL].astype(str).tolist()\n",
        "        self.y = df[cfg.LABEL_COL].astype(int).values\n",
        "        self.fe = feats_scaled.astype(np.float32)\n",
        "    def __len__(self): return len(self.x)\n",
        "    def __getitem__(self, i):\n",
        "        enc = tok(self.x[i], truncation=True, padding=\"max_length\", max_length=cfg.MAX_LEN, return_tensors=\"pt\")\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(int(self.y[i]), dtype=torch.long),\n",
        "            \"feats\": torch.tensor(self.fe[i], dtype=torch.float32),\n",
        "        }\n",
        "\n",
        "class SimpleFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + n_feats, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (out.last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "        fused = torch.cat([pooled, feats], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "\n",
        "class GatedFusion(nn.Module):\n",
        "    def __init__(self, model_name: str, n_feats: int, n_labels: int = 2, feat_proj: int = 64):\n",
        "        super().__init__()\n",
        "        self.encoder = XLMRobertaModel.from_pretrained(model_name)\n",
        "        H = self.encoder.config.hidden_size\n",
        "        self.fe_proj = nn.Sequential(nn.Linear(n_feats, feat_proj), nn.ReLU())\n",
        "        self.gate    = nn.Sequential(nn.Linear(H + n_feats, 64), nn.ReLU(), nn.Linear(64, 1), nn.Sigmoid())\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(H + feat_proj, n_labels)\n",
        "    def forward(self, input_ids, attention_mask, feats):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        mask = attention_mask.unsqueeze(-1).float()\n",
        "        pooled = (out.last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "        alpha = self.gate(torch.cat([pooled, feats], dim=1))\n",
        "        ef    = self.fe_proj(feats)\n",
        "        fused = torch.cat([pooled, alpha * ef], dim=1)\n",
        "        return self.classifier(self.dropout(fused))\n",
        "\n",
        "# Load artifacts\n",
        "xgb_model = xgb.XGBClassifier(); xgb_model.load_model(os.path.join(cfg.XGB_DIR, \"xgb_model.json\"))\n",
        "xgb_scaler = joblib.load(os.path.join(cfg.XGB_DIR, \"scaler12.pkl\"))\n",
        "\n",
        "xlmr = XLMRobertaForSequenceClassification.from_pretrained(cfg.XLMR_DIR).to(device); xlmr.eval()\n",
        "\n",
        "simple = SimpleFusion(\"xlm-roberta-base\", cfg.N_FEATS, 2).to(device)\n",
        "simple.load_state_dict(torch.load(os.path.join(cfg.SIMPLE_DIR, \"fusion_simple.pt\"), map_location=device), strict=False); simple.eval()\n",
        "simple_scaler = joblib.load(os.path.join(cfg.SIMPLE_DIR, \"scaler12.pkl\"))\n",
        "\n",
        "gated = GatedFusion(\"xlm-roberta-base\", cfg.N_FEATS, 2, feat_proj=64).to(device)\n",
        "gated.load_state_dict(torch.load(os.path.join(cfg.GATED_DIR, \"fusion_gated.pt\"), map_location=device), strict=False); gated.eval()\n",
        "gated_scaler = joblib.load(os.path.join(cfg.GATED_DIR, \"scaler12.pkl\"))\n",
        "\n",
        "# ---------------- Eval helpers ----------------\n",
        "@torch.no_grad()\n",
        "def eval_xlmr(df):\n",
        "    ds = TextOnlyDS(df)\n",
        "    dl = DataLoader(ds, batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=DataCollatorWithPadding(tok))\n",
        "    probs = []\n",
        "    for b in dl:\n",
        "        inp = {k: v.to(device) for k, v in b.items() if k in (\"input_ids\",\"attention_mask\")}\n",
        "        pr = torch.softmax(xlmr(**inp).logits, dim=-1)[:, cfg.POS_LABEL].cpu().numpy()\n",
        "        probs.append(pr)\n",
        "    return df[cfg.LABEL_COL].astype(int).values, np.concatenate(probs)\n",
        "\n",
        "def eval_xgb(df):\n",
        "    X = engineered_features(df); Xs = xgb_scaler.transform(X)\n",
        "    y_prob = xgb_model.predict_proba(Xs)[:, cfg.POS_LABEL]\n",
        "    return df[cfg.LABEL_COL].astype(int).values, y_prob\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_fusion(df, scaler, model):\n",
        "    X = engineered_features(df); Xs = scaler.transform(X).astype(np.float32)\n",
        "    ds = TextFeatDS(df, Xs)\n",
        "    dl = DataLoader(ds, batch_size=cfg.BATCH_SIZE, shuffle=False, collate_fn=DataCollatorWithPadding(tok))\n",
        "    probs = []\n",
        "    for b in dl:\n",
        "        ids = b[\"input_ids\"].to(device); am = b[\"attention_mask\"].to(device); ft = b[\"feats\"].to(device)\n",
        "        pr = torch.softmax(model(ids, am, ft), dim=-1)[:, cfg.POS_LABEL].cpu().numpy()\n",
        "        probs.append(pr)\n",
        "    return df[cfg.LABEL_COL].astype(int).values, np.concatenate(probs)\n",
        "\n",
        "def eval_model(df, model_name):\n",
        "    if model_name == \"XLM-R Only\":\n",
        "        return eval_xlmr(df)\n",
        "    elif model_name == \"XGBoost + Features\":\n",
        "        return eval_xgb(df)\n",
        "    elif model_name == \"Simple Fusion\":\n",
        "        return eval_fusion(df, simple_scaler, simple)\n",
        "    else:\n",
        "        return eval_fusion(df, gated_scaler, gated)\n",
        "\n",
        "def pr_ap(y_true, y_prob, pos=1):\n",
        "    try:\n",
        "        prec, rec, _ = precision_recall_curve(y_true, y_prob, pos_label=pos)\n",
        "        ap = average_precision_score(y_true, y_prob)\n",
        "    except Exception:\n",
        "        prec, rec, ap = np.array([1.0, 0.0]), np.array([0.0, 1.0]), np.nan\n",
        "    return prec, rec, ap\n",
        "\n",
        "def fpr_at_95_tpr(y_true, y_prob, pos=1):\n",
        "    try:\n",
        "        fpr, tpr, thr = roc_curve(y_true, y_prob, pos_label=pos)\n",
        "        mask = tpr >= 0.95\n",
        "        return float(np.min(fpr[mask])) if np.any(mask) else np.nan\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "# ---------------- Build per-group file lists ----------------\n",
        "files = sorted(glob.glob(os.path.join(cfg.PERT_DIR, \"*.csv\")))\n",
        "attack_to_group = {}\n",
        "for p in files:\n",
        "    name = os.path.splitext(os.path.basename(p))[0]\n",
        "    grp = GROUP_MAP.get(name, None)\n",
        "    if grp:\n",
        "        attack_to_group.setdefault(grp, []).append(p)\n",
        "\n",
        "# ---------------- Clean baseline ----------------\n",
        "test_df = pd.read_csv(cfg.TEST_CSV)\n",
        "assert cfg.TEXT_COL in test_df.columns and cfg.LABEL_COL in test_df.columns, \"test.csv must have content + label\"\n",
        "\n",
        "clean_curves = {}\n",
        "for model_name in MODELS:\n",
        "    y_true_c, y_prob_c = eval_model(test_df, model_name)\n",
        "    pc, rc, ap_c = pr_ap(y_true_c, y_prob_c, pos=cfg.POS_LABEL)\n",
        "    fpr95_c = fpr_at_95_tpr(y_true_c, y_prob_c, pos=cfg.POS_LABEL)\n",
        "    clean_curves[model_name] = {\"prec\": pc, \"rec\": rc, \"ap\": ap_c, \"fpr95\": fpr95_c}\n",
        "\n",
        "# ---------------- Worst-case search per group ----------------\n",
        "summary_rows = []\n",
        "worst_curves = {m: {} for m in MODELS}   # store worst-AP PR curve per group for plotting\n",
        "\n",
        "for model_name in MODELS:\n",
        "    c_ap = clean_curves[model_name][\"ap\"]\n",
        "    c_fpr = clean_curves[model_name][\"fpr95\"]\n",
        "\n",
        "    for grp in ORDER_GROUPS:\n",
        "        paths = attack_to_group.get(grp, [])\n",
        "        if not paths:\n",
        "            summary_rows.append({\n",
        "                \"Model\": model_name, \"Group\": grp,\n",
        "                \"Clean AP\": c_ap, \"Worst AP\": np.nan, \"ΔAP\": np.nan,\n",
        "                \"Clean FPR@95\": c_fpr, \"Worst FPR@95\": np.nan, \"ΔFPR@95\": np.nan,\n",
        "                \"Worst_AP_Attack\": None, \"Worst_FPR_Attack\": None\n",
        "            })\n",
        "            worst_curves[model_name][grp] = None\n",
        "            continue\n",
        "\n",
        "        # Track worst AP and worst ΔFPR (max increase). They may be from different attacks.\n",
        "        min_ap = np.inf;  min_ap_attack = None; min_ap_curve = None\n",
        "        max_dfpr = -np.inf; max_dfpr_attack = None; worst_fpr_value = np.nan\n",
        "\n",
        "        for p in paths:\n",
        "            dfp = pd.read_csv(p)\n",
        "            if cfg.TEXT_COL not in dfp.columns or cfg.LABEL_COL not in dfp.columns:\n",
        "                continue\n",
        "            y_true_g, y_prob_g = eval_model(dfp, model_name)\n",
        "            prec, rec, ap_g = pr_ap(y_true_g, y_prob_g, pos=cfg.POS_LABEL)\n",
        "            fpr95_g = fpr_at_95_tpr(y_true_g, y_prob_g, pos=cfg.POS_LABEL)\n",
        "\n",
        "            # Worst AP (min)\n",
        "            if np.isfinite(ap_g) and ap_g < min_ap:\n",
        "                min_ap = ap_g\n",
        "                min_ap_attack = os.path.splitext(os.path.basename(p))[0]\n",
        "                min_ap_curve = (prec, rec, ap_g)\n",
        "\n",
        "            # Worst ΔFPR (max increase)\n",
        "            if np.isfinite(c_fpr) and np.isfinite(fpr95_g):\n",
        "                delta = fpr95_g - c_fpr\n",
        "                if delta > max_dfpr:\n",
        "                    max_dfpr = delta\n",
        "                    max_dfpr_attack = os.path.splitext(os.path.basename(p))[0]\n",
        "                    worst_fpr_value = fpr95_g\n",
        "\n",
        "        # Record for plotting (PR uses the worst-AP curve)\n",
        "        worst_curves[model_name][grp] = None if min_ap_attack is None else {\n",
        "            \"prec\": min_ap_curve[0], \"rec\": min_ap_curve[1], \"ap\": min_ap_curve[2], \"attack\": min_ap_attack\n",
        "        }\n",
        "\n",
        "        # Add summary row\n",
        "        summary_rows.append({\n",
        "            \"Model\": model_name, \"Group\": grp,\n",
        "            \"Clean AP\": c_ap,\n",
        "            \"Worst AP\": min_ap if np.isfinite(min_ap) else np.nan,\n",
        "            \"ΔAP\": (c_ap - min_ap) if (np.isfinite(c_ap) and np.isfinite(min_ap)) else np.nan,\n",
        "            \"Clean FPR@95\": c_fpr,\n",
        "            \"Worst FPR@95\": worst_fpr_value if np.isfinite(worst_fpr_value) else np.nan,\n",
        "            \"ΔFPR@95\": max_dfpr if np.isfinite(max_dfpr) else np.nan,\n",
        "            \"Worst_AP_Attack\": min_ap_attack,\n",
        "            \"Worst_FPR_Attack\": max_dfpr_attack\n",
        "        })\n",
        "\n",
        "summary = pd.DataFrame(summary_rows)\n",
        "sum_csv = os.path.join(cfg.OUT_DIR, \"group_pr_fpr95_worst_summary.csv\")\n",
        "summary.to_csv(sum_csv, index=False)\n",
        "print(\"Saved:\", sum_csv)\n",
        "print(summary.round(4).to_string(index=False))\n",
        "\n",
        "# ---------------- Single Multi-Panel Figure (Worst-case) ----------------\n",
        "n_models = len(MODELS)\n",
        "fig, axes = plt.subplots(2, n_models, figsize=(5*n_models, 8.5), constrained_layout=True)\n",
        "\n",
        "for j, model_name in enumerate(MODELS):\n",
        "    # --- Top row: PR curves (Clean vs each Group's worst-AP attack) ---\n",
        "    ax_pr = axes[0, j] if n_models > 1 else axes[0]\n",
        "    c = clean_curves[model_name]\n",
        "    ax_pr.plot(c[\"rec\"], c[\"prec\"], label=f\"Clean (AP={c['ap']:.3f})\", color=CLEAN_COLOR, linewidth=2)\n",
        "\n",
        "    for grp in ORDER_GROUPS:\n",
        "        wc = worst_curves[model_name].get(grp)\n",
        "        if wc is None:\n",
        "            continue\n",
        "        label = f\"{grp} worst (AP={wc['ap']:.3f})\"\n",
        "        ax_pr.plot(wc[\"rec\"], wc[\"prec\"], label=label, color=GROUP_COLORS.get(grp, \"gray\"), alpha=0.95)\n",
        "\n",
        "    ax_pr.set_title(f\"{model_name} — Worst-case PR\")\n",
        "    ax_pr.set_xlabel(\"Recall\"); ax_pr.set_ylabel(\"Precision\")\n",
        "    ax_pr.set_xlim(0, 1); ax_pr.set_ylim(0, 1)\n",
        "    ax_pr.grid(True, linestyle=\"--\", alpha=0.3)\n",
        "    ax_pr.legend(fontsize=8, loc=\"lower left\")\n",
        "\n",
        "    # --- Bottom row: worst ΔFPR@95%TPR bars ---\n",
        "    ax_df = axes[1, j] if n_models > 1 else axes[1]\n",
        "    sub = summary[(summary[\"Model\"]==model_name) & (summary[\"Group\"].isin(ORDER_GROUPS))].copy()\n",
        "    sub = sub.sort_values(\"Group\")\n",
        "    xs = np.arange(len(sub))\n",
        "    ax_df.bar(xs, sub[\"ΔFPR@95\"].values, color=[GROUP_COLORS[g] for g in sub[\"Group\"]], edgecolor=\"black\", linewidth=0.7)\n",
        "    for xi, v in enumerate(sub[\"ΔFPR@95\"].values):\n",
        "        if np.isfinite(v):\n",
        "            ax_df.text(xi, v + (0.01 if v >= 0 else -0.01), f\"{v:.3f}\", ha=\"center\", va=\"bottom\" if v>=0 else \"top\", fontsize=8)\n",
        "    ax_df.set_xticks(xs); ax_df.set_xticklabels(sub[\"Group\"], rotation=0)\n",
        "    ax_df.set_ylabel(\"ΔFPR @ 95% TPR\")\n",
        "    ax_df.set_title(f\"{model_name} — Worst ΔFPR@95%TPR\")\n",
        "    ax_df.axhline(0, color=\"black\", linewidth=0.8)\n",
        "    ax_df.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
        "\n",
        "panel_path = os.path.join(cfg.FIG_DIR, \"panel_pr_and_deltafpr_worst.png\")\n",
        "plt.savefig(panel_path, dpi=cfg.DPI)\n",
        "plt.show()\n",
        "print(\"Saved:\", panel_path)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "HftMfCGd2GAv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
